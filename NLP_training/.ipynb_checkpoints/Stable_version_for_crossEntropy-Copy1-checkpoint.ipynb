{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POLITICS', 'TRAVEL', 'HEALTHY LIVING', 'BUSINESS', 'BLACK VOICES', 'THE WORLDPOST', 'IMPACT', 'MEDIA', 'WORLDPOST', 'SCIENCE', 'TECH', 'FIFTY', 'ENVIRONMENT', 'CULTURE & ARTS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\אבינעם\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\אבינעם\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\אבינעם\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import nltk\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import torch.utils.data as torch_data\n",
    "import scipy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# from Utils.pytorch_utils import torch_net\n",
    "from Utils.pytorch_utils import sparse_to_matrix #, accuracy_test\n",
    "\n",
    "from Utils.NLP_utils import accuracy, find_senteces_with_lemma, get_wordnet_pos, load_and_lemmatize_data, load_processed_data\n",
    "\n",
    "# pickle file, data set as readable json file, since original data set is a 'pseudo json', written in text file.\n",
    "DATA_SET_FILE = r\"C:\\Users\\גורים\\PycharmProjects\\NLP_training\\datasets\\News_Category_Dataset_v2_mod.pkl\"\n",
    "PROCESSED_DATA_SET = r\"C:\\Users\\גורים\\PycharmProjects\\NLP_training\\datasets\\News_Category_Dataset_v2_mod_processed.pkl\"\n",
    "\n",
    "ALL_CATEGORIES = ['POLITICS', 'WELLNESS', 'ENTERTAINMENT', 'TRAVEL', 'STYLE & BEAUTY',\n",
    "       'PARENTING', 'HEALTHY LIVING', 'QUEER VOICES', 'FOOD & DRINK',\n",
    "       'BUSINESS', 'COMEDY', 'SPORTS', 'BLACK VOICES', 'HOME & LIVING',\n",
    "       'PARENTS', 'THE WORLDPOST', 'WEDDINGS', 'WOMEN', 'IMPACT', 'DIVORCE',\n",
    "       'CRIME', 'MEDIA', 'WEIRD NEWS', 'GREEN', 'WORLDPOST', 'RELIGION',\n",
    "       'STYLE', 'SCIENCE', 'WORLD NEWS', 'TASTE', 'TECH', 'MONEY', 'ARTS',\n",
    "       'FIFTY', 'GOOD NEWS', 'ARTS & CULTURE', 'ENVIRONMENT', 'COLLEGE',\n",
    "       'LATINO VOICES', 'CULTURE & ARTS', 'EDUCATION']\n",
    "\n",
    "# REQUIRED_CATEGORIES = ['RELIGION','SCIENCE', 'TASTE','PARENTING' , 'COLLEGE' ,'POLITICS' ]\n",
    "REQUIRED_CATEGORIES = (np.array(ALL_CATEGORIES)[::3]).tolist()\n",
    "print (REQUIRED_CATEGORIES)\n",
    "NUM_CATEGORIES = len(REQUIRED_CATEGORIES)\n",
    "    \n",
    "    \n",
    "CrossEntropyLoss = \"CrossEntropyLoss\"\n",
    "MSELoss = \"MSELoss\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set loss type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_name = CrossEntropyLoss\n",
    "# loss_name = MSELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_to_matrix(A):\n",
    "    if type(A) == scipy.sparse.csr.csr_matrix:\n",
    "        return np.array(A.todense())\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_disp(y_pred,y_true,label = False):\n",
    "    cm = confusion_matrix(y_pred,y_true)\n",
    "    if not label:\n",
    "        label = range(NUM_CATEGORIES)\n",
    "    cm_pd = pd.DataFrame(cm,index = [\"{}_P\".format(i)  for i in label],columns = [\"{}_T\".format(i)  for i in label])\n",
    "    return cm_pd\n",
    "\n",
    "# def accuracy_test_dummies(model, x, y, data_set_name = 'test',print_sample = False):\n",
    "#     predicted = torch.argmax(model(torch.tensor(x, dtype=torch.float)), dim=-1).numpy()\n",
    "#     truth = np.argmax(y, axis=-1)\n",
    "#     # print(np.array((predicted, truth)))\n",
    "#     print (f\"Accuracy {data_set_name} = \",\n",
    "#            round( np.array(predicted == truth).mean()* 100, 3 ),\n",
    "#            \"%\")\n",
    "#     if print_sample:\n",
    "#         ps = print_sample\n",
    "#         sample = pd.DataFrame((predicted[:ps],truth[:ps]),index=['predicted','truth'])\n",
    "#         print (sample)\n",
    "#         print (pd.value_counts(predicted))\n",
    "#         print (\"\\tConfusion Matrix:\\n\",confusion_matrix_disp (predicted,truth))\n",
    "        \n",
    "# def accuracy_test_classes(model, x, y, data_set_name = 'test',print_sample = False):\n",
    "#     predicted = torch.argmax(model(torch.tensor(x, dtype=torch.float)), dim=-1).numpy()\n",
    "#     truth = y.ravel()\n",
    "#     # print(np.array((predicted, truth)))\n",
    "#     print (f\"Accuracy {data_set_name} = \",\n",
    "#            round( np.array(predicted == truth).mean()* 100, 3 ),\n",
    "#            \"%\")\n",
    "#     if print_sample:\n",
    "#         ps = print_sample\n",
    "#         sample = pd.DataFrame((predicted[:ps],truth[:ps]),index=['predicted','truth'])\n",
    "#         print (sample)\n",
    "#         print (pd.value_counts(predicted))\n",
    "#         print (\"\\tConfusion Matrix:\\n\",confusion_matrix_disp (predicted,truth))\n",
    "\n",
    "def accuracy_test(model, x, y, data_set_name = 'test',print_sample = False,top_n_guess = 1):\n",
    "          \n",
    "    if loss_name == MSELoss:\n",
    "        truth = np.argmax(y, axis=-1)\n",
    "    elif loss_name == CrossEntropyLoss:\n",
    "        truth = y.ravel()\n",
    "    \n",
    "    model_result = model(torch.tensor(x, dtype=torch.float))\n",
    "    top_guesses = torch.argsort( model_result , dim = -1, descending=True ).numpy() [:,:top_n_guess]\n",
    "    # predicted   = torch.argmax ( model_result, dim=-1).numpy()\n",
    "    true_predicted = (top_guesses == truth[:,None]).any(1)\n",
    "    \n",
    "#     print (\"model_result = \", model_result[:10])\n",
    "#     print (\"top_guesses =\", top_guesses[:10])\n",
    "#     print (\"predicted = \", predicted[:10])\n",
    "\n",
    "    print (f\"Accuracy (top {top_n_guess} guesses) - {data_set_name} = \",\n",
    "           round( np.array(true_predicted).mean()* 100, 3 ),\n",
    "           \"%\")\n",
    "    if print_sample:\n",
    "        ps = print_sample\n",
    "        sample = pd.DataFrame((top_guesses[:ps],truth[:ps]),index=['predicted','truth'])\n",
    "        print (sample)\n",
    "        # print (pd.value_counts(predicted))\n",
    "    print (f\"\\tConfusion Matrix {data_set_name}:\\n\",confusion_matrix_disp (top_guesses[:,0],truth))\n",
    "    \n",
    "    \n",
    "        \n",
    "# if loss_name == MSELoss:\n",
    "#     accuracy_test = accuracy_test_dummies\n",
    "# elif loss_name == CrossEntropyLoss:\n",
    "#     accuracy_test = accuracy_test_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "\n",
    "# dataset, headlines, headlines_orig = load_and_lemmatize_data(DATA_SET_FILE)\n",
    "dataset, headlines, headlines_orig = load_processed_data(PROCESSED_DATA_SET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reduce dataset to n categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = dataset['category']\n",
    "pd.value_counts(categories)\n",
    "\n",
    "# filter data for desired categories, to make problem easier\n",
    "filter_categories = True\n",
    "if filter_categories:\n",
    "    filter_index =  categories.isin(REQUIRED_CATEGORIES)\n",
    "    dataset   = dataset[filter_index]\n",
    "    headlines = np.array(headlines)[filter_index]\n",
    "    headlines_orig = np.array(headlines_orig)[filter_index]\n",
    "    \n",
    "else:\n",
    "    NUM_CATEGORIES = len(set(categories))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categories_to_index(categories):\n",
    "    d = {}\n",
    "    for i, cat in enumerate(REQUIRED_CATEGORIES):\n",
    "        d[cat] = i\n",
    "        \n",
    "    r = np.array(range(len(categories)))\n",
    "\n",
    "    for cat,i in d.items():\n",
    "        # print (cat,i)\n",
    "        r[categories == cat ] = i\n",
    "    return r\n",
    "\n",
    "categories = dataset['category']\n",
    "if loss_name == CrossEntropyLoss:  \n",
    "    Y = categories_to_index(categories)[:,np.newaxis]\n",
    "else:\n",
    "    Y  = np.array(pd.get_dummies(categories)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data and lables to train/test\n",
    "\n",
    "headlines_train, headlines_test,\\\n",
    "headlines_train_orig, headlines_test_orig,\\\n",
    "Y_train, Y_test,\\\n",
    "    = sklearn.model_selection.train_test_split(\n",
    "    headlines,headlines_orig, Y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features (Bag Of Words) using Vectorizer\n",
    "\n",
    "max_features=2000\n",
    "\n",
    "vectorizer = CountVectorizer\n",
    "# vectorizer = TfidfVectorizer\n",
    "matrix = vectorizer(max_features=max_features, ngram_range=(1, 2), max_df=0.1 ,min_df = 5)\n",
    "matrix.fit(headlines_train)\n",
    "X_train = matrix.transform(headlines_train)# .todense()\n",
    "X_test = matrix.transform(headlines_test)# .todense()\n",
    "\n",
    "# --- convert to data frame for display and debug ---\n",
    "# tokens = matrix.get_feature_names()\n",
    "# X_train= pd.DataFrame(X_train,columns=tokens)\n",
    "# X_test= pd.DataFrame(X_test,columns=tokens)\n",
    "\n",
    "assert X_train.shape[1]==max_features, X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated torch nn\n"
     ]
    }
   ],
   "source": [
    "def torch_net(X_train, Y_train, X_test, Y_test,\n",
    "              hidden_layers=[10], device=torch.device('cpu'), epoch=30, batch_size=17):\n",
    "    \n",
    "    def set_learning_rate(optimizer,lr):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "            \n",
    "    def print_learning_rate(optimizer):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print('lr', param_group['lr'])\n",
    "    \n",
    "    # hiden_layers = [size1,size2...]\n",
    "\n",
    "        \n",
    "    dtype = torch.float\n",
    "    # device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "    # N is batch size; D_in is input dimension;\n",
    "    # H is hidden dimension; D_out is output dimension.\n",
    "    N, D_in = X_train.shape\n",
    "    \n",
    "    if loss_name == MSELoss: \n",
    "        D_out = Y_train.shape[-1] \n",
    "    elif loss_name == CrossEntropyLoss: \n",
    "        D_out = NUM_CATEGORIES\n",
    "\n",
    "    # Create random input and output data\n",
    "\n",
    "    [X_train, Y_train, X_test, Y_test] = \\\n",
    "        [sparse_to_matrix(A) for A in[X_train, Y_train, X_test, Y_test]]\n",
    "\n",
    "    X = torch.tensor(X_train, device=device, dtype=dtype)\n",
    "    if loss_name == CrossEntropyLoss:\n",
    "        y_dtype = torch.int64\n",
    "    else:\n",
    "        y_dtype = dtype\n",
    "    Y = torch.tensor(Y_train, device=device, dtype=y_dtype)\n",
    "#     print (Y)\n",
    "\n",
    "    #create neural network net with multiple hidden layers with H dimetions:\n",
    "    dims = [D_in, *hidden_layers, D_out]\n",
    "    layers = []\n",
    "    for dim_ind in range(len(dims)-2):\n",
    "        layers.append(torch.nn.Linear(dims[dim_ind], dims[dim_ind+1]))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "    layers.append(torch.nn.Dropout(0.5))\n",
    "    layers.append(torch.nn.Linear(dims[-2], D_out))   \n",
    "    \n",
    "    model = torch.nn.Sequential(*layers)\n",
    "    if loss_name == CrossEntropyLoss:\n",
    "        weights = (np.power(1/pd.value_counts(Y.tolist(),normalize=True),1.2)).to_list()\n",
    "        weights = torch.tensor(weights)\n",
    "        loss_fn = torch.nn.CrossEntropyLoss(reduction='mean', weight=weights)     \n",
    "    elif loss_name == MSELoss:\n",
    "        loss_fn = torch.nn.MSELoss(reduction='mean') \n",
    "\n",
    "    # Use the optim package to define an Optimizer that will update the weights of\n",
    "    # the model for us. Here we will use Adam; the optim package contains many other\n",
    "    # optimization algoriths. The first argument to the Adam constructor tells the\n",
    "    # optimizer which Tensors it should update.\n",
    "    learning_rate = 0.005\n",
    "    weight_decay = 0.001\n",
    "    lr_decay = 0.9\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=10000, verbose=True, threshold=0.0001,\n",
    "                                  threshold_mode='rel', cooldown=2000, min_lr=1e-10, eps=1e-08)\n",
    "    \n",
    "    dataloader = torch_data.DataLoader(\n",
    "        torch_data.TensorDataset(X, Y), batch_size=batch_size,\n",
    "        shuffle=True, num_workers=4)\n",
    "    print (\"Start training:\")\n",
    "    print (\"loss name is: \",loss_name, \" Using loss function: \", loss_fn)\n",
    "    accuracy_test(model, X_test, Y_test, data_set_name='test',print_sample = 10, top_n_guess= 1 )\n",
    "    # accuracy_test(model, X_train, Y_train, data_set_name='train',print_sample = 0, top_n_guess= 3)\n",
    "    \n",
    "    epoch_lr = learning_rate\n",
    "    min_loss = 100.0\n",
    "    i_iter =-1\n",
    "    for e in range(epoch):\n",
    "        for t,(x_batch, y_batch) in enumerate(dataloader):\n",
    "            i_iter +=1\n",
    "            # Forward pass: compute predicted y by passing x to the model.\n",
    "            y_pred = model(x_batch)\n",
    "#             print (\"x_batch.shape\", x_batch.shape)\n",
    "#             print (\"y_batch.shape\", y_batch.shape)\n",
    "#             print (\"y_pred.shape\", y_pred.shape)\n",
    "#             print (\"y_batch[0,0]\", y_batch[0,0])\n",
    "#             print (\"y_pred[0,0]\", y_pred[0,0])\n",
    "            y_pred_soft = torch.nn.functional.softmax(y_pred, dim = -1)\n",
    "            # Compute and print loss.\n",
    "#             batch_class_weights = torch.ones((y_batch.dim()))\n",
    "#             loss = loss_fn(y_pred_soft, y_batch, weight = batch_class_weights)\n",
    "#             loss = loss_fn(y_pred_soft, y_batch)\n",
    "#             print (y_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            if loss < min_loss:\n",
    "                print (f\"loss < min_loss, updating min_loss to {loss}, i_iter {i_iter}\")\n",
    "#                 accuracy_test(model, X_train, Y_train, data_set_name= 'train', print_sample = 0, top_n_guess= 1)\n",
    "#                 accuracy_test(model, X_test, Y_test, data_set_name= 'test', print_sample=0, top_n_guess= 1)\n",
    "                min_loss = loss\n",
    "            if not ( (t +1) % 2000 ) :\n",
    "                print(f\"iter-{t+1}, loss {round(loss.item(),3)}\")\n",
    "\n",
    "            # Before the backward pass, use the optimizer object to zero all of the\n",
    "            # gradients for the variables it will update (which are the learnable\n",
    "            # weights of the model). This is because by default, gradients are\n",
    "            # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "            # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backward pass: compute gradient of the loss with respect to model\n",
    "            # parameters\n",
    "\n",
    "            #  $$$ this command destroy exit() command $$$\n",
    "            loss.backward()\n",
    "\n",
    "            # Calling the step function on an Optimizer makes an update to its\n",
    "            # parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            scheduler.step(loss)\n",
    "            \n",
    "            \n",
    "        if not ((e+1) %10): \n",
    "            accuracy_test(model, X_train, Y_train, data_set_name= 'train', print_sample = 0, top_n_guess= 1)\n",
    "            accuracy_test(model, X_test, Y_test, data_set_name= 'test', print_sample=0, top_n_guess= 1)\n",
    "        \n",
    "#         epoch_lr = epoch_lr * lr_decay\n",
    "        print_learning_rate(optimizer)\n",
    "        print(f\"epoch-{e+1}, loss {round(loss.item(),3)}\")\n",
    "        print(\"------------------------------------\")\n",
    "        # set_learning_rate(optimizer,epoch_lr)\n",
    "        \n",
    "    print (\"DONE, returning model\")\n",
    "    return model\n",
    "\n",
    "print (\"updated torch nn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training:\n",
      "loss name is:  CrossEntropyLoss  Using loss function:  CrossEntropyLoss()\n",
      "Accuracy (top 1 guesses) - test =  3.727 %\n",
      "                                                           0\n",
      "predicted  [[2], [8], [8], [2], [8], [7], [7], [7], [8], ...\n",
      "truth                        [0, 10, 8, 0, 0, 8, 7, 1, 0, 0]\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T   2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P      3     1     1    0    0    0    0    0    0    1     0     0     0   \n",
      "1_P      0     0     0    0    0    0    0    0    0    0     0     0     0   \n",
      "2_P   1325   407   283  227  217  159  152  115  103   89    83    64    53   \n",
      "3_P      0     0     0    0    0    0    0    0    0    0     0     0     0   \n",
      "4_P      0     0     0    0    0    0    0    0    0    0     0     0     0   \n",
      "5_P      0     0     0    0    0    0    0    0    0    0     0     0     0   \n",
      "6_P      0     0     0    0    0    0    0    0    0    0     0     0     0   \n",
      "7_P   2873   866   587  518  401  321  279  225  218  214   166   121   123   \n",
      "8_P   4976  1522  1013  925  704  526  530  447  375  338   324   206   203   \n",
      "9_P      0     0     0    0    0    0    0    0    0    0     0     0     0   \n",
      "10_P     0     0     0    0    0    0    0    0    0    0     0     0     0   \n",
      "11_P    14     3     3    1    1    2    1    2    0    2     1     1     0   \n",
      "12_P     0     0     0    0    0    0    0    0    0    0     0     0     0   \n",
      "13_P   570   196   124  125   75   67   67   57   50   43    39    28    28   \n",
      "\n",
      "      13_T  \n",
      "0_P      0  \n",
      "1_P      0  \n",
      "2_P     49  \n",
      "3_P      0  \n",
      "4_P      0  \n",
      "5_P      0  \n",
      "6_P      0  \n",
      "7_P     95  \n",
      "8_P    156  \n",
      "9_P      0  \n",
      "10_P     0  \n",
      "11_P     0  \n",
      "12_P     0  \n",
      "13_P    11  \n",
      "loss < min_loss, updating min_loss to 2.6429054737091064, i_iter 0\n",
      "loss < min_loss, updating min_loss to 2.6291263103485107, i_iter 1\n",
      "loss < min_loss, updating min_loss to 2.6066956520080566, i_iter 2\n",
      "loss < min_loss, updating min_loss to 2.5815632343292236, i_iter 8\n",
      "loss < min_loss, updating min_loss to 2.560093879699707, i_iter 20\n",
      "loss < min_loss, updating min_loss to 2.539769172668457, i_iter 33\n",
      "loss < min_loss, updating min_loss to 2.491847038269043, i_iter 44\n",
      "loss < min_loss, updating min_loss to 2.43815541267395, i_iter 45\n",
      "loss < min_loss, updating min_loss to 2.4035041332244873, i_iter 57\n",
      "loss < min_loss, updating min_loss to 2.350476026535034, i_iter 86\n",
      "loss < min_loss, updating min_loss to 2.277834415435791, i_iter 102\n",
      "loss < min_loss, updating min_loss to 2.024899959564209, i_iter 143\n",
      "loss < min_loss, updating min_loss to 1.8802911043167114, i_iter 347\n",
      "loss < min_loss, updating min_loss to 1.8516196012496948, i_iter 520\n",
      "loss < min_loss, updating min_loss to 1.6237765550613403, i_iter 610\n",
      "loss < min_loss, updating min_loss to 1.6132861375808716, i_iter 669\n",
      "loss < min_loss, updating min_loss to 1.5835613012313843, i_iter 931\n",
      "loss < min_loss, updating min_loss to 1.452204942703247, i_iter 1694\n",
      "loss < min_loss, updating min_loss to 1.3981493711471558, i_iter 1844\n",
      "loss < min_loss, updating min_loss to 1.373279094696045, i_iter 1851\n",
      "loss < min_loss, updating min_loss to 1.0822731256484985, i_iter 1868\n",
      "iter-2000, loss 1.484\n",
      "loss < min_loss, updating min_loss to 1.0358258485794067, i_iter 2216\n",
      "loss < min_loss, updating min_loss to 0.8879228234291077, i_iter 2491\n",
      "lr 0.005\n",
      "epoch-1, loss 2.467\n",
      "------------------------------------\n",
      "loss < min_loss, updating min_loss to 0.7778458595275879, i_iter 4273\n",
      "loss < min_loss, updating min_loss to 0.7533672451972961, i_iter 4620\n",
      "iter-2000, loss 1.662\n",
      "loss < min_loss, updating min_loss to 0.7440057396888733, i_iter 5570\n",
      "loss < min_loss, updating min_loss to 0.6119051575660706, i_iter 6495\n",
      "lr 0.005\n",
      "epoch-2, loss 0.897\n",
      "------------------------------------\n",
      "loss < min_loss, updating min_loss to 0.5980498790740967, i_iter 6896\n",
      "loss < min_loss, updating min_loss to 0.49919864535331726, i_iter 7364\n",
      "iter-2000, loss 2.331\n",
      "lr 0.005\n",
      "epoch-3, loss 3.059\n",
      "------------------------------------\n",
      "loss < min_loss, updating min_loss to 0.47316718101501465, i_iter 10244\n",
      "iter-2000, loss 2.611\n",
      "lr 0.005\n",
      "epoch-4, loss 1.998\n",
      "------------------------------------\n",
      "iter-2000, loss 1.754\n",
      "lr 0.005\n",
      "epoch-5, loss 2.746\n",
      "------------------------------------\n",
      "loss < min_loss, updating min_loss to 0.4550187587738037, i_iter 17725\n",
      "iter-2000, loss 2.145\n",
      "lr 0.005\n",
      "epoch-6, loss 2.721\n",
      "------------------------------------\n",
      "iter-2000, loss 1.514\n",
      "lr 0.005\n",
      "epoch-7, loss 1.29\n",
      "------------------------------------\n",
      "loss < min_loss, updating min_loss to 0.434318870306015, i_iter 24731\n",
      "iter-2000, loss 1.611\n",
      "loss < min_loss, updating min_loss to 0.17045672237873077, i_iter 26463\n",
      "lr 0.005\n",
      "epoch-8, loss 0.17\n",
      "------------------------------------\n",
      "iter-2000, loss 1.284\n",
      "lr 0.005\n",
      "epoch-9, loss 0.854\n",
      "------------------------------------\n",
      "iter-2000, loss 2.119\n",
      "Accuracy (top 1 guesses) - train =  44.649 %\n",
      "\tConfusion Matrix train:\n",
      "        0_T   1_T   2_T   3_T   4_T   5_T  6_T   7_T  8_T  9_T  10_T  11_T  \\\n",
      "0_P   9500    22    46   280    86    67   18   138   30   12    18    10   \n",
      "1_P    155  3404    69    68    39    32   29     8   23   13     8    30   \n",
      "2_P    655   285  2040   545    97    37  391    40   65  155    89   321   \n",
      "3_P   1763   119   216  1349    43    46  119    58   37   20   152    28   \n",
      "4_P   3506   251   254   252  2042   167  353   291  141   63    89    67   \n",
      "5_P   1502    99    38   118    30  1657   84    53  857   15    18     2   \n",
      "6_P   1325   276   760   531   185   161  987    81  201   54   133    55   \n",
      "7_P   2008    32    28   103   100    55   15  1039   35   13    36     7   \n",
      "8_P    257   162    28    38    24   154   33    12  187   12     7     4   \n",
      "9_P    766   314   325   121   130    91   94    74   79  922    79    39   \n",
      "10_P   357    75    64   221    37    25   31    61   20   29   745    19   \n",
      "11_P   356   511   589   260    84    17  102    37   32   45    46   349   \n",
      "12_P   287   158    27    68    19    33   58    14   21   42     8     5   \n",
      "13_P   541  1184   199   187   214    47  116    63  105   96    41    45   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P     16     0  \n",
      "1_P     27    13  \n",
      "2_P     49    32  \n",
      "3_P     30     5  \n",
      "4_P     39    48  \n",
      "5_P     16     4  \n",
      "6_P     76    42  \n",
      "7_P     11     3  \n",
      "8_P     11     8  \n",
      "9_P    111    44  \n",
      "10_P     7     7  \n",
      "11_P    25    33  \n",
      "12_P   409     8  \n",
      "13_P    89   472  \n",
      "Accuracy (top 1 guesses) - test =  41.581 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   3851     6   17  113   43   31   12   69   13    4    15     4     9   \n",
      "1_P     64  1414   27   34   16   16   13    5   13   11    10    15    18   \n",
      "2_P    277   154  833  226   48   19  160   21   28   73    54   140    18   \n",
      "3_P    708    50   70  529   26   21   61   32   23   19    61    15    15   \n",
      "4_P   1495   117  139  115  890   65  134  131   63   41    53    29    28   \n",
      "5_P    635    42   18   49   19  644   53   24  314   14    16     2    20   \n",
      "6_P    584   126  319  257   93   86  360   32   94   53    42    40    34   \n",
      "7_P    922    11   13   49   44   27    7  393   19    6    13     5     9   \n",
      "8_P    126    76   12   11    6   71   20   11   53    5     5     5     3   \n",
      "9_P    367   154  142   78   63   44   56   30   38  371    28    23    54   \n",
      "10_P   172    30   33   99   16    7   20   34   11   12   268    11     6   \n",
      "11_P   186   228  253  102   38   13   53   22   15   24    18    98    11   \n",
      "12_P   157    72   12   35   10   11   17    7   17   15     8     6   135   \n",
      "13_P   217   515  123   99   86   20   63   35   45   39    22    27    47   \n",
      "\n",
      "      13_T  \n",
      "0_P      1  \n",
      "1_P      8  \n",
      "2_P     18  \n",
      "3_P      3  \n",
      "4_P     23  \n",
      "5_P      3  \n",
      "6_P     19  \n",
      "7_P      6  \n",
      "8_P      9  \n",
      "9_P     19  \n",
      "10_P     1  \n",
      "11_P    12  \n",
      "12_P     9  \n",
      "13_P   180  \n",
      "lr 0.005\n",
      "epoch-10, loss 2.934\n",
      "------------------------------------\n",
      "iter-2000, loss 2.395\n",
      "lr 0.005\n",
      "epoch-11, loss 0.467\n",
      "------------------------------------\n",
      "Epoch 36464: reducing learning rate of group 0 to 4.5000e-03.\n",
      "iter-2000, loss 1.211\n",
      "lr 0.0045000000000000005\n",
      "epoch-12, loss 0.56\n",
      "------------------------------------\n",
      "iter-2000, loss 2.279\n",
      "lr 0.0045000000000000005\n",
      "epoch-13, loss 3.329\n",
      "------------------------------------\n",
      "iter-2000, loss 2.248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.0045000000000000005\n",
      "epoch-14, loss 2.218\n",
      "------------------------------------\n",
      "iter-2000, loss 2.375\n",
      "Epoch 48465: reducing learning rate of group 0 to 4.0500e-03.\n",
      "lr 0.004050000000000001\n",
      "epoch-15, loss 1.192\n",
      "------------------------------------\n",
      "iter-2000, loss 1.321\n",
      "lr 0.004050000000000001\n",
      "epoch-16, loss 1.421\n",
      "------------------------------------\n",
      "iter-2000, loss 1.371\n",
      "lr 0.004050000000000001\n",
      "epoch-17, loss 3.455\n",
      "------------------------------------\n",
      "iter-2000, loss 1.298\n",
      "lr 0.004050000000000001\n",
      "epoch-18, loss 0.368\n",
      "------------------------------------\n",
      "Epoch 60466: reducing learning rate of group 0 to 3.6450e-03.\n",
      "iter-2000, loss 1.557\n",
      "lr 0.0036450000000000007\n",
      "epoch-19, loss 0.286\n",
      "------------------------------------\n",
      "iter-2000, loss 1.328\n",
      "Accuracy (top 1 guesses) - train =  46.762 %\n",
      "\tConfusion Matrix train:\n",
      "        0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T  8_T  9_T  10_T  11_T  \\\n",
      "0_P   9613     5    34   168   100    58    21   149   16    5    13     1   \n",
      "1_P    294  4418   150   120    78    53    59    25   57   40    26    55   \n",
      "2_P    391    88  1311   252    49    15   208    22   34  110    42    89   \n",
      "3_P   2423   176   250  1717    86    32   119    59   29   20   155    36   \n",
      "4_P   1568    86    75    85  1693    44    95    80   56   14    26    17   \n",
      "5_P    922    36    14    40    18  1073    33    32  500    5     8     1   \n",
      "6_P   1627   214   747   424   316   242  1209    59  203   59    79    54   \n",
      "7_P   2076    41    58    84   154    39    31  1216   28   14    55    15   \n",
      "8_P   1432   207    71   171    57   847    90    64  659   38    22    12   \n",
      "9_P    546   134   227    86   111    39    54    52   27  871    40    11   \n",
      "10_P   318   113   105   303    69    19    68    74   17   43   884    19   \n",
      "11_P   900   699  1475   499   230    47   272    68  106  144    85   648   \n",
      "12_P   584   237    69   113    48    61    99    35   43   90    15     6   \n",
      "13_P   284   438    97    79   121    20    72    34   58   38    19    17   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      8     2  \n",
      "1_P     57    63  \n",
      "2_P     21     7  \n",
      "3_P     26     6  \n",
      "4_P     16    26  \n",
      "5_P      6     0  \n",
      "6_P     46    27  \n",
      "7_P      6     3  \n",
      "8_P     24     6  \n",
      "9_P     77    28  \n",
      "10_P    10    12  \n",
      "11_P    55    68  \n",
      "12_P   524    17  \n",
      "13_P    40   454  \n",
      "Accuracy (top 1 guesses) - test =  42.922 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   3929     3   18   82   52   24    7   68   15    2    10     2     6   \n",
      "1_P    136  1811   79   72   37   29   35   11   24   25    22    24    38   \n",
      "2_P    163    58  467  102   20    7   83   19   13   47    25    49     7   \n",
      "3_P   1052    91  120  650   41   16   62   36   23   14    66    12    18   \n",
      "4_P    723    36   32   49  716   28   45   45   14   24    17     9    13   \n",
      "5_P    350    21    9   20    8  447   17   13  185    1     9     0     4   \n",
      "6_P    702    91  327  202  148  102  449   36   98   55    33    36    32   \n",
      "7_P    902    18   18   42   67   16   14  457   16    9    24     3     8   \n",
      "8_P    636    95   36   57   30  308   63   27  228   26    16     8    23   \n",
      "9_P    213    77  106   50   45   21   26   15   26  335    16    18    28   \n",
      "10_P   158    43   58  139   29    8   26   33   13   19   299    10     7   \n",
      "11_P   410   321  647  218  127   31  146   43   45   67    61   218    31   \n",
      "12_P   259   128   34   61   29   24   35   16   21   40     7    13   176   \n",
      "13_P   128   202   60   52   49   14   21   27   25   23     8    18    16   \n",
      "\n",
      "      13_T  \n",
      "0_P      0  \n",
      "1_P     21  \n",
      "2_P      3  \n",
      "3_P      4  \n",
      "4_P     12  \n",
      "5_P      1  \n",
      "6_P     17  \n",
      "7_P      8  \n",
      "8_P     13  \n",
      "9_P     18  \n",
      "10_P     6  \n",
      "11_P    30  \n",
      "12_P    18  \n",
      "13_P   160  \n",
      "lr 0.0036450000000000007\n",
      "epoch-20, loss 2.892\n",
      "------------------------------------\n",
      "iter-2000, loss 1.248\n",
      "lr 0.0036450000000000007\n",
      "epoch-21, loss 1.247\n",
      "------------------------------------\n",
      "iter-2000, loss 1.81\n",
      "Epoch 72467: reducing learning rate of group 0 to 3.2805e-03.\n",
      "lr 0.003280500000000001\n",
      "epoch-22, loss 1.979\n",
      "------------------------------------\n",
      "iter-2000, loss 2.416\n",
      "lr 0.003280500000000001\n",
      "epoch-23, loss 2.775\n",
      "------------------------------------\n",
      "iter-2000, loss 2.306\n",
      "lr 0.003280500000000001\n",
      "epoch-24, loss 0.93\n",
      "------------------------------------\n",
      "iter-2000, loss 1.628\n",
      "lr 0.003280500000000001\n",
      "epoch-25, loss 1.344\n",
      "------------------------------------\n",
      "Epoch 84468: reducing learning rate of group 0 to 2.9525e-03.\n",
      "iter-2000, loss 1.827\n",
      "lr 0.002952450000000001\n",
      "epoch-26, loss 2.359\n",
      "------------------------------------\n",
      "iter-2000, loss 1.183\n",
      "lr 0.002952450000000001\n",
      "epoch-27, loss 0.833\n",
      "------------------------------------\n",
      "iter-2000, loss 1.808\n",
      "lr 0.002952450000000001\n",
      "epoch-28, loss 1.913\n",
      "------------------------------------\n",
      "iter-2000, loss 2.008\n",
      "loss < min_loss, updating min_loss to 0.06961829960346222, i_iter 95931\n",
      "lr 0.002952450000000001\n",
      "epoch-29, loss 0.07\n",
      "------------------------------------\n",
      "iter-2000, loss 0.861\n",
      "Accuracy (top 1 guesses) - train =  48.316 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T  6_T   7_T  8_T   9_T  10_T  11_T  \\\n",
      "0_P   10742    20    50   258   112    97   30   131   31     2     5     4   \n",
      "1_P     217  4087   108   115    50    47   43    10   50    24    20    40   \n",
      "2_P     219    55  1151   153    16     8  144    14   22    45    19    60   \n",
      "3_P    1539   142   286  1687    40    40  151    37   35    21    75    33   \n",
      "4_P    1391    79    83    77  1705    36  106    69   36    16    14    10   \n",
      "5_P     749    22    16    40    30  1011   32    20  407     1     4     0   \n",
      "6_P     728    86   473   170   142    73  876    28   77    23    31    19   \n",
      "7_P    3032    76   120   154   202    88   63  1323   40    25    60    26   \n",
      "8_P    1317   241   101   150   111   911  179    50  802    27    29     4   \n",
      "9_P     593   270   485   171   144    70  102    61   47  1026    87    39   \n",
      "10_P    542   133   141   456    92    56   83    82   34    29   993    28   \n",
      "11_P    554   505  1254   317   174    27  242    40   53    59    50   641   \n",
      "12_P    727   324   153   192    73    86  185    33   77   102    29    21   \n",
      "13_P    628   852   262   201   239    39  194    71  122    91    53    56   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      9     1  \n",
      "1_P     42    30  \n",
      "2_P      7     2  \n",
      "3_P     17     6  \n",
      "4_P     12    23  \n",
      "5_P      0     1  \n",
      "6_P     11     9  \n",
      "7_P     17     5  \n",
      "8_P     23     4  \n",
      "9_P     88    34  \n",
      "10_P    12     4  \n",
      "11_P    28    30  \n",
      "12_P   572    22  \n",
      "13_P    78   548  \n",
      "Accuracy (top 1 guesses) - test =  43.897 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   4369     4   20  116   51   33   16   61   13    2    11     1     8   \n",
      "1_P    102  1677   58   45   35   26   33   12   23   21    10    19    26   \n",
      "2_P     83    29  430   52   12   10   59    5    7   19    11    31     3   \n",
      "3_P    683    80  132  637   26   19   73   29   26   19    36    15    19   \n",
      "4_P    609    45   45   45  682   11   60   44   14   23    13    16    14   \n",
      "5_P    332    13    7   17    9  394   21   11  136    2     9     0     0   \n",
      "6_P    273    35  184   97   86   34  293   19   33   17    12    13    14   \n",
      "7_P   1342    28   52   75  113   40   31  489   25   22    32     8     9   \n",
      "8_P    597   123   55   72   53  392  103   22  299   22    23     6    19   \n",
      "9_P    245   138  212   90   62   26   36   26   30  382    26    37    40   \n",
      "10_P   271    61   75  198   34   18   50   36   21   18   347    16     6   \n",
      "11_P   257   232  526  161   85   24  104   22   26   44    38   201    15   \n",
      "12_P   324   188   65   83   32   22   64   22   38   54    14    15   190   \n",
      "13_P   274   342  150  108  118   26   86   48   55   42    31    42    44   \n",
      "\n",
      "      13_T  \n",
      "0_P      0  \n",
      "1_P     20  \n",
      "2_P      3  \n",
      "3_P      3  \n",
      "4_P     13  \n",
      "5_P      0  \n",
      "6_P      7  \n",
      "7_P      7  \n",
      "8_P     15  \n",
      "9_P     25  \n",
      "10_P     3  \n",
      "11_P    13  \n",
      "12_P    15  \n",
      "13_P   187  \n",
      "lr 0.002952450000000001\n",
      "epoch-30, loss 2.73\n",
      "------------------------------------\n",
      "iter-2000, loss 1.018\n",
      "lr 0.002952450000000001\n",
      "epoch-31, loss 0.42\n",
      "------------------------------------\n",
      "iter-2000, loss 1.163\n",
      "lr 0.002952450000000001\n",
      "epoch-32, loss 2.723\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105932: reducing learning rate of group 0 to 2.6572e-03.\n",
      "iter-2000, loss 1.71\n",
      "lr 0.002657205000000001\n",
      "epoch-33, loss 0.16\n",
      "------------------------------------\n",
      "iter-2000, loss 1.699\n",
      "lr 0.002657205000000001\n",
      "epoch-34, loss 1.967\n",
      "------------------------------------\n",
      "iter-2000, loss 1.568\n",
      "lr 0.002657205000000001\n",
      "epoch-35, loss 1.553\n",
      "------------------------------------\n",
      "iter-2000, loss 1.282\n",
      "Epoch 117933: reducing learning rate of group 0 to 2.3915e-03.\n",
      "lr 0.002391484500000001\n",
      "epoch-36, loss 1.224\n",
      "------------------------------------\n",
      "iter-2000, loss 1.468\n",
      "lr 0.002391484500000001\n",
      "epoch-37, loss 0.546\n",
      "------------------------------------\n",
      "iter-2000, loss 1.336\n",
      "lr 0.002391484500000001\n",
      "epoch-38, loss 1.728\n",
      "------------------------------------\n",
      "iter-2000, loss 0.974\n",
      "lr 0.002391484500000001\n",
      "epoch-39, loss 0.274\n",
      "------------------------------------\n",
      "Epoch 129934: reducing learning rate of group 0 to 2.1523e-03.\n",
      "iter-2000, loss 1.042\n",
      "Accuracy (top 1 guesses) - train =  45.961 %\n",
      "\tConfusion Matrix train:\n",
      "        0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T  8_T  9_T  10_T  11_T  \\\n",
      "0_P   8104     3    21   103    31    29     5    56    8    3     3     0   \n",
      "1_P    287  4439   121   142    69    36    50    21   44   33    21    35   \n",
      "2_P    288    49  1363   217    16    14   177    16   21   47    21    64   \n",
      "3_P   2117    83   161  1633    43    29   106    48   28   16    63    12   \n",
      "4_P   2380   131   110   136  1966    68   194   105   66   38    30    12   \n",
      "5_P   1260    21    19    44    23  1227    33    31  434    6     2     0   \n",
      "6_P    880   112   541   273   142   108  1055    35  121   26    44    26   \n",
      "7_P   3818    43    90   111   177    89    41  1350   30   18    30    16   \n",
      "8_P   1218   331   105   166    67   798   139    50  845   42    38     7   \n",
      "9_P    452   152   297   105    94    49    65    40   35  979    42    15   \n",
      "10_P   539   182   188   551    86    50    97    87   35   54  1069    34   \n",
      "11_P   807   638  1466   465   243    38   277    68   65   97    68   722   \n",
      "12_P   426   192    48    79    23    40    90    19   28   81    13     5   \n",
      "13_P   402   516   153   116   150    14   101    43   73   51    25    33   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      5     0  \n",
      "1_P     43    36  \n",
      "2_P     10     2  \n",
      "3_P     19     4  \n",
      "4_P     32    21  \n",
      "5_P      3     0  \n",
      "6_P     22    11  \n",
      "7_P      8     3  \n",
      "8_P     32    11  \n",
      "9_P     68    26  \n",
      "10_P    16     7  \n",
      "11_P    51    54  \n",
      "12_P   560    16  \n",
      "13_P    47   528  \n",
      "Accuracy (top 1 guesses) - test =  41.042 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   3280     2   11   42   24   17    6   34    8    2     5     1     3   \n",
      "1_P    112  1834   59   74   34   26   32   10   22   15    12    18    33   \n",
      "2_P    131    30  496   77   12    5   69    4    6   30    13    37     5   \n",
      "3_P    899    39   83  587   24   16   46   38   23   13    33    13    21   \n",
      "4_P   1033    64   57   95  795   24   76   68   26   29    17    19    14   \n",
      "5_P    540    14   10   18   17  467   23   17  163    2    12     0     8   \n",
      "6_P    391    42  243  127   73   59  367   22   50   31    12    27    18   \n",
      "7_P   1658    23   30   72   94   37   21  495   23   21    26     6     8   \n",
      "8_P    527   136   56   82   38  321   82   24  280   34    21     8    22   \n",
      "9_P    198    92  156   55   41   26   32   17   26  350    22    16    40   \n",
      "10_P   272   100   88  238   37   20   58   46   25   32   368    16    13   \n",
      "11_P   372   273  605  212  117   23  133   31   33   57    50   228    28   \n",
      "12_P   193   110   37   47   13   15   34   10   23   45    10    10   176   \n",
      "13_P   155   236   80   70   79   19   50   30   38   26    12    21    18   \n",
      "\n",
      "      13_T  \n",
      "0_P      0  \n",
      "1_P     24  \n",
      "2_P      0  \n",
      "3_P      4  \n",
      "4_P     19  \n",
      "5_P      2  \n",
      "6_P      9  \n",
      "7_P      9  \n",
      "8_P     13  \n",
      "9_P     18  \n",
      "10_P     6  \n",
      "11_P    21  \n",
      "12_P    20  \n",
      "13_P   166  \n",
      "lr 0.002152336050000001\n",
      "epoch-40, loss 2.56\n",
      "------------------------------------\n",
      "iter-2000, loss 2.025\n",
      "lr 0.002152336050000001\n",
      "epoch-41, loss 2.526\n",
      "------------------------------------\n",
      "iter-2000, loss 1.669\n",
      "lr 0.002152336050000001\n",
      "epoch-42, loss 2.253\n",
      "------------------------------------\n",
      "iter-2000, loss 2.18\n",
      "Epoch 141935: reducing learning rate of group 0 to 1.9371e-03.\n",
      "lr 0.001937102445000001\n",
      "epoch-43, loss 1.564\n",
      "------------------------------------\n",
      "iter-2000, loss 0.636\n",
      "lr 0.001937102445000001\n",
      "epoch-44, loss 1.303\n",
      "------------------------------------\n",
      "iter-2000, loss 1.155\n",
      "lr 0.001937102445000001\n",
      "epoch-45, loss 0.072\n",
      "------------------------------------\n",
      "iter-2000, loss 2.544\n",
      "lr 0.001937102445000001\n",
      "epoch-46, loss 0.915\n",
      "------------------------------------\n",
      "Epoch 153936: reducing learning rate of group 0 to 1.7434e-03.\n",
      "iter-2000, loss 2.481\n",
      "lr 0.001743392200500001\n",
      "epoch-47, loss 0.622\n",
      "------------------------------------\n",
      "iter-2000, loss 1.693\n",
      "lr 0.001743392200500001\n",
      "epoch-48, loss 1.257\n",
      "------------------------------------\n",
      "iter-2000, loss 0.584\n",
      "lr 0.001743392200500001\n",
      "epoch-49, loss 2.17\n",
      "------------------------------------\n",
      "iter-2000, loss 0.944\n",
      "Accuracy (top 1 guesses) - train =  48.539 %\n",
      "\tConfusion Matrix train:\n",
      "        0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T  8_T   9_T  10_T  11_T  \\\n",
      "0_P   8578     7    23   126    56    52    10    59    6     4     4     3   \n",
      "1_P    196  4303    93    97    53    35    36     4   27    17    13    27   \n",
      "2_P    553   170  2225   389    64    34   381    30   41   103    45   163   \n",
      "3_P   2550   102   211  1794    84    34   129    44   36    16    61    16   \n",
      "4_P   1567    89    70    57  1812    36    85    54   37    30    15    16   \n",
      "5_P    994    17    22    33    23  1242    49    21  324     2     6     0   \n",
      "6_P    916   135   356   206   201   108  1060    50   89    17    38    25   \n",
      "7_P   3729    72   109   102   217    74    43  1401   32    14    27    12   \n",
      "8_P   1428   262    81   167    88   768   121    51  990    33    18    12   \n",
      "9_P    477   191   288   122    91    75    64    38   49  1033    51    13   \n",
      "10_P   652   169   146   559   119    48   117   102   50    45  1112    29   \n",
      "11_P   464   540   875   299   156    20   152    44   50    63    47   628   \n",
      "12_P   539   260    68    91    45    45   105    32   33    73    16    10   \n",
      "13_P   335   575   116    99   121    18    78    39   69    41    16    27   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      2     1  \n",
      "1_P     35    24  \n",
      "2_P     15    10  \n",
      "3_P     23     5  \n",
      "4_P     17    28  \n",
      "5_P      6     0  \n",
      "6_P     14    19  \n",
      "7_P     15     5  \n",
      "8_P     22     8  \n",
      "9_P     81    28  \n",
      "10_P    17    11  \n",
      "11_P    31    37  \n",
      "12_P   586    18  \n",
      "13_P    52   525  \n",
      "Accuracy (top 1 guesses) - test =  42.768 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   3463     3   17   55   33   19    6   39    3    1    12     2     6   \n",
      "1_P     87  1744   40   53   26   18   19    9   16   13    15    13    27   \n",
      "2_P    237    84  827  191   42   21  132   21   18   65    34    85    16   \n",
      "3_P   1082    45   95  628   32   23   65   40   26   15    35    14    19   \n",
      "4_P    681    51   46   50  735   14   45   37   14   28    13    14    18   \n",
      "5_P    418    14   11   19    5  468   22   15  135    7     4     0     8   \n",
      "6_P    368    58  155  104  116   50  361   28   53   24    21    28    17   \n",
      "7_P   1632    32   33   64  101   42   31  506   28   17    23    10     7   \n",
      "8_P    627   134   41   82   40  315   85   23  322   18    21     8    23   \n",
      "9_P    215   105  148   68   46   32   37   20   30  363    25    29    38   \n",
      "10_P   327    79  108  241   56   20   56   55   24   26   366    15    16   \n",
      "11_P   232   263  371  136   60   18   88   18   26   45    29   170    12   \n",
      "12_P   258   142   42   40   39   20   40   12   27   41     7    12   177   \n",
      "13_P   134   241   77   65   67   15   42   23   24   24     8    20    23   \n",
      "\n",
      "      13_T  \n",
      "0_P      0  \n",
      "1_P     18  \n",
      "2_P      5  \n",
      "3_P      6  \n",
      "4_P     17  \n",
      "5_P      1  \n",
      "6_P     13  \n",
      "7_P     11  \n",
      "8_P     15  \n",
      "9_P     14  \n",
      "10_P     8  \n",
      "11_P     9  \n",
      "12_P    19  \n",
      "13_P   175  \n",
      "lr 0.001743392200500001\n",
      "epoch-50, loss 2.068\n",
      "------------------------------------\n",
      "Epoch 165937: reducing learning rate of group 0 to 1.5691e-03.\n",
      "iter-2000, loss 1.326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.001569052980450001\n",
      "epoch-51, loss 2.045\n",
      "------------------------------------\n",
      "iter-2000, loss 0.929\n",
      "lr 0.001569052980450001\n",
      "epoch-52, loss 0.658\n",
      "------------------------------------\n",
      "iter-2000, loss 1.294\n",
      "lr 0.001569052980450001\n",
      "epoch-53, loss 3.155\n",
      "------------------------------------\n",
      "iter-2000, loss 0.705\n",
      "Epoch 177938: reducing learning rate of group 0 to 1.4121e-03.\n",
      "lr 0.0014121476824050009\n",
      "epoch-54, loss 1.722\n",
      "------------------------------------\n",
      "iter-2000, loss 1.463\n",
      "lr 0.0014121476824050009\n",
      "epoch-55, loss 1.093\n",
      "------------------------------------\n",
      "iter-2000, loss 1.603\n",
      "lr 0.0014121476824050009\n",
      "epoch-56, loss 1.296\n",
      "------------------------------------\n",
      "iter-2000, loss 1.805\n",
      "lr 0.0014121476824050009\n",
      "epoch-57, loss 1.139\n",
      "------------------------------------\n",
      "Epoch 189939: reducing learning rate of group 0 to 1.2709e-03.\n",
      "iter-2000, loss 2.254\n",
      "lr 0.0012709329141645008\n",
      "epoch-58, loss 1.713\n",
      "------------------------------------\n",
      "iter-2000, loss 0.69\n",
      "lr 0.0012709329141645008\n",
      "epoch-59, loss 1.586\n",
      "------------------------------------\n",
      "iter-2000, loss 2.184\n",
      "Accuracy (top 1 guesses) - train =  49.72 %\n",
      "\tConfusion Matrix train:\n",
      "        0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T  8_T   9_T  10_T  11_T  \\\n",
      "0_P   9003     6    33   128    53    39    10    54    3     1     5     1   \n",
      "1_P    263  4448   137   133    50    34    54    17   44    22    19    40   \n",
      "2_P    299    66  1647   201    26    16   200    19   21    49    24    80   \n",
      "3_P   2192    98   242  1822    45    21   129    36   32    11    52    20   \n",
      "4_P   2036   131    91    92  2073    58   135   105   57    33    33     9   \n",
      "5_P   1180    48    22    44    18  1398    30    25  379     3     3     0   \n",
      "6_P    911   109   417   256   131   101  1150    40  106    17    30    20   \n",
      "7_P   3230    41    88    99   167    78    30  1395   19     9    28     7   \n",
      "8_P   1066   176    60   139    55   608    99    29  900    20    14     3   \n",
      "9_P    508   173   325   121    76    83    62    46   48  1056    60    10   \n",
      "10_P   496   136   153   447    62    39    81    62   31    38  1101    15   \n",
      "11_P   560   419  1159   346   162    24   186    52   46    67    49   732   \n",
      "12_P   781   384   141   169    57    62   136    43   48   105    23    14   \n",
      "13_P   453   657   168   144   155    28   128    46   99    60    28    30   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      7     0  \n",
      "1_P     30    16  \n",
      "2_P      9     4  \n",
      "3_P     16     1  \n",
      "4_P     18    21  \n",
      "5_P      1     0  \n",
      "6_P     12     8  \n",
      "7_P      5     2  \n",
      "8_P     18     3  \n",
      "9_P     60    21  \n",
      "10_P     6     6  \n",
      "11_P    21    34  \n",
      "12_P   644    19  \n",
      "13_P    69   584  \n",
      "Accuracy (top 1 guesses) - test =  43.382 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   3642     1   17   65   35   14   12   38    4    1     9     2     4   \n",
      "1_P    111  1824   80   64   37   25   30   16   21   17    16    21    30   \n",
      "2_P    134    36  609   80   16    8   68   17    9   41    18    38     5   \n",
      "3_P    936    39  102  658   32   19   64   32   24    6    25    16    22   \n",
      "4_P    888    61   57   69  801   28   73   62   14   29    28    22    20   \n",
      "5_P    522    23   12   27   15  522   20   13  153   11    15     2     9   \n",
      "6_P    349    49  181  142   78   69  374   21   57   25    16    24    16   \n",
      "7_P   1424    23   26   59   85   34   22  486   24   13    21     5     5   \n",
      "8_P    477   101   37   54   26  246   66   22  267   15    15     9    12   \n",
      "9_P    249    87  162   76   55   35   37   26   28  356    22    22    37   \n",
      "10_P   234    64   79  197   37   15   42   31   19   34   346    14    11   \n",
      "11_P   247   214  467  132   71   15   97   30   34   43    42   194    17   \n",
      "12_P   350   184   83   93   27   28   63   21   39   58    15    22   198   \n",
      "13_P   198   289   99   80   83   17   61   31   53   38    25    29    21   \n",
      "\n",
      "      13_T  \n",
      "0_P      0  \n",
      "1_P     18  \n",
      "2_P      4  \n",
      "3_P      2  \n",
      "4_P     21  \n",
      "5_P      1  \n",
      "6_P      9  \n",
      "7_P     11  \n",
      "8_P     11  \n",
      "9_P     17  \n",
      "10_P     7  \n",
      "11_P    15  \n",
      "12_P    19  \n",
      "13_P   176  \n",
      "lr 0.0012709329141645008\n",
      "epoch-60, loss 0.321\n",
      "------------------------------------\n",
      "iter-2000, loss 1.254\n",
      "lr 0.0012709329141645008\n",
      "epoch-61, loss 0.178\n",
      "------------------------------------\n",
      "Epoch 201940: reducing learning rate of group 0 to 1.1438e-03.\n",
      "iter-2000, loss 1.838\n",
      "lr 0.0011438396227480508\n",
      "epoch-62, loss 3.627\n",
      "------------------------------------\n",
      "iter-2000, loss 2.273\n",
      "lr 0.0011438396227480508\n",
      "epoch-63, loss 2.374\n",
      "------------------------------------\n",
      "iter-2000, loss 1.782\n",
      "lr 0.0011438396227480508\n",
      "epoch-64, loss 2.09\n",
      "------------------------------------\n",
      "iter-2000, loss 1.625\n",
      "Epoch 213941: reducing learning rate of group 0 to 1.0295e-03.\n",
      "lr 0.0010294556604732458\n",
      "epoch-65, loss 0.095\n",
      "------------------------------------\n",
      "iter-2000, loss 1.253\n",
      "lr 0.0010294556604732458\n",
      "epoch-66, loss 1.635\n",
      "------------------------------------\n",
      "iter-2000, loss 1.634\n",
      "lr 0.0010294556604732458\n",
      "epoch-67, loss 1.305\n",
      "------------------------------------\n",
      "iter-2000, loss 0.826\n",
      "lr 0.0010294556604732458\n",
      "epoch-68, loss 0.537\n",
      "------------------------------------\n",
      "Epoch 225942: reducing learning rate of group 0 to 9.2651e-04.\n",
      "iter-2000, loss 1.082\n",
      "lr 0.0009265100944259213\n",
      "epoch-69, loss 1.181\n",
      "------------------------------------\n",
      "iter-2000, loss 1.449\n",
      "Accuracy (top 1 guesses) - train =  51.737 %\n",
      "\tConfusion Matrix train:\n",
      "        0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   9185     9    24   119    48    46    10    67     6     1     2     3   \n",
      "1_P    186  4430    81    90    39    35    38    10    25     7     8    18   \n",
      "2_P    349    99  1963   262    35    18   196    17    17    63    24    94   \n",
      "3_P   2561   150   249  2028    50    47   142    51    41    23    76    13   \n",
      "4_P   2017   113    99    97  2110    53   101    83    46    37    22     8   \n",
      "5_P    989    26    12    23    16  1291    22    18   225     0     2     0   \n",
      "6_P    998   152   544   249   188   105  1328    41   124    19    36    23   \n",
      "7_P   3108    45    69   100   152    57    29  1419    17    14    27     7   \n",
      "8_P   1245   210    72   135    60   777   107    40  1111    30    24     5   \n",
      "9_P    400   146   292    96    69    42    51    35    34  1079    36     8   \n",
      "10_P   441   154   131   437    64    38    86    83    33    31  1132    14   \n",
      "11_P   509   472   936   263   110    21   125    46    44    48    42   753   \n",
      "12_P   597   302    68   114    48    39    77    21    29    82    14     8   \n",
      "13_P   393   584   143   128   141    20   118    38    81    57    24    27   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      3     0  \n",
      "1_P     30    14  \n",
      "2_P      6     3  \n",
      "3_P     24     3  \n",
      "4_P     16    24  \n",
      "5_P      5     0  \n",
      "6_P     16    13  \n",
      "7_P      2     1  \n",
      "8_P     11     7  \n",
      "9_P     62    17  \n",
      "10_P     5     8  \n",
      "11_P    13    24  \n",
      "12_P   664    11  \n",
      "13_P    59   594  \n",
      "Accuracy (top 1 guesses) - test =  43.752 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   3696     5   19   70   32   28   10   56    8    2     7     3     5   \n",
      "1_P     84  1742   48   38   36   24   23    7   22   10    10    16    29   \n",
      "2_P    168    48  697  101   23   11   92   15    9   47    21    59     5   \n",
      "3_P   1076    69  117  720   33   22   69   33   29   21    41    18    26   \n",
      "4_P    887    53   55   63  802   20   59   62   23   30    18    18    18   \n",
      "5_P    426    29    9    9    9  430   18   13  117    3     9     0     7   \n",
      "6_P    411    64  242  147  106   70  413   27   61   38    20    37    24   \n",
      "7_P   1384    27   23   56   83   27   23  476   18   10    20     5     7   \n",
      "8_P    535   118   36   78   32  349   65   21  321   24    22     7    19   \n",
      "9_P    176    85  145   50   39   30   38   18   27  348    21    26    35   \n",
      "10_P   233    84   81  194   44   14   48   46   23   25   362    15    13   \n",
      "11_P   243   235  394  142   61   17   70   30   27   41    38   180    14   \n",
      "12_P   266   171   49   55   27   16   43   11   25   52    12    10   185   \n",
      "13_P   176   265   96   73   71   17   58   31   36   36    12    26    20   \n",
      "\n",
      "      13_T  \n",
      "0_P      0  \n",
      "1_P     19  \n",
      "2_P      5  \n",
      "3_P      7  \n",
      "4_P     19  \n",
      "5_P      3  \n",
      "6_P     12  \n",
      "7_P      9  \n",
      "8_P     11  \n",
      "9_P     13  \n",
      "10_P     9  \n",
      "11_P    16  \n",
      "12_P    18  \n",
      "13_P   170  \n",
      "lr 0.0009265100944259213\n",
      "epoch-70, loss 1.156\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter-2000, loss 1.692\n",
      "lr 0.0009265100944259213\n",
      "epoch-71, loss 2.073\n",
      "------------------------------------\n",
      "iter-2000, loss 1.732\n",
      "Epoch 237943: reducing learning rate of group 0 to 8.3386e-04.\n",
      "lr 0.0008338590849833291\n",
      "epoch-72, loss 3.395\n",
      "------------------------------------\n",
      "iter-2000, loss 0.866\n",
      "lr 0.0008338590849833291\n",
      "epoch-73, loss 3.385\n",
      "------------------------------------\n",
      "iter-2000, loss 1.187\n",
      "lr 0.0008338590849833291\n",
      "epoch-74, loss 1.269\n",
      "------------------------------------\n",
      "iter-2000, loss 1.179\n",
      "lr 0.0008338590849833291\n",
      "epoch-75, loss 0.817\n",
      "------------------------------------\n",
      "Epoch 249944: reducing learning rate of group 0 to 7.5047e-04.\n",
      "iter-2000, loss 1.507\n",
      "lr 0.0007504731764849962\n",
      "epoch-76, loss 1.985\n",
      "------------------------------------\n",
      "iter-2000, loss 0.44\n",
      "lr 0.0007504731764849962\n",
      "epoch-77, loss 1.272\n",
      "------------------------------------\n",
      "iter-2000, loss 1.381\n",
      "lr 0.0007504731764849962\n",
      "epoch-78, loss 0.924\n",
      "------------------------------------\n",
      "iter-2000, loss 1.678\n",
      "lr 0.0007504731764849962\n",
      "epoch-79, loss 1.381\n",
      "------------------------------------\n",
      "Epoch 261945: reducing learning rate of group 0 to 6.7543e-04.\n",
      "iter-2000, loss 1.986\n",
      "Accuracy (top 1 guesses) - train =  53.082 %\n",
      "\tConfusion Matrix train:\n",
      "        0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   9098     9    24    96    40    47     5    41     4     0     3     0   \n",
      "1_P    259  4630    95   124    54    36    53     9    33    13     3    20   \n",
      "2_P    368    84  1891   255    30    20   184    12    23    34    20    60   \n",
      "3_P   2412   117   216  2034    47    33   130    36    36     9    48     6   \n",
      "4_P   1893    74    91    82  2151    41    92    78    48    13    19     6   \n",
      "5_P   1154    33    19    34    13  1540    21    21   257     3     0     0   \n",
      "6_P    798   134   388   208   125    86  1338    34    93    15    23     4   \n",
      "7_P   3313    36    87   101   148    71    30  1481    26    12    18     8   \n",
      "8_P    950   156    54   103    58   551    83    27  1090    11    12     3   \n",
      "9_P    559   182   366   137    98    61    67    51    56  1213    59    17   \n",
      "10_P   479   150   137   472    57    29    67    63    32    29  1206     4   \n",
      "11_P   616   432  1107   269   134    17   135    47    27    27    22   822   \n",
      "12_P   700   333    78   122    55    41   109    29    26    74    17     9   \n",
      "13_P   379   522   130   104   120    16   116    40    82    38    19    22   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      2     0  \n",
      "1_P     28    27  \n",
      "2_P      3     1  \n",
      "3_P      9     1  \n",
      "4_P      7     8  \n",
      "5_P      0     0  \n",
      "6_P      7     3  \n",
      "7_P      3     0  \n",
      "8_P      2     4  \n",
      "9_P     74    25  \n",
      "10_P     6     1  \n",
      "11_P    10    15  \n",
      "12_P   725    10  \n",
      "13_P    40   624  \n",
      "Accuracy (top 1 guesses) - test =  43.511 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   3587     5   12   62   29   18   10   40    6    1     5     2    11   \n",
      "1_P    107  1831   63   59   32   23   32   13   16   15    15    24    28   \n",
      "2_P    183    36  635  113   21   15   81    9    8   41    19    53     8   \n",
      "3_P   1057    50  117  690   39   25   60   43   24   18    37    16    18   \n",
      "4_P    818    49   60   67  794   18   60   58   21   27    17    21    12   \n",
      "5_P    486    31   10   30   14  503   22   15  144    8    15     0     6   \n",
      "6_P    361    55  194  106   78   57  397   21   50   17    19    20    19   \n",
      "7_P   1524    23   34   65   91   34   24  484   30   10    29     3    10   \n",
      "8_P    434    82   29   49   26  267   64   13  292   13    13     7    17   \n",
      "9_P    250   107  202   88   57   42   57   30   27  381    28    34    46   \n",
      "10_P   224    71   94  182   50   16   44   40   21   29   353    14    12   \n",
      "11_P   272   233  417  147   68   12   74   34   29   44    37   188    13   \n",
      "12_P   283   177   58   65   38   27   45   17   34   49    11    11   184   \n",
      "13_P   175   245   86   73   61   18   59   29   44   34    15    27    23   \n",
      "\n",
      "      13_T  \n",
      "0_P      0  \n",
      "1_P     24  \n",
      "2_P      5  \n",
      "3_P      5  \n",
      "4_P     20  \n",
      "5_P      2  \n",
      "6_P      7  \n",
      "7_P     10  \n",
      "8_P     11  \n",
      "9_P     17  \n",
      "10_P    10  \n",
      "11_P    14  \n",
      "12_P    21  \n",
      "13_P   165  \n",
      "lr 0.0006754258588364966\n",
      "epoch-80, loss 0.329\n",
      "------------------------------------\n",
      "iter-2000, loss 1.468\n",
      "lr 0.0006754258588364966\n",
      "epoch-81, loss 0.662\n",
      "------------------------------------\n",
      "iter-2000, loss 1.383\n",
      "lr 0.0006754258588364966\n",
      "epoch-82, loss 0.205\n",
      "------------------------------------\n",
      "iter-2000, loss 0.853\n",
      "Epoch 273946: reducing learning rate of group 0 to 6.0788e-04.\n",
      "lr 0.000607883272952847\n",
      "epoch-83, loss 0.264\n",
      "------------------------------------\n",
      "iter-2000, loss 0.831\n",
      "lr 0.000607883272952847\n",
      "epoch-84, loss 0.149\n",
      "------------------------------------\n",
      "iter-2000, loss 1.213\n",
      "lr 0.000607883272952847\n",
      "epoch-85, loss 1.076\n",
      "------------------------------------\n",
      "iter-2000, loss 1.198\n",
      "lr 0.000607883272952847\n",
      "epoch-86, loss 0.928\n",
      "------------------------------------\n",
      "Epoch 285947: reducing learning rate of group 0 to 5.4709e-04.\n",
      "iter-2000, loss 1.294\n",
      "lr 0.0005470949456575623\n",
      "epoch-87, loss 0.857\n",
      "------------------------------------\n",
      "iter-2000, loss 0.527\n",
      "lr 0.0005470949456575623\n",
      "epoch-88, loss 0.87\n",
      "------------------------------------\n",
      "iter-2000, loss 1.342\n",
      "lr 0.0005470949456575623\n",
      "epoch-89, loss 2.529\n",
      "------------------------------------\n",
      "iter-2000, loss 1.414\n",
      "Accuracy (top 1 guesses) - train =  57.45 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   10375    11    41   116    53    43     9    50     4     1     2     0   \n",
      "1_P     186  4554    79    92    28    22    30     7    19     6     1    18   \n",
      "2_P     361    90  1996   210    28    15   124     9     8    27    16    35   \n",
      "3_P    2203   135   243  2210    35    31   133    41    25     8    57     8   \n",
      "4_P    2111   134    96    85  2359    51    95   100    52    18     7     5   \n",
      "5_P    1371    61    26    35    16  1729    20    20   180     0     2     0   \n",
      "6_P     790   181   510   292    81    64  1557    25   101    14    27     6   \n",
      "7_P    2285    45    62    71   133    44    19  1484    19    11    12     7   \n",
      "8_P    1063   210    63   109    60   465   104    40  1265    19    15     3   \n",
      "9_P     490   180   327   101    73    46    38    37    42  1262    53     7   \n",
      "10_P    456   132   121   443    50    30    63    81    26    34  1253     7   \n",
      "11_P    471   377   929   196    81     8    80    27    17    20     8   870   \n",
      "12_P    524   295    64    86    32    34    63    17    14    42     6     3   \n",
      "13_P    292   487   126    95   101     7    95    31    61    29    10    12   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      3     0  \n",
      "1_P     20    13  \n",
      "2_P      3     0  \n",
      "3_P      7     3  \n",
      "4_P     10    12  \n",
      "5_P      1     0  \n",
      "6_P      7     6  \n",
      "7_P      2     2  \n",
      "8_P      4     7  \n",
      "9_P     74    24  \n",
      "10_P     6     0  \n",
      "11_P     6     3  \n",
      "12_P   744     8  \n",
      "13_P    29   641  \n",
      "Accuracy (top 1 guesses) - test =  45.092 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   4078     6   24   69   34   18   14   58    8    3    14     4     7   \n",
      "1_P     71  1764   59   44   31   20   13   10   14   14    15    16    24   \n",
      "2_P    164    50  625   79   16   13   74   10    8   43    19    56     7   \n",
      "3_P    993    74  106  718   33   21   52   32   37   18    37    24    30   \n",
      "4_P    960    70   79   73  827   22   86   72   30   35    25    25    16   \n",
      "5_P    595    39   21   36   25  526   27   18  154   11    15     3    14   \n",
      "6_P    335    64  242  139   92   53  397   25   47   34    25    39    23   \n",
      "7_P   1038    23   28   54   73   30   20  456   20   12    13     3     4   \n",
      "8_P    486   114   34   79   36  264   82   25  298   25    18    10    17   \n",
      "9_P    207   110  184   82   54   35   46   24   32  345    19    30    46   \n",
      "10_P   224    77   94  175   40   18   57   55   17   35   347    22    18   \n",
      "11_P   216   204  396  128   60    9   75   20   23   44    38   156    11   \n",
      "12_P   241   170   47   49   31   28   42   17   28   41    17     8   172   \n",
      "13_P   153   230   72   71   46   18   44   24   30   27    11    24    18   \n",
      "\n",
      "      13_T  \n",
      "0_P      1  \n",
      "1_P     19  \n",
      "2_P      6  \n",
      "3_P      3  \n",
      "4_P     26  \n",
      "5_P      3  \n",
      "6_P     13  \n",
      "7_P      8  \n",
      "8_P     18  \n",
      "9_P     13  \n",
      "10_P     8  \n",
      "11_P    14  \n",
      "12_P    23  \n",
      "13_P   156  \n",
      "lr 0.0005470949456575623\n",
      "epoch-90, loss 0.591\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297948: reducing learning rate of group 0 to 4.9239e-04.\n",
      "iter-2000, loss 1.269\n",
      "lr 0.0004923854510918061\n",
      "epoch-91, loss 0.271\n",
      "------------------------------------\n",
      "iter-2000, loss 1.492\n",
      "lr 0.0004923854510918061\n",
      "epoch-92, loss 0.794\n",
      "------------------------------------\n",
      "iter-2000, loss 0.746\n",
      "lr 0.0004923854510918061\n",
      "epoch-93, loss 1.248\n",
      "------------------------------------\n",
      "iter-2000, loss 0.894\n",
      "Epoch 309949: reducing learning rate of group 0 to 4.4315e-04.\n",
      "lr 0.00044314690598262546\n",
      "epoch-94, loss 0.711\n",
      "------------------------------------\n",
      "iter-2000, loss 0.841\n",
      "lr 0.00044314690598262546\n",
      "epoch-95, loss 1.737\n",
      "------------------------------------\n",
      "iter-2000, loss 0.855\n",
      "lr 0.00044314690598262546\n",
      "epoch-96, loss 0.618\n",
      "------------------------------------\n",
      "iter-2000, loss 0.741\n",
      "loss < min_loss, updating min_loss to 0.0610586442053318, i_iter 320875\n",
      "lr 0.00044314690598262546\n",
      "epoch-97, loss 0.061\n",
      "------------------------------------\n",
      "iter-2000, loss 1.531\n",
      "lr 0.00044314690598262546\n",
      "epoch-98, loss 0.201\n",
      "------------------------------------\n",
      "iter-2000, loss 1.053\n",
      "lr 0.00044314690598262546\n",
      "epoch-99, loss 1.294\n",
      "------------------------------------\n",
      "iter-2000, loss 0.703\n",
      "Accuracy (top 1 guesses) - train =  59.866 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   10281     8    47    81    54    26     3    41     0     0     1     2   \n",
      "1_P     223  4784    86    99    28    15    32    11    17     7     3    13   \n",
      "2_P     364    82  2218   193    20    14    91    10     6    24    12    22   \n",
      "3_P    2111   124   243  2348    21    16   120    28    19     7    34     6   \n",
      "4_P    2125   128    82    67  2476    37    75    86    40    12     7     4   \n",
      "5_P    1664    68    32    34    18  1988     8    29   131     6     2     1   \n",
      "6_P     920   224   556   352   101    39  1730    24   100    10    28    11   \n",
      "7_P    2298    46    60    75   103    32    11  1564    13     6    17     6   \n",
      "8_P    1105   237    87   143    66   318   110    26  1382    16    15     4   \n",
      "9_P     385   134   255    81    35    42    21    32    16  1297    36     3   \n",
      "10_P    393   115   121   412    36    25    48    67    14    18  1290     2   \n",
      "11_P    360   281   743   111    56     7    58    11    13    12     5   891   \n",
      "12_P    420   195    46    43    18    21    40    11     6    45     5     2   \n",
      "13_P    329   466   107   102    98     9    83    29    76    31    14    14   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      0     0  \n",
      "1_P     30    17  \n",
      "2_P      5     0  \n",
      "3_P      5     1  \n",
      "4_P      8     9  \n",
      "5_P      4     0  \n",
      "6_P     10     7  \n",
      "7_P      1     2  \n",
      "8_P      6     4  \n",
      "9_P     61    10  \n",
      "10_P     8     2  \n",
      "11_P     3     1  \n",
      "12_P   749     7  \n",
      "13_P    26   659  \n",
      "Accuracy (top 1 guesses) - test =  45.08 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   4060    11   31   71   44   17   15   59    6    3     9     4     6   \n",
      "1_P     93  1827   56   50   29   19   32    8   14   15    14    26    23   \n",
      "2_P    166    56  650   87   17   11   74   14   11   50    24    58    10   \n",
      "3_P    894    55  103  703   33   21   59   40   36   17    39    29    27   \n",
      "4_P    939    48   79   65  804   23   73   70   23   31    25    31    18   \n",
      "5_P    720    60   33   48   30  532   36   23  162   16    25     5    17   \n",
      "6_P    411    96  274  162  100   59  398   26   63   38    36    39    27   \n",
      "7_P   1053    27   23   57   74   27   23  464   28   13    23     4     7   \n",
      "8_P    508   118   43   86   50  270   90   19  290   25    21    12    21   \n",
      "9_P    184   103  160   72   51   31   39   20   22  345    24    26    40   \n",
      "10_P   208    66  106  170   49   17   47   48   17   30   327    14    16   \n",
      "11_P   177   172  330  105   55   13   65   13   20   38    25   140    13   \n",
      "12_P   197   128   42   46   17   17   24   14   21   35     9    10   162   \n",
      "13_P   151   228   81   74   45   18   54   28   33   31    12    22    20   \n",
      "\n",
      "      13_T  \n",
      "0_P      2  \n",
      "1_P     22  \n",
      "2_P      2  \n",
      "3_P      4  \n",
      "4_P     20  \n",
      "5_P      5  \n",
      "6_P     16  \n",
      "7_P      8  \n",
      "8_P     15  \n",
      "9_P     14  \n",
      "10_P     7  \n",
      "11_P    19  \n",
      "12_P    17  \n",
      "13_P   160  \n",
      "lr 0.00044314690598262546\n",
      "epoch-100, loss 1.365\n",
      "------------------------------------\n",
      "Epoch 330876: reducing learning rate of group 0 to 3.9883e-04.\n",
      "iter-2000, loss 0.567\n",
      "loss < min_loss, updating min_loss to 0.0014413088792935014, i_iter 334107\n",
      "lr 0.0003988322153843629\n",
      "epoch-101, loss 0.001\n",
      "------------------------------------\n",
      "iter-2000, loss 0.828\n",
      "lr 0.0003988322153843629\n",
      "epoch-102, loss 2.625\n",
      "------------------------------------\n",
      "iter-2000, loss 0.781\n",
      "lr 0.0003988322153843629\n",
      "epoch-103, loss 0.665\n",
      "------------------------------------\n",
      "iter-2000, loss 1.924\n",
      "lr 0.0003988322153843629\n",
      "epoch-104, loss 2.892\n",
      "------------------------------------\n",
      "Epoch 344108: reducing learning rate of group 0 to 3.5895e-04.\n",
      "iter-2000, loss 0.398\n",
      "lr 0.0003589489938459266\n",
      "epoch-105, loss 1.177\n",
      "------------------------------------\n",
      "iter-2000, loss 1.805\n",
      "lr 0.0003589489938459266\n",
      "epoch-106, loss 2.824\n",
      "------------------------------------\n",
      "iter-2000, loss 0.573\n",
      "lr 0.0003589489938459266\n",
      "epoch-107, loss 1.779\n",
      "------------------------------------\n",
      "iter-2000, loss 0.334\n",
      "Epoch 356109: reducing learning rate of group 0 to 3.2305e-04.\n",
      "lr 0.00032305409446133396\n",
      "epoch-108, loss 0.831\n",
      "------------------------------------\n",
      "iter-2000, loss 0.603\n",
      "lr 0.00032305409446133396\n",
      "epoch-109, loss 3.515\n",
      "------------------------------------\n",
      "iter-2000, loss 0.754\n",
      "Accuracy (top 1 guesses) - train =  63.706 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   11275    15    56    73    50    40     6    38     2     1     1     1   \n",
      "1_P     248  4960    83   109    34    20    32    15    22     9     3    17   \n",
      "2_P     442   117  2449   248    26    22    92    10    15    23    15    13   \n",
      "3_P    1906   143   240  2557    15     8    95    30    25     4    37     9   \n",
      "4_P    1976    82    69    41  2533    17    36    60    23     7     3     3   \n",
      "5_P    1294    31    26    27    13  2113     0    12    83     2     1     0   \n",
      "6_P     899   191   406   304    83    32  1866    16   106     6    17     5   \n",
      "7_P    1949    33    48    47    86    22     8  1604     6     5    13     4   \n",
      "8_P     996   163    58    86    47   200    72    21  1447    11     9     0   \n",
      "9_P     406   137   202    68    34    57    17    37    13  1347    22     5   \n",
      "10_P    359    81    97   305    26    12    32    58     9    15  1319     3   \n",
      "11_P    426   283   798   132    61     9    60    25    17    10    15   910   \n",
      "12_P    525   290    70    71    38    32    41    15     9    36     7     2   \n",
      "13_P    277   366    81    73    84     5    73    28    56    15     7     9   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      1     0  \n",
      "1_P     24    22  \n",
      "2_P      3     0  \n",
      "3_P      5     1  \n",
      "4_P      5     5  \n",
      "5_P      0     0  \n",
      "6_P      8     8  \n",
      "7_P      1     1  \n",
      "8_P      3     2  \n",
      "9_P     62    11  \n",
      "10_P     1     0  \n",
      "11_P     6     3  \n",
      "12_P   783    13  \n",
      "13_P    14   653  \n",
      "Accuracy (top 1 guesses) - test =  46.221 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   4378     7   28   98   53   27   21   66   14    4    12     6     7   \n",
      "1_P    115  1865   71   54   41   22   31   13   22   19    20    24    31   \n",
      "2_P    189    66  695  104   28   12   87   18   21   64    28    78    12   \n",
      "3_P    893    79  110  696   36   22   64   37   39   19    49    25    30   \n",
      "4_P    873    53   63   64  762   20   65   72   21   38    20    21    16   \n",
      "5_P    558    48   24   38   29  531   35   19  164   11    22     6    15   \n",
      "6_P    388    74  248  153  102   64  394   25   63   40    27    37    24   \n",
      "7_P    932    24   26   53   69   25   21  453   23    8    27     3    10   \n",
      "8_P    487   105   38   67   48  243   65   20  266   24    20     8    17   \n",
      "9_P    187    94  171   69   56   34   36   26   21  330    21    27    38   \n",
      "10_P   184    59   73  148   52   13   48   43   15   26   317    16     9   \n",
      "11_P   208   170  334  129   57   18   78   20   21   35    28   135    18   \n",
      "12_P   252   166   60   54   23   28   37   16   25   41    13    14   164   \n",
      "13_P   117   185   70   69   42   16   47   18   31   28     9    20    16   \n",
      "\n",
      "      13_T  \n",
      "0_P      2  \n",
      "1_P     27  \n",
      "2_P      4  \n",
      "3_P      4  \n",
      "4_P     18  \n",
      "5_P      5  \n",
      "6_P     14  \n",
      "7_P      9  \n",
      "8_P     13  \n",
      "9_P     20  \n",
      "10_P     7  \n",
      "11_P    18  \n",
      "12_P    19  \n",
      "13_P   151  \n",
      "lr 0.00032305409446133396\n",
      "epoch-110, loss 0.289\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter-2000, loss 0.314\n",
      "lr 0.00032305409446133396\n",
      "epoch-111, loss 0.236\n",
      "------------------------------------\n",
      "Epoch 368110: reducing learning rate of group 0 to 2.9075e-04.\n",
      "iter-2000, loss 0.422\n",
      "lr 0.00029074868501520056\n",
      "epoch-112, loss 0.5\n",
      "------------------------------------\n",
      "iter-2000, loss 1.338\n",
      "lr 0.00029074868501520056\n",
      "epoch-113, loss 0.704\n",
      "------------------------------------\n",
      "iter-2000, loss 0.715\n",
      "lr 0.00029074868501520056\n",
      "epoch-114, loss 0.92\n",
      "------------------------------------\n",
      "iter-2000, loss 0.878\n",
      "Epoch 380111: reducing learning rate of group 0 to 2.6167e-04.\n",
      "lr 0.00026167381651368053\n",
      "epoch-115, loss 0.166\n",
      "------------------------------------\n",
      "iter-2000, loss 0.893\n",
      "lr 0.00026167381651368053\n",
      "epoch-116, loss 1.099\n",
      "------------------------------------\n",
      "iter-2000, loss 0.812\n",
      "lr 0.00026167381651368053\n",
      "epoch-117, loss 0.167\n",
      "------------------------------------\n",
      "iter-2000, loss 0.704\n",
      "lr 0.00026167381651368053\n",
      "epoch-118, loss 0.26\n",
      "------------------------------------\n",
      "Epoch 392112: reducing learning rate of group 0 to 2.3551e-04.\n",
      "iter-2000, loss 0.855\n",
      "lr 0.0002355064348623125\n",
      "epoch-119, loss 2.668\n",
      "------------------------------------\n",
      "iter-2000, loss 0.752\n",
      "Accuracy (top 1 guesses) - train =  65.81 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   11379    14    50    49    42    16     1    23     1     0     0     1   \n",
      "1_P     239  4953    81   106    26    15    27     6    19     4     1    11   \n",
      "2_P     611   141  2812   277    31    17    59    16     7     6    12    20   \n",
      "3_P    1778   133   214  2668    13    10    69    12    17     4    33     6   \n",
      "4_P    2087   114    82    36  2659    13    34    65    18     8     0     2   \n",
      "5_P    1575    50    39    21    11  2298     1    16    90     3     1     1   \n",
      "6_P     813   212   353   272    85    16  1978     7    90     8     5     6   \n",
      "7_P    2003    38    53    56    52    30     4  1669     8     2    11     3   \n",
      "8_P     910   200    59    88    38    79    72    16  1473     6     7     5   \n",
      "9_P     393   138   223    62    32    53    24    36    12  1394    31     4   \n",
      "10_P    308    70    87   333    15    12    18    61     6    10  1355     3   \n",
      "11_P    258   197   497    64    26     3    28    10     5     3     2   905   \n",
      "12_P    371   207    42    32    19    21    28     8     9    27     4     2   \n",
      "13_P    253   425    91    77    81     6    87    24    78    16     7    12   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      2     0  \n",
      "1_P     26    17  \n",
      "2_P      6     2  \n",
      "3_P      3     0  \n",
      "4_P      7     2  \n",
      "5_P      1     0  \n",
      "6_P      6     6  \n",
      "7_P      1     0  \n",
      "8_P      5     4  \n",
      "9_P     55     7  \n",
      "10_P     1     2  \n",
      "11_P     0     1  \n",
      "12_P   787     9  \n",
      "13_P    16   669  \n",
      "Accuracy (top 1 guesses) - test =  46.346 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   4361    11   28  103   49   31   18   81   11    3    11     5     5   \n",
      "1_P    131  1835   70   51   31   17   34   14   15   21    14    21    27   \n",
      "2_P    243    87  757  110   40   21   98   16   18   54    39    79    22   \n",
      "3_P    830    66  121  682   32   25   69   33   38   25    52    19    25   \n",
      "4_P    952    62   77   77  807   22   79   80   16   35    24    30    16   \n",
      "5_P    682    71   35   49   32  584   42   20  178   25    22     4    18   \n",
      "6_P    369    90  252  166  103   57  386   30   64   38    33    49    32   \n",
      "7_P    933    28   21   62   60   30   16  425   32   13    25     4    10   \n",
      "8_P    443   107   40   83   38  197   79   22  261   21    18    10    16   \n",
      "9_P    201   103  175   78   57   31   45   27   28  332    19    39    44   \n",
      "10_P   168    55   72  153   40   11   40   48   17   21   312    15     9   \n",
      "11_P   134   144  238   87   44   12   48   15   15   35    20   118    12   \n",
      "12_P   192   117   47   41   16   21   34   11   23   41    11     7   154   \n",
      "13_P   122   219   78   54   49   16   41   24   30   23    13    20    17   \n",
      "\n",
      "      13_T  \n",
      "0_P      1  \n",
      "1_P     25  \n",
      "2_P      6  \n",
      "3_P      1  \n",
      "4_P     25  \n",
      "5_P      8  \n",
      "6_P     14  \n",
      "7_P      8  \n",
      "8_P     17  \n",
      "9_P     21  \n",
      "10_P     8  \n",
      "11_P    11  \n",
      "12_P    13  \n",
      "13_P   153  \n",
      "lr 0.0002355064348623125\n",
      "epoch-120, loss 1.544\n",
      "------------------------------------\n",
      "iter-2000, loss 0.47\n",
      "lr 0.0002355064348623125\n",
      "epoch-121, loss 2.019\n",
      "------------------------------------\n",
      "iter-2000, loss 0.392\n",
      "lr 0.0002355064348623125\n",
      "epoch-122, loss 0.197\n",
      "------------------------------------\n",
      "Epoch 404113: reducing learning rate of group 0 to 2.1196e-04.\n",
      "iter-2000, loss 0.405\n",
      "lr 0.00021195579137608126\n",
      "epoch-123, loss 2.516\n",
      "------------------------------------\n",
      "iter-2000, loss 0.404\n",
      "lr 0.00021195579137608126\n",
      "epoch-124, loss 1.942\n",
      "------------------------------------\n",
      "iter-2000, loss 0.727\n",
      "lr 0.00021195579137608126\n",
      "epoch-125, loss 0.418\n",
      "------------------------------------\n",
      "iter-2000, loss 0.298\n",
      "Epoch 416114: reducing learning rate of group 0 to 1.9076e-04.\n",
      "lr 0.00019076021223847313\n",
      "epoch-126, loss 1.745\n",
      "------------------------------------\n",
      "iter-2000, loss 0.509\n",
      "lr 0.00019076021223847313\n",
      "epoch-127, loss 0.838\n",
      "------------------------------------\n",
      "iter-2000, loss 0.837\n",
      "lr 0.00019076021223847313\n",
      "epoch-128, loss 0.098\n",
      "------------------------------------\n",
      "iter-2000, loss 0.754\n",
      "lr 0.00019076021223847313\n",
      "epoch-129, loss 1.513\n",
      "------------------------------------\n",
      "Epoch 428115: reducing learning rate of group 0 to 1.7168e-04.\n",
      "iter-2000, loss 0.579\n",
      "Accuracy (top 1 guesses) - train =  68.638 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   12018    14    60    43    31    11     1    11     1     2     0     1   \n",
      "1_P     270  5161   105   103    35    12    33     5    26     6     0    14   \n",
      "2_P     641   134  3030   231    26    17    48    15    10    11     7    11   \n",
      "3_P    1659   138   195  2842    13     6    66     9    16     5    21     4   \n",
      "4_P    1949   101    65    17  2699     7    22    37    25     2     0     2   \n",
      "5_P    1449    45    44    17    10  2360     0    15    47     1     0     1   \n",
      "6_P     712   182   234   219    59     7  2055     7    74     8     5     2   \n",
      "7_P    1771    42    35    49    59    26     3  1731     3     6    13     6   \n",
      "8_P     894   179    57    88    39    55    61    17  1535     8     4     5   \n",
      "9_P     326    90   170    38    20    48     9    22     4  1392    19     2   \n",
      "10_P    386    83    94   346    13    21    18    70     9    13  1387     2   \n",
      "11_P    277   161   479    61    20     4    27    15     8     3     1   921   \n",
      "12_P    405   232    51    23    28    12    30     3     7    25     6     1   \n",
      "13_P    221   330    64    64    78     3    57    12    68     9     6     9   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      2     0  \n",
      "1_P     15    21  \n",
      "2_P      4     0  \n",
      "3_P      5     1  \n",
      "4_P     10     6  \n",
      "5_P      1     0  \n",
      "6_P      7     5  \n",
      "7_P      1     0  \n",
      "8_P      2     5  \n",
      "9_P     55     8  \n",
      "10_P     1     2  \n",
      "11_P     1     3  \n",
      "12_P   798     8  \n",
      "13_P    14   660  \n",
      "Accuracy (top 1 guesses) - test =  47.167 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   4541    12   29  101   70   39   34   67   10    4    12     4     8   \n",
      "1_P    129  1905   68   54   41   25   38   13   22   17    15    28    29   \n",
      "2_P    264    80  765  138   38   25  127   24   18   66    33    85    20   \n",
      "3_P    817    73  136  693   36   28   72   45   43   23    50    28    24   \n",
      "4_P    878    57   66   56  779   21   73   67   29   39    28    26    19   \n",
      "5_P    696    69   28   46   32  562   38   30  177   19    23     5    16   \n",
      "6_P    339    85  235  137   92   51  357   24   47   35    31    43    30   \n",
      "7_P    867    33   27   59   80   23   23  446   28   13    28     4    11   \n",
      "8_P    404   107   38   75   43  202   69   16  254   22    18     9    20   \n",
      "9_P    174    95  169   70   49   31   35   22   29  333    14    29    36   \n",
      "10_P   225    63   95  178   43   20   40   45   22   31   316    15    16   \n",
      "11_P   132   147  241   84   42   15   51    9   22   29    24   117    13   \n",
      "12_P   192   114   47   39   18   21   32   16   23   34    12    10   149   \n",
      "13_P   103   155   67   66   35   12   40   22   22   22     9    17    16   \n",
      "\n",
      "      13_T  \n",
      "0_P      0  \n",
      "1_P     25  \n",
      "2_P     13  \n",
      "3_P      2  \n",
      "4_P     29  \n",
      "5_P      6  \n",
      "6_P     15  \n",
      "7_P     11  \n",
      "8_P     12  \n",
      "9_P     16  \n",
      "10_P     9  \n",
      "11_P    11  \n",
      "12_P    14  \n",
      "13_P   148  \n",
      "lr 0.00017168419101462582\n",
      "epoch-130, loss 0.574\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter-2000, loss 1.114\n",
      "lr 0.00017168419101462582\n",
      "epoch-131, loss 0.179\n",
      "------------------------------------\n",
      "iter-2000, loss 0.444\n",
      "lr 0.00017168419101462582\n",
      "epoch-132, loss 0.183\n",
      "------------------------------------\n",
      "iter-2000, loss 0.224\n",
      "lr 0.00017168419101462582\n",
      "epoch-133, loss 1.274\n",
      "------------------------------------\n",
      "Epoch 440116: reducing learning rate of group 0 to 1.5452e-04.\n",
      "iter-2000, loss 0.306\n",
      "lr 0.00015451577191316325\n",
      "epoch-134, loss 1.362\n",
      "------------------------------------\n",
      "iter-2000, loss 0.631\n",
      "lr 0.00015451577191316325\n",
      "epoch-135, loss 1.998\n",
      "------------------------------------\n",
      "iter-2000, loss 0.501\n",
      "lr 0.00015451577191316325\n",
      "epoch-136, loss 1.656\n",
      "------------------------------------\n",
      "iter-2000, loss 0.342\n",
      "Epoch 452117: reducing learning rate of group 0 to 1.3906e-04.\n",
      "lr 0.00013906419472184693\n",
      "epoch-137, loss 0.912\n",
      "------------------------------------\n",
      "iter-2000, loss 0.456\n",
      "lr 0.00013906419472184693\n",
      "epoch-138, loss 1.323\n",
      "------------------------------------\n",
      "iter-2000, loss 0.814\n",
      "lr 0.00013906419472184693\n",
      "epoch-139, loss 0.234\n",
      "------------------------------------\n",
      "iter-2000, loss 0.643\n",
      "Accuracy (top 1 guesses) - train =  70.639 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   12612    13    65    27    25    11     0    11     1     1     1     1   \n",
      "1_P     263  5220   107    97    35    10    31     9    20     3     3    10   \n",
      "2_P     664   123  3091   153    21    18    27    10     6    13     5     6   \n",
      "3_P    1508   150   235  3014     7     4    43    14    21     4    19     6   \n",
      "4_P    1980    88    69    14  2749     8    20    35    20     1     1     1   \n",
      "5_P    1174    33    38    12     6  2350     0    11    22     1     1     0   \n",
      "6_P     743   215   285   262    55     3  2119     3    73     4     2     2   \n",
      "7_P    1456    28    32    35    38    29     4  1763     3     3    12     5   \n",
      "8_P    1017   186    50    89    32    82    50    14  1574     5     8     1   \n",
      "9_P     262    75   127    22    17    38    10    18     5  1402    19     1   \n",
      "10_P    354    64    66   263    10    10    10    53     2    11  1389     1   \n",
      "11_P    208   120   385    48    10     4    16     6     4     4     0   930   \n",
      "12_P    462   195    61    27    31    16    22     4     4    23     1     2   \n",
      "13_P    275   382    72    78    94     6    78    18    78    16     8    15   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      1     0  \n",
      "1_P     15    12  \n",
      "2_P      5     0  \n",
      "3_P      1     1  \n",
      "4_P      5     6  \n",
      "5_P      1     0  \n",
      "6_P      3     2  \n",
      "7_P      0     1  \n",
      "8_P      3     2  \n",
      "9_P     48     1  \n",
      "10_P     1     1  \n",
      "11_P     0     1  \n",
      "12_P   815     6  \n",
      "13_P    18   686  \n",
      "Accuracy (top 1 guesses) - test =  47.454 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   4662    15   39  110   54   43   30   85   19    4    19     4    10   \n",
      "1_P    130  1897   69   58   35   21   42   13   23   19    15    26    34   \n",
      "2_P    271    86  749  122   43   22   96   22   16   57    32    75    16   \n",
      "3_P    789    74  138  730   38   27   74   44   38   23    63    28    26   \n",
      "4_P    927    64   78   68  777   23   78   76   21   34    25    27    22   \n",
      "5_P    594    59   27   43   36  518   40   26  149   19    22     5    11   \n",
      "6_P    371    89  238  151  103   59  370   27   63   38    37    49    28   \n",
      "7_P    775    25   30   60   71   29   21  419   22   10    26     8    13   \n",
      "8_P    438   112   35   60   38  241   83   22  282   23    15     4    18   \n",
      "9_P    179    76  176   72   52   30   24   21   22  320    18    27    36   \n",
      "10_P   180    55   81  145   44   19   34   40   14   28   300    18    13   \n",
      "11_P   102   125  207   68   45   13   47   13   18   31    20   111    11   \n",
      "12_P   212   123   63   44   20   19   37   14   20   44    14    14   149   \n",
      "13_P   131   195   81   65   42   11   53   24   39   37     7    24    20   \n",
      "\n",
      "      13_T  \n",
      "0_P      2  \n",
      "1_P     29  \n",
      "2_P     10  \n",
      "3_P      6  \n",
      "4_P     23  \n",
      "5_P      7  \n",
      "6_P     14  \n",
      "7_P      9  \n",
      "8_P     13  \n",
      "9_P     13  \n",
      "10_P     8  \n",
      "11_P     9  \n",
      "12_P    18  \n",
      "13_P   150  \n",
      "lr 0.00013906419472184693\n",
      "epoch-140, loss 1.614\n",
      "------------------------------------\n",
      "Epoch 464118: reducing learning rate of group 0 to 1.2516e-04.\n",
      "iter-2000, loss 0.64\n",
      "lr 0.00012515777524966224\n",
      "epoch-141, loss 0.217\n",
      "------------------------------------\n",
      "iter-2000, loss 0.485\n",
      "lr 0.00012515777524966224\n",
      "epoch-142, loss 0.125\n",
      "------------------------------------\n",
      "iter-2000, loss 0.415\n",
      "lr 0.00012515777524966224\n",
      "epoch-143, loss 0.68\n",
      "------------------------------------\n",
      "iter-2000, loss 0.574\n",
      "Epoch 476119: reducing learning rate of group 0 to 1.1264e-04.\n",
      "lr 0.00011264199772469603\n",
      "epoch-144, loss 0.062\n",
      "------------------------------------\n",
      "iter-2000, loss 0.184\n",
      "lr 0.00011264199772469603\n",
      "epoch-145, loss 0.502\n",
      "------------------------------------\n",
      "iter-2000, loss 0.35\n",
      "lr 0.00011264199772469603\n",
      "epoch-146, loss 0.76\n",
      "------------------------------------\n",
      "iter-2000, loss 0.477\n",
      "lr 0.00011264199772469603\n",
      "epoch-147, loss 0.324\n",
      "------------------------------------\n",
      "Epoch 488120: reducing learning rate of group 0 to 1.0138e-04.\n",
      "iter-2000, loss 0.34\n",
      "lr 0.00010137779795222643\n",
      "epoch-148, loss 0.157\n",
      "------------------------------------\n",
      "iter-2000, loss 0.29\n",
      "lr 0.00010137779795222643\n",
      "epoch-149, loss 0.338\n",
      "------------------------------------\n",
      "iter-2000, loss 0.194\n",
      "Accuracy (top 1 guesses) - train =  72.589 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   13041    19    72    44    15    12     3     3     7     2     0     1   \n",
      "1_P     254  5302    82    82    29     9    15    11    22     5     1    10   \n",
      "2_P     886   181  3380   230    40    38    43     9    10     8     7    10   \n",
      "3_P    1286   146   161  3109    10     5    51     4    17     5    16     4   \n",
      "4_P    1817    89    48    16  2801     6    19    22    16     6     0     1   \n",
      "5_P    1300    28    36     8     4  2414     0    19    28     4     1     0   \n",
      "6_P     630   171   185   174    45     4  2161     1    79     2     5     0   \n",
      "7_P    1624    29    42    44    36    28     1  1799     6     3    17     7   \n",
      "8_P     790   159    41    67    26    29    41     8  1586     5     3     4   \n",
      "9_P     294    72   129    32    17    28     8    27     7  1408    22     2   \n",
      "10_P    284    54    59   209     7     6     8    43     1    11  1384     2   \n",
      "11_P    227   167   347    50     9     0    13     8     6     2     5   926   \n",
      "12_P    364   214    55    25    33     6    28     2     1    19     3     4   \n",
      "13_P    181   261    46    51    58     4    39    13    47    11     5    10   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      1     0  \n",
      "1_P     17    18  \n",
      "2_P      6     0  \n",
      "3_P      0     2  \n",
      "4_P      5     7  \n",
      "5_P      1     0  \n",
      "6_P      5     7  \n",
      "7_P      0     0  \n",
      "8_P      0     4  \n",
      "9_P     39     1  \n",
      "10_P     1     0  \n",
      "11_P     0     3  \n",
      "12_P   829     7  \n",
      "13_P    12   670  \n",
      "Accuracy (top 1 guesses) - test =  48.043 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   4779    21   47  121   74   45   31   91   19    5    14     4     9   \n",
      "1_P    134  1889   67   62   41   27   47   15   21   25    18    22    33   \n",
      "2_P    338   105  819  164   49   28  139   22   27   65    32    90    29   \n",
      "3_P    720    74  120  711   34   25   76   58   49   26    64    23    24   \n",
      "4_P    864    57   77   66  765   20   74   73   25   34    32    22    21   \n",
      "5_P    646    72   34   44   39  574   52   27  179   25    24     8    13   \n",
      "6_P    316    82  209  140   98   55  348   21   53   34    32    46    22   \n",
      "7_P    859    34   31   66   71   28   30  424   30   18    30    11    11   \n",
      "8_P    380    91   34   54   34  191   59   17  241   18    11     4    15   \n",
      "9_P    174    88  168   76   48   25   29   21   23  309    21    24    38   \n",
      "10_P   156    58   77  134   43   13   39   28   16   22   296    12    11   \n",
      "11_P   112   140  219   62   42   13   48   14   18   33    22   126     9   \n",
      "12_P   190   130   55   46   25   17   26   14   20   50    12    12   154   \n",
      "13_P    93   154   54   50   35   14   31   21   25   23     5    16    18   \n",
      "\n",
      "      13_T  \n",
      "0_P      1  \n",
      "1_P     37  \n",
      "2_P     16  \n",
      "3_P      6  \n",
      "4_P     26  \n",
      "5_P      8  \n",
      "6_P     12  \n",
      "7_P      9  \n",
      "8_P      7  \n",
      "9_P     17  \n",
      "10_P     7  \n",
      "11_P     9  \n",
      "12_P    15  \n",
      "13_P   141  \n",
      "lr 0.00010137779795222643\n",
      "epoch-150, loss 0.282\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter-2000, loss 1.058\n",
      "lr 0.00010137779795222643\n",
      "epoch-151, loss 0.423\n",
      "------------------------------------\n",
      "Epoch 500121: reducing learning rate of group 0 to 9.1240e-05.\n",
      "iter-2000, loss 0.394\n",
      "lr 9.124001815700379e-05\n",
      "epoch-152, loss 0.149\n",
      "------------------------------------\n",
      "iter-2000, loss 0.477\n",
      "lr 9.124001815700379e-05\n",
      "epoch-153, loss 0.821\n",
      "------------------------------------\n",
      "iter-2000, loss 0.69\n",
      "lr 9.124001815700379e-05\n",
      "epoch-154, loss 0.439\n",
      "------------------------------------\n",
      "iter-2000, loss 0.49\n",
      "Epoch 512122: reducing learning rate of group 0 to 8.2116e-05.\n",
      "lr 8.211601634130342e-05\n",
      "epoch-155, loss 0.896\n",
      "------------------------------------\n",
      "iter-2000, loss 0.618\n",
      "lr 8.211601634130342e-05\n",
      "epoch-156, loss 0.045\n",
      "------------------------------------\n",
      "iter-2000, loss 0.314\n",
      "lr 8.211601634130342e-05\n",
      "epoch-157, loss 0.282\n",
      "------------------------------------\n",
      "iter-2000, loss 0.214\n",
      "lr 8.211601634130342e-05\n",
      "epoch-158, loss 0.303\n",
      "------------------------------------\n",
      "Epoch 524123: reducing learning rate of group 0 to 7.3904e-05.\n",
      "iter-2000, loss 0.825\n",
      "lr 7.390441470717308e-05\n",
      "epoch-159, loss 0.291\n",
      "------------------------------------\n",
      "iter-2000, loss 0.154\n",
      "Accuracy (top 1 guesses) - train =  74.362 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   13583    22    92    17    17     9     0     6     1     0     0     0   \n",
      "1_P     323  5449   103    95    28     7    20    11    24     8     2    10   \n",
      "2_P     798   180  3369   168    32    23    29     7     6     5     8     7   \n",
      "3_P    1343   145   187  3229     7     7    30     6    19     4    20     9   \n",
      "4_P    1707    66    38    11  2830     9     8    17    11     2     0     1   \n",
      "5_P    1214    24    40     7     5  2419     0    17    13     3     0     0   \n",
      "6_P     630   164   202   181    40     2  2217     1    51     2     3     0   \n",
      "7_P    1218    25    28    19    20    24     2  1803     1     6    10     6   \n",
      "8_P     864   165    43   100    29    37    26    11  1637     6     4     5   \n",
      "9_P     232    59   108    17    14    35     5    14     5  1420    15     2   \n",
      "10_P    290    48    58   174     7     8     8    50     1    11  1399     1   \n",
      "11_P    218   118   317    50     7     5     9    12     7     3     2   928   \n",
      "12_P    354   153    52    21    35     2    28     2     7    12     3     0   \n",
      "13_P    204   274    46    52    59     2    48    12    50     9     3    12   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      0     0  \n",
      "1_P     13    17  \n",
      "2_P      8     2  \n",
      "3_P      3     1  \n",
      "4_P      2     3  \n",
      "5_P      0     0  \n",
      "6_P      3     4  \n",
      "7_P      0     0  \n",
      "8_P      2     3  \n",
      "9_P     27     2  \n",
      "10_P     0     1  \n",
      "11_P     1     2  \n",
      "12_P   842     2  \n",
      "13_P    15   682  \n",
      "Accuracy (top 1 guesses) - test =  48.786 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   4933    17   38  112   70   52   39  111   25    7    15     4    19   \n",
      "1_P    159  1930   83   65   52   27   54   16   32   30    21    26    35   \n",
      "2_P    331    95  847  147   47   19  126   21   22   74    36    94    22   \n",
      "3_P    782    85  137  740   44   33   74   58   42   31    70    29    21   \n",
      "4_P    782    57   72   60  764   27   76   73   17   28    30    12    21   \n",
      "5_P    619    69   31   43   42  548   46   24  172   22    20     4    15   \n",
      "6_P    344    94  207  149   92   47  348   20   53   31    30    45    24   \n",
      "7_P    701    24   23   55   78   25   23  395   22   19    27    11    11   \n",
      "8_P    390    92   36   70   46  212   62   22  253   19    14    10    24   \n",
      "9_P    152    83  149   64   40   25   28   20   23  303    16    26    32   \n",
      "10_P   169    47   74  136   36   15   45   35   18   25   290    10     9   \n",
      "11_P   101   133  212   63   36   16   45   10   22   22    25   115     7   \n",
      "12_P   191   103   45   35   17   15   29   17   20   53    11    13   154   \n",
      "13_P   107   166   57   57   34   14   34   24   25   23     8    21    13   \n",
      "\n",
      "      13_T  \n",
      "0_P      4  \n",
      "1_P     37  \n",
      "2_P     10  \n",
      "3_P      3  \n",
      "4_P     29  \n",
      "5_P     10  \n",
      "6_P     14  \n",
      "7_P      9  \n",
      "8_P     13  \n",
      "9_P     15  \n",
      "10_P     7  \n",
      "11_P    11  \n",
      "12_P    14  \n",
      "13_P   135  \n",
      "lr 7.390441470717308e-05\n",
      "epoch-160, loss 0.244\n",
      "------------------------------------\n",
      "iter-2000, loss 0.215\n",
      "lr 7.390441470717308e-05\n",
      "epoch-161, loss 0.054\n",
      "------------------------------------\n",
      "iter-2000, loss 0.274\n",
      "lr 7.390441470717308e-05\n",
      "epoch-162, loss 0.174\n",
      "------------------------------------\n",
      "Epoch 536124: reducing learning rate of group 0 to 6.6514e-05.\n",
      "iter-2000, loss 1.68\n",
      "lr 6.651397323645577e-05\n",
      "epoch-163, loss 0.367\n",
      "------------------------------------\n",
      "iter-2000, loss 0.876\n",
      "lr 6.651397323645577e-05\n",
      "epoch-164, loss 0.191\n",
      "------------------------------------\n",
      "iter-2000, loss 0.223\n",
      "loss < min_loss, updating min_loss to 0.00020190057693980634, i_iter 545819\n",
      "lr 6.651397323645577e-05\n",
      "epoch-165, loss 0.0\n",
      "------------------------------------\n",
      "iter-2000, loss 0.253\n",
      "lr 6.651397323645577e-05\n",
      "epoch-166, loss 0.785\n",
      "------------------------------------\n",
      "iter-2000, loss 0.796\n",
      "lr 6.651397323645577e-05\n",
      "epoch-167, loss 0.005\n",
      "------------------------------------\n",
      "iter-2000, loss 0.375\n",
      "lr 6.651397323645577e-05\n",
      "epoch-168, loss 0.354\n",
      "------------------------------------\n",
      "Epoch 555820: reducing learning rate of group 0 to 5.9863e-05.\n",
      "iter-2000, loss 0.721\n",
      "lr 5.9862575912810195e-05\n",
      "epoch-169, loss 0.076\n",
      "------------------------------------\n",
      "iter-2000, loss 0.197\n",
      "Accuracy (top 1 guesses) - train =  75.808 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   14084    31    86    22    16     5     0     4     2     1     1     0   \n",
      "1_P     295  5428    99    86    32     5    21     9    23     3     3    12   \n",
      "2_P     862   160  3475   137    21    20    24     5     7     6     9     8   \n",
      "3_P    1224   141   183  3345     7     4    41     4    21     0    16     2   \n",
      "4_P    1508    64    50    10  2863     3     9    14    10     2     1     0   \n",
      "5_P    1193    24    50     7     4  2454     0    15    13     6     0     0   \n",
      "6_P     526   142   126   152    31     0  2228     0    54     2     0     0   \n",
      "7_P    1191    32    27    20    21    20     1  1823     4     5    19    10   \n",
      "8_P     822   163    38    66    22    21    27     9  1624     5     3     4   \n",
      "9_P     277    85   128    22    16    37     8    23     0  1428    19     1   \n",
      "10_P    277    43    47   167     6    10     6    44     2     8  1392     2   \n",
      "11_P    169   101   262    34     6     2     5     5     1     6     0   927   \n",
      "12_P    357   184    52    17    36     4    21     3     9     7     1     0   \n",
      "13_P    193   294    60    56    49     4    39    11    63    12     5    15   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      1     0  \n",
      "1_P      7    16  \n",
      "2_P      7     1  \n",
      "3_P      1     0  \n",
      "4_P      1     3  \n",
      "5_P      0     0  \n",
      "6_P      1     3  \n",
      "7_P      0     0  \n",
      "8_P      1     2  \n",
      "9_P     19     2  \n",
      "10_P     0     0  \n",
      "11_P     2     0  \n",
      "12_P   862     5  \n",
      "13_P    14   687  \n",
      "Accuracy (top 1 guesses) - test =  49.052 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   5081    21   49  133   89   58   40  104   24   13    23    10    16   \n",
      "1_P    160  1898   65   67   47   29   49   17   30   27    19    22    31   \n",
      "2_P    313   123  832  152   39   27  139   21   22   81    39    84    20   \n",
      "3_P    732    86  133  738   37   27   86   63   49   22    68    26    31   \n",
      "4_P    782    45   78   63  743   19   83   73   27   30    28    20    19   \n",
      "5_P    619    59   36   48   41  557   48   26  179   23    18     4    10   \n",
      "6_P    309    96  215  125   86   48  321   19   53   35    28    46    26   \n",
      "7_P    688    23   26   58   79   34   25  409   24   16    36    15    12   \n",
      "8_P    359    98   39   60   47  190   73   18  241   19    13    11    17   \n",
      "9_P    171    80  156   74   41   32   22   20   21  317    12    31    36   \n",
      "10_P   176    54   80  122   39   17   41   39   12   23   284    10     9   \n",
      "11_P    96   109  177   57   38   12   36   10   18   20    22   106     9   \n",
      "12_P   179   135   65   42   31   12   26    8   25   40    14    12   152   \n",
      "13_P    96   168   60   57   41   13   40   19   21   21     9    23    19   \n",
      "\n",
      "      13_T  \n",
      "0_P      4  \n",
      "1_P     32  \n",
      "2_P     14  \n",
      "3_P      9  \n",
      "4_P     22  \n",
      "5_P      9  \n",
      "6_P     13  \n",
      "7_P      9  \n",
      "8_P     15  \n",
      "9_P     14  \n",
      "10_P    10  \n",
      "11_P     7  \n",
      "12_P    13  \n",
      "13_P   140  \n",
      "lr 5.9862575912810195e-05\n",
      "epoch-170, loss 0.591\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter-2000, loss 0.49\n",
      "lr 5.9862575912810195e-05\n",
      "epoch-171, loss 1.498\n",
      "------------------------------------\n",
      "iter-2000, loss 0.43\n",
      "Epoch 567821: reducing learning rate of group 0 to 5.3876e-05.\n",
      "lr 5.3876318321529174e-05\n",
      "epoch-172, loss 0.232\n",
      "------------------------------------\n",
      "iter-2000, loss 0.245\n",
      "lr 5.3876318321529174e-05\n",
      "epoch-173, loss 0.017\n",
      "------------------------------------\n",
      "iter-2000, loss 0.998\n",
      "lr 5.3876318321529174e-05\n",
      "epoch-174, loss 0.158\n",
      "------------------------------------\n",
      "iter-2000, loss 0.75\n",
      "lr 5.3876318321529174e-05\n",
      "epoch-175, loss 1.214\n",
      "------------------------------------\n",
      "Epoch 579822: reducing learning rate of group 0 to 4.8489e-05.\n",
      "iter-2000, loss 0.601\n",
      "lr 4.848868648937626e-05\n",
      "epoch-176, loss 0.142\n",
      "------------------------------------\n",
      "iter-2000, loss 0.503\n",
      "lr 4.848868648937626e-05\n",
      "epoch-177, loss 0.051\n",
      "------------------------------------\n",
      "iter-2000, loss 0.946\n",
      "lr 4.848868648937626e-05\n",
      "epoch-178, loss 0.009\n",
      "------------------------------------\n",
      "iter-2000, loss 0.263\n",
      "Epoch 591823: reducing learning rate of group 0 to 4.3640e-05.\n",
      "lr 4.3639817840438635e-05\n",
      "epoch-179, loss 0.081\n",
      "------------------------------------\n",
      "iter-2000, loss 0.371\n",
      "Accuracy (top 1 guesses) - train =  76.669 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   14349    29    83    18    16     6     0     6     2     1     1     0   \n",
      "1_P     317  5415    86    91    24     6    19     8    23     5     5    11   \n",
      "2_P     928   175  3613   132    16    20    24     2     9     5    10     8   \n",
      "3_P    1152   157   160  3392     5     4    30     3    28     1     8     5   \n",
      "4_P    1513    84    42     7  2873    11     7    10     8     4     0     1   \n",
      "5_P    1029    13    14     6     1  2444     0    15    11     7     1     0   \n",
      "6_P     524   149   121   157    36     0  2241     0    51     1     1     0   \n",
      "7_P    1148    22    25    14    22    27     2  1845     2     9    11     6   \n",
      "8_P     833   166    40    70    21    18    22     6  1639     1     2     5   \n",
      "9_P     242    66   121    18    11    37     3    18     5  1424    17     1   \n",
      "10_P    255    47    35   134     7     6     4    33     0     7  1405     3   \n",
      "11_P    171   101   239    31     4     3     7    11     1     1     3   930   \n",
      "12_P    318   147    42     9    34     3    15     0     2     9     0     0   \n",
      "13_P    199   321    62    62    60     4    56    12    52    16     5    11   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      2     0  \n",
      "1_P     10    11  \n",
      "2_P      3     1  \n",
      "3_P      1     1  \n",
      "4_P      5     5  \n",
      "5_P      0     0  \n",
      "6_P      3     4  \n",
      "7_P      0     0  \n",
      "8_P      1     2  \n",
      "9_P     27     3  \n",
      "10_P     0     0  \n",
      "11_P     2     4  \n",
      "12_P   851     5  \n",
      "13_P    11   683  \n",
      "Accuracy (top 1 guesses) - test =  49.081 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   5123    20   52  115   90   62   47  130   21    9    25     7    18   \n",
      "1_P    147  1888   69   60   53   24   40   18   30   26    15    35    34   \n",
      "2_P    371   104  877  174   50   33  134   21   30   77    41    95    21   \n",
      "3_P    725    81  145  726   33   28   86   53   46   30    83    26    29   \n",
      "4_P    795    58   84   65  757   22   72   81   21   38    20    21    19   \n",
      "5_P    586    64   34   47   32  545   45   23  176   26    22     6    14   \n",
      "6_P    317    90  204  132   81   51  323   22   56   32    29    42    33   \n",
      "7_P    637    33   27   60   71   28   23  380   26   18    28     6    13   \n",
      "8_P    388    99   30   63   39  200   74   13  240   15    20     7    11   \n",
      "9_P    166    88  140   71   44   30   27   31   24  303    16    29    37   \n",
      "10_P   147    43   66  125   40   12   34   30   17   19   272    13    13   \n",
      "11_P    95   125  168   53   39   11   38    8   15   22    23   105     5   \n",
      "12_P   165   116   48   44   23   16   43   11   19   47    11     8   141   \n",
      "13_P    99   186   67   61   46   13   43   25   25   25     8    20    19   \n",
      "\n",
      "      13_T  \n",
      "0_P      4  \n",
      "1_P     29  \n",
      "2_P     12  \n",
      "3_P      8  \n",
      "4_P     26  \n",
      "5_P      8  \n",
      "6_P      8  \n",
      "7_P     13  \n",
      "8_P     12  \n",
      "9_P     14  \n",
      "10_P     7  \n",
      "11_P     9  \n",
      "12_P    15  \n",
      "13_P   146  \n",
      "lr 4.3639817840438635e-05\n",
      "epoch-180, loss 0.19\n",
      "------------------------------------\n",
      "iter-2000, loss 0.065\n",
      "lr 4.3639817840438635e-05\n",
      "epoch-181, loss 0.117\n",
      "------------------------------------\n",
      "iter-2000, loss 0.434\n",
      "lr 4.3639817840438635e-05\n",
      "epoch-182, loss 0.03\n",
      "------------------------------------\n",
      "Epoch 603824: reducing learning rate of group 0 to 3.9276e-05.\n",
      "iter-2000, loss 0.264\n",
      "lr 3.9275836056394775e-05\n",
      "epoch-183, loss 0.259\n",
      "------------------------------------\n",
      "iter-2000, loss 0.29\n",
      "lr 3.9275836056394775e-05\n",
      "epoch-184, loss 0.277\n",
      "------------------------------------\n",
      "iter-2000, loss 0.276\n",
      "lr 3.9275836056394775e-05\n",
      "epoch-185, loss 0.279\n",
      "------------------------------------\n",
      "iter-2000, loss 0.267\n",
      "lr 3.9275836056394775e-05\n",
      "epoch-186, loss 0.132\n",
      "------------------------------------\n",
      "Epoch 615825: reducing learning rate of group 0 to 3.5348e-05.\n",
      "iter-2000, loss 0.249\n",
      "lr 3.53482524507553e-05\n",
      "epoch-187, loss 0.718\n",
      "------------------------------------\n",
      "iter-2000, loss 0.362\n",
      "lr 3.53482524507553e-05\n",
      "epoch-188, loss 0.244\n",
      "------------------------------------\n",
      "iter-2000, loss 0.504\n",
      "lr 3.53482524507553e-05\n",
      "epoch-189, loss 0.108\n",
      "------------------------------------\n",
      "iter-2000, loss 0.307\n",
      "Epoch 627826: reducing learning rate of group 0 to 3.1813e-05.\n",
      "Accuracy (top 1 guesses) - train =  77.384 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   14563    34   103    14    18     7     0     1     3     2     1     0   \n",
      "1_P     302  5480    96    90    26     5    20    14    17     3     5    11   \n",
      "2_P     918   173  3649   108    23    19    19     4     6    10    13     9   \n",
      "3_P    1122   146   138  3426     6     2    19     5    23     2    10     2   \n",
      "4_P    1527    80    52     8  2880     4     8     9     7     3     1     1   \n",
      "5_P     996    12    30     7     4  2448     0    11    11     3     2     0   \n",
      "6_P     494   151   120   162    29     2  2259     0    45     2     2     1   \n",
      "7_P    1103    21    21    11    13    34     0  1838     1     5    16     7   \n",
      "8_P     845   136    44    86    21    23    23     6  1652     3     2     6   \n",
      "9_P     217    51    95    18    15    31    11    20     3  1431    16     2   \n",
      "10_P    234    40    50   117     4     5     3    39     0     4  1397     1   \n",
      "11_P    128    89   181    26     1     5     7    10     1     3     0   931   \n",
      "12_P    328   150    51    12    30     1    12     0     5    11     1     1   \n",
      "13_P    201   329    53    56    60     3    49    12    59     9     3     9   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      0     0  \n",
      "1_P     11    15  \n",
      "2_P      4     1  \n",
      "3_P      1     2  \n",
      "4_P      5     2  \n",
      "5_P      0     0  \n",
      "6_P      3     1  \n",
      "7_P      0     0  \n",
      "8_P      1     4  \n",
      "9_P     14     4  \n",
      "10_P     0     0  \n",
      "11_P     1     2  \n",
      "12_P   865     1  \n",
      "13_P    11   687  \n",
      "Accuracy (top 1 guesses) - test =  49.595 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   5231    26   49  131  102   69   50  129   29    9    23     7    23   \n",
      "1_P    148  1927   69   66   57   30   47   17   33   24    25    28    39   \n",
      "2_P    341   105  878  156   58   27  143   19   31   76    35   100    27   \n",
      "3_P    700    88  143  720   41   31   85   55   42   22    82    33    26   \n",
      "4_P    760    52   78   76  737   23   81   75   21   30    24    24    23   \n",
      "5_P    536    61   32   48   31  530   45   18  170   20    20     4    11   \n",
      "6_P    343    98  226  127   85   48  330   23   57   37    23    42    26   \n",
      "7_P    663    38   26   58   69   27   22  382   25   18    36     9    11   \n",
      "8_P    371    82   28   61   42  207   65   20  243   18    13     8    16   \n",
      "9_P    160    77  150   64   45   31   18   28   25  312    17    26    38   \n",
      "10_P   164    41   59  131   38   18   34   38   13   27   274    11     6   \n",
      "11_P    98   113  152   52   35    8   39    6   16   24    17   101     4   \n",
      "12_P   155   116   58   38   21   13   37   15   18   44    10    10   141   \n",
      "13_P    91   171   63   68   37   13   33   21   23   26    14    17    16   \n",
      "\n",
      "      13_T  \n",
      "0_P      7  \n",
      "1_P     36  \n",
      "2_P     11  \n",
      "3_P      7  \n",
      "4_P     27  \n",
      "5_P      7  \n",
      "6_P      8  \n",
      "7_P     11  \n",
      "8_P     14  \n",
      "9_P     12  \n",
      "10_P     7  \n",
      "11_P     7  \n",
      "12_P    13  \n",
      "13_P   144  \n",
      "lr 3.1813427205679776e-05\n",
      "epoch-190, loss 0.16\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter-2000, loss 0.186\n",
      "lr 3.1813427205679776e-05\n",
      "epoch-191, loss 0.762\n",
      "------------------------------------\n",
      "iter-2000, loss 0.462\n",
      "lr 3.1813427205679776e-05\n",
      "epoch-192, loss 0.006\n",
      "------------------------------------\n",
      "iter-2000, loss 0.432\n",
      "lr 3.1813427205679776e-05\n",
      "epoch-193, loss 0.14\n",
      "------------------------------------\n",
      "Epoch 639827: reducing learning rate of group 0 to 2.8632e-05.\n",
      "iter-2000, loss 0.356\n",
      "lr 2.8632084485111798e-05\n",
      "epoch-194, loss 0.105\n",
      "------------------------------------\n",
      "iter-2000, loss 1.306\n",
      "lr 2.8632084485111798e-05\n",
      "epoch-195, loss 2.229\n",
      "------------------------------------\n",
      "iter-2000, loss 0.434\n",
      "lr 2.8632084485111798e-05\n",
      "epoch-196, loss 0.06\n",
      "------------------------------------\n",
      "iter-2000, loss 0.21\n",
      "lr 2.8632084485111798e-05\n",
      "epoch-197, loss 1.513\n",
      "------------------------------------\n",
      "Epoch 651828: reducing learning rate of group 0 to 2.5769e-05.\n",
      "iter-2000, loss 0.288\n",
      "lr 2.576887603660062e-05\n",
      "epoch-198, loss 2.139\n",
      "------------------------------------\n",
      "iter-2000, loss 0.715\n",
      "lr 2.576887603660062e-05\n",
      "epoch-199, loss 0.203\n",
      "------------------------------------\n",
      "iter-2000, loss 0.333\n",
      "Accuracy (top 1 guesses) - train =  77.98 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   14763    39   104    17    12     3     1     2     0     0     0     0   \n",
      "1_P     289  5494    87    83    30     4    15     8    18     8     4     7   \n",
      "2_P     965   177  3688    96    23    20    20     5     7     6     9     9   \n",
      "3_P    1097   150   140  3490     4     3    28     2    25     2    12     4   \n",
      "4_P    1425    78    43    11  2879     7     9    14     7     2     1     0   \n",
      "5_P     976    18    17     4     3  2446     1    10     7     3     2     0   \n",
      "6_P     542   135   118   149    29     0  2260     0    47     2     2     1   \n",
      "7_P    1041    18    14    15    16    27     1  1844     4     8    14    10   \n",
      "8_P     808   167    41    71    24    29    21     8  1665     4     2     2   \n",
      "9_P     202    40    82     8    11    28     4    21     0  1422    16     1   \n",
      "10_P    251    39    40   109     7    12     3    31     2    11  1399     2   \n",
      "11_P    140    88   207    25     3     5     4    10     2     2     1   933   \n",
      "12_P    304   140    43     8    28     3    16     1     1    11     1     0   \n",
      "13_P    175   309    59    55    61     2    47    13    48    10     6    12   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      0     0  \n",
      "1_P      9    16  \n",
      "2_P     11     0  \n",
      "3_P      0     1  \n",
      "4_P      2     3  \n",
      "5_P      0     0  \n",
      "6_P      5     3  \n",
      "7_P      0     0  \n",
      "8_P      0     5  \n",
      "9_P      7     1  \n",
      "10_P     0     1  \n",
      "11_P     0     1  \n",
      "12_P   871     1  \n",
      "13_P    11   687  \n",
      "Accuracy (top 1 guesses) - test =  49.591 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   5250    28   49  128  112   67   51  132   27    9    22    12    24   \n",
      "1_P    150  1926   71   64   49   27   42   18   20   27    30    25    31   \n",
      "2_P    357   101  862  160   55   21  126   24   31   86    36    97    20   \n",
      "3_P    716    88  148  723   43   27   98   57   41   27    76    35    34   \n",
      "4_P    736    59   74   66  733   25   74   70   22   38    27    16    17   \n",
      "5_P    550    62   27   45   31  541   39   29  172   19    19     8     9   \n",
      "6_P    335    99  227  141   99   48  335   21   64   39    28    45    25   \n",
      "7_P    619    33   27   65   67   33   24  382   28   18    32    10    13   \n",
      "8_P    391    89   44   67   39  203   66   25  243   14    14     7    18   \n",
      "9_P    147    78  134   62   45   29   22   17   23  302    18    23    36   \n",
      "10_P   173    48   67  120   34   16   41   33   13   24   268     7    13   \n",
      "11_P    88   115  167   59   32   13   42   10   18   17    26   103     5   \n",
      "12_P   170   102   45   41   25   13   34    9   18   42    11    16   143   \n",
      "13_P    79   167   69   55   34   12   35   19   26   25     6    16    19   \n",
      "\n",
      "      13_T  \n",
      "0_P      4  \n",
      "1_P     36  \n",
      "2_P     11  \n",
      "3_P      3  \n",
      "4_P     23  \n",
      "5_P      5  \n",
      "6_P     16  \n",
      "7_P     12  \n",
      "8_P     12  \n",
      "9_P     14  \n",
      "10_P     9  \n",
      "11_P    12  \n",
      "12_P    16  \n",
      "13_P   138  \n",
      "lr 2.576887603660062e-05\n",
      "epoch-200, loss 0.144\n",
      "------------------------------------\n",
      "iter-2000, loss 1.088\n",
      "Epoch 663829: reducing learning rate of group 0 to 2.3192e-05.\n",
      "lr 2.3191988432940557e-05\n",
      "epoch-201, loss 0.212\n",
      "------------------------------------\n",
      "iter-2000, loss 0.286\n",
      "lr 2.3191988432940557e-05\n",
      "epoch-202, loss 0.018\n",
      "------------------------------------\n",
      "iter-2000, loss 0.327\n",
      "lr 2.3191988432940557e-05\n",
      "epoch-203, loss 0.514\n",
      "------------------------------------\n",
      "iter-2000, loss 0.221\n",
      "lr 2.3191988432940557e-05\n",
      "epoch-204, loss 0.031\n",
      "------------------------------------\n",
      "Epoch 675830: reducing learning rate of group 0 to 2.0873e-05.\n",
      "iter-2000, loss 0.639\n",
      "lr 2.08727895896465e-05\n",
      "epoch-205, loss 2.046\n",
      "------------------------------------\n",
      "iter-2000, loss 0.275\n",
      "lr 2.08727895896465e-05\n",
      "epoch-206, loss 0.034\n",
      "------------------------------------\n",
      "iter-2000, loss 0.456\n",
      "lr 2.08727895896465e-05\n",
      "epoch-207, loss 0.145\n",
      "------------------------------------\n",
      "iter-2000, loss 0.376\n",
      "Epoch 687831: reducing learning rate of group 0 to 1.8786e-05.\n",
      "lr 1.878551063068185e-05\n",
      "epoch-208, loss 0.009\n",
      "------------------------------------\n",
      "iter-2000, loss 0.908\n",
      "lr 1.878551063068185e-05\n",
      "epoch-209, loss 0.719\n",
      "------------------------------------\n",
      "iter-2000, loss 0.404\n",
      "Accuracy (top 1 guesses) - train =  78.508 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   14970    35    96    10    19     5     2     2     2     1     1     0   \n",
      "1_P     307  5509    86    73    16     6    12     2    27     8     2    11   \n",
      "2_P     906   163  3708    99    22    25    19     3    12     8    11     7   \n",
      "3_P    1128   153   162  3532     2     3    33     5    35     0    14     5   \n",
      "4_P    1391    69    38     7  2898     2     7     8     7     1     0     0   \n",
      "5_P     854    18    16     3     4  2439     0    11     4     1     0     2   \n",
      "6_P     525   126   122   143    27     0  2263     0    32     1     0     0   \n",
      "7_P     991    23    17    14    15    32     0  1855     1     8     9     7   \n",
      "8_P     828   148    45    75    20    23    21     7  1647     2     5     7   \n",
      "9_P     200    49    87     9     8    37     6    17     2  1436    14     0   \n",
      "10_P    230    44    28    86     6     9     3    35     0     3  1403     4   \n",
      "11_P    183   103   191    25     5     1     4    11     6     4     5   929   \n",
      "12_P    272   138    37    13    32     4    14     1     3     7     1     0   \n",
      "13_P    193   314    50    52    56     3    46    12    55    11     4     9   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      3     0  \n",
      "1_P      8    15  \n",
      "2_P      6     0  \n",
      "3_P      0     2  \n",
      "4_P      5     3  \n",
      "5_P      0     0  \n",
      "6_P      3     3  \n",
      "7_P      0     0  \n",
      "8_P      2     1  \n",
      "9_P     17     2  \n",
      "10_P     0     0  \n",
      "11_P     0     1  \n",
      "12_P   859     2  \n",
      "13_P    13   690  \n",
      "Accuracy (top 1 guesses) - test =  49.745 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   5307    27   59  121  110   82   51  134   29    7    33     8    18   \n",
      "1_P    159  1935   82   73   54   32   47   24   27   29    21    25    35   \n",
      "2_P    325   109  860  173   42   30  148   19   28   89    40   103    22   \n",
      "3_P    709   109  158  717   46   33   83   64   55   32    84    27    34   \n",
      "4_P    743    48   83   59  742   22   80   78   19   35    24    23    19   \n",
      "5_P    504    50   22   51   35  521   38   20  167   17    17     2    10   \n",
      "6_P    350    96  218  152  103   40  335   21   54   37    29    49    26   \n",
      "7_P    641    28   29   53   70   24   15  385   31   15    29     6    10   \n",
      "8_P    375    88   36   67   32  205   76   20  247   21    18    11    16   \n",
      "9_P    141    76  130   70   39   27   24   22   22  291    15    26    40   \n",
      "10_P   154    47   65  125   35   17   37   26   14   26   266    11     9   \n",
      "11_P    89   113  168   52   32   11   38    8   10   19    22    99     8   \n",
      "12_P   174   103   40   35   18   22   26    9   18   49     4    13   142   \n",
      "13_P    90   166   61   48   40    9   31   16   25   20    11    17    18   \n",
      "\n",
      "      13_T  \n",
      "0_P      5  \n",
      "1_P     34  \n",
      "2_P      6  \n",
      "3_P     10  \n",
      "4_P     23  \n",
      "5_P      9  \n",
      "6_P     15  \n",
      "7_P     13  \n",
      "8_P     12  \n",
      "9_P     13  \n",
      "10_P     6  \n",
      "11_P    10  \n",
      "12_P    16  \n",
      "13_P   139  \n",
      "lr 1.878551063068185e-05\n",
      "epoch-210, loss 0.109\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter-2000, loss 0.146\n",
      "lr 1.878551063068185e-05\n",
      "epoch-211, loss 0.094\n",
      "------------------------------------\n",
      "Epoch 699832: reducing learning rate of group 0 to 1.6907e-05.\n",
      "iter-2000, loss 0.9\n",
      "lr 1.6906959567613665e-05\n",
      "epoch-212, loss 0.099\n",
      "------------------------------------\n",
      "iter-2000, loss 0.541\n",
      "lr 1.6906959567613665e-05\n",
      "epoch-213, loss 0.092\n",
      "------------------------------------\n",
      "iter-2000, loss 1.161\n",
      "lr 1.6906959567613665e-05\n",
      "epoch-214, loss 0.043\n",
      "------------------------------------\n",
      "iter-2000, loss 0.119\n",
      "lr 1.6906959567613665e-05\n",
      "epoch-215, loss 0.983\n",
      "------------------------------------\n",
      "Epoch 711833: reducing learning rate of group 0 to 1.5216e-05.\n",
      "iter-2000, loss 0.322\n",
      "lr 1.5216263610852298e-05\n",
      "epoch-216, loss 0.468\n",
      "------------------------------------\n",
      "iter-2000, loss 0.357\n",
      "lr 1.5216263610852298e-05\n",
      "epoch-217, loss 0.284\n",
      "------------------------------------\n",
      "iter-2000, loss 0.51\n",
      "lr 1.5216263610852298e-05\n",
      "epoch-218, loss 2.076\n",
      "------------------------------------\n",
      "iter-2000, loss 0.258\n",
      "Epoch 723834: reducing learning rate of group 0 to 1.3695e-05.\n",
      "lr 1.3694637249767069e-05\n",
      "epoch-219, loss 1.698\n",
      "------------------------------------\n",
      "iter-2000, loss 0.431\n",
      "Accuracy (top 1 guesses) - train =  78.81 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   14942    39    88    11    14     6     0     2     3     0     0     0   \n",
      "1_P     347  5577    95    82    30     3    19     7    23     6     2     8   \n",
      "2_P     939   178  3797    89    28    21    23     4     8     4    13     6   \n",
      "3_P    1014   141   104  3546     3     2    24     1    28     0    15     4   \n",
      "4_P    1423    68    55    13  2891     8     8    15    10     3     2     1   \n",
      "5_P     953    11    20     2     4  2464     0     5     8     3     3     1   \n",
      "6_P     444   115    93   120    23     1  2261     0    38     1     0     1   \n",
      "7_P    1059    21    15    12    13    34     2  1854     2     7    14     9   \n",
      "8_P     775   139    37    77    20    18    13     9  1653     6     4     2   \n",
      "9_P     226    66    81    11     8    24     4    20     2  1431    12     1   \n",
      "10_P    236    40    33    85     9     4     2    27     4     5  1398     2   \n",
      "11_P    165    90   183    33     4     1     5    13     4     5     2   935   \n",
      "12_P    303   129    41    13    41     0    21     1     2    10     1     0   \n",
      "13_P    152   278    41    47    42     3    48    11    48    10     3    11   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      1     0  \n",
      "1_P      5    19  \n",
      "2_P      3     0  \n",
      "3_P      2     0  \n",
      "4_P      2     3  \n",
      "5_P      0     0  \n",
      "6_P      1     3  \n",
      "7_P      0     1  \n",
      "8_P      2     3  \n",
      "9_P     17     3  \n",
      "10_P     0     0  \n",
      "11_P     3     0  \n",
      "12_P   873     1  \n",
      "13_P     7   686  \n",
      "Accuracy (top 1 guesses) - test =  49.807 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   5334    25   57  125  122   68   55  131   32   13    24     6    18   \n",
      "1_P    159  1940   79   74   55   31   45   22   28   26    20    29    32   \n",
      "2_P    355   117  847  166   44   33  142   25   29   82    43   107    19   \n",
      "3_P    670    88  148  714   40   33   89   53   46   26    80    27    30   \n",
      "4_P    738    50   79   68  738   21   82   78   25   32    22    21    17   \n",
      "5_P    530    59   30   50   34  545   47   34  179   19    18     6    15   \n",
      "6_P    331    93  221  140   82   46  325   23   61   34    28    39    32   \n",
      "7_P    628    34   25   65   70   24   21  378   31   19    35     8    15   \n",
      "8_P    342    86   38   75   32  200   62   13  222   15    14    12    16   \n",
      "9_P    161    96  137   72   51   24   25   17   27  305    19    26    29   \n",
      "10_P   152    45   56  121   37   14   36   38   13   19   269    12    10   \n",
      "11_P   105   107  180   50   43   10   42    7   14   20    21   100    12   \n",
      "12_P   164    98   53   36   18   18   25   10   20   49    13    13   144   \n",
      "13_P    92   157   61   40   32    8   33   17   19   28     7    14    18   \n",
      "\n",
      "      13_T  \n",
      "0_P      5  \n",
      "1_P     41  \n",
      "2_P     13  \n",
      "3_P      7  \n",
      "4_P     26  \n",
      "5_P      5  \n",
      "6_P     10  \n",
      "7_P     14  \n",
      "8_P     10  \n",
      "9_P     17  \n",
      "10_P     4  \n",
      "11_P    10  \n",
      "12_P     9  \n",
      "13_P   140  \n",
      "lr 1.3694637249767069e-05\n",
      "epoch-220, loss 0.105\n",
      "------------------------------------\n",
      "iter-2000, loss 0.264\n",
      "lr 1.3694637249767069e-05\n",
      "epoch-221, loss 0.048\n",
      "------------------------------------\n",
      "iter-2000, loss 0.51\n",
      "lr 1.3694637249767069e-05\n",
      "epoch-222, loss 0.752\n",
      "------------------------------------\n",
      "Epoch 735835: reducing learning rate of group 0 to 1.2325e-05.\n",
      "iter-2000, loss 0.371\n",
      "lr 1.2325173524790362e-05\n",
      "epoch-223, loss 0.107\n",
      "------------------------------------\n",
      "iter-2000, loss 0.197\n",
      "lr 1.2325173524790362e-05\n",
      "epoch-224, loss 0.062\n",
      "------------------------------------\n",
      "iter-2000, loss 0.205\n",
      "lr 1.2325173524790362e-05\n",
      "epoch-225, loss 0.285\n",
      "------------------------------------\n",
      "iter-2000, loss 0.659\n",
      "lr 1.2325173524790362e-05\n",
      "epoch-226, loss 0.796\n",
      "------------------------------------\n",
      "Epoch 747836: reducing learning rate of group 0 to 1.1093e-05.\n",
      "iter-2000, loss 0.49\n",
      "lr 1.1092656172311326e-05\n",
      "epoch-227, loss 0.447\n",
      "------------------------------------\n",
      "iter-2000, loss 0.431\n",
      "lr 1.1092656172311326e-05\n",
      "epoch-228, loss 0.286\n",
      "------------------------------------\n",
      "iter-2000, loss 0.222\n",
      "lr 1.1092656172311326e-05\n",
      "epoch-229, loss 0.005\n",
      "------------------------------------\n",
      "iter-2000, loss 0.201\n",
      "Epoch 759837: reducing learning rate of group 0 to 9.9834e-06.\n",
      "Accuracy (top 1 guesses) - train =  78.995 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   15143    37    99    12    11     7     0     1     1     3     0     1   \n",
      "1_P     328  5520   101    74    24     2    22     6    19     4     4    11   \n",
      "2_P     960   180  3751   104    31    23    18     5     7     9     8     8   \n",
      "3_P    1082   155   125  3521     3     1    20     4    34     0    14     3   \n",
      "4_P    1392    76    34     8  2893     4     7    16     8     4     1     0   \n",
      "5_P     903    17    20     2     2  2449     0    13     7     4     1     1   \n",
      "6_P     479   134    94   130    29     1  2278     1    31     1     1     0   \n",
      "7_P     873    19    12    13    16    34     2  1848     5     3    16     4   \n",
      "8_P     768   145    39    84    16    23    17     6  1671     2     3     3   \n",
      "9_P     195    57    91    11    12    29     7    17     2  1436    11     0   \n",
      "10_P    232    30    30   100     8     7     2    27     0     3  1399     0   \n",
      "11_P    152   100   183    28     4     2     7    14     4     3     4   939   \n",
      "12_P    294   125    50     6    38     4    13     0     2     4     1     0   \n",
      "13_P    177   297    54    48    43     3    37    11    42    15     6    11   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      1     0  \n",
      "1_P      4    20  \n",
      "2_P      8     1  \n",
      "3_P      2     1  \n",
      "4_P      3     0  \n",
      "5_P      1     0  \n",
      "6_P      0     2  \n",
      "7_P      0     0  \n",
      "8_P      0     3  \n",
      "9_P      5     3  \n",
      "10_P     0     0  \n",
      "11_P     2     1  \n",
      "12_P   878     2  \n",
      "13_P    12   686  \n",
      "Accuracy (top 1 guesses) - test =  50.068 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   5366    26   53  129  123   72   61  139   27   13    30    10    15   \n",
      "1_P    160  1948   71   70   59   24   42   17   35   32    19    31    37   \n",
      "2_P    364   120  891  168   39   37  139   24   25   89    47   102    21   \n",
      "3_P    710    91  144  723   41   30   88   61   55   27    79    38    34   \n",
      "4_P    712    53   75   64  734   31   77   77   18   32    17    24    22   \n",
      "5_P    512    46   33   38   32  519   44   25  171   25    14     5    14   \n",
      "6_P    344    94  220  134   96   46  334   28   51   30    34    43    31   \n",
      "7_P    599    28   32   69   70   28   17  371   27   17    31     6     9   \n",
      "8_P    358    93   26   72   34  216   66   15  241   17    18     6     9   \n",
      "9_P    158    85  132   72   36   22   30   28   24  292    22    25    34   \n",
      "10_P   155    48   62  112   31   17   32   29   14   22   271    12     9   \n",
      "11_P    83   110  162   50   43    9   40    7   17   22    16    92     6   \n",
      "12_P   161    96   51   38   24   14   28    8   20   43     6    11   146   \n",
      "13_P    79   157   59   57   36   10   31   17   21   26     9    15    20   \n",
      "\n",
      "      13_T  \n",
      "0_P      7  \n",
      "1_P     33  \n",
      "2_P     11  \n",
      "3_P      7  \n",
      "4_P     31  \n",
      "5_P      8  \n",
      "6_P     16  \n",
      "7_P     10  \n",
      "8_P     15  \n",
      "9_P     14  \n",
      "10_P     4  \n",
      "11_P     9  \n",
      "12_P    10  \n",
      "13_P   136  \n",
      "lr 9.983390555080193e-06\n",
      "epoch-230, loss 1.076\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter-2000, loss 0.166\n",
      "lr 9.983390555080193e-06\n",
      "epoch-231, loss 0.12\n",
      "------------------------------------\n",
      "iter-2000, loss 0.364\n",
      "lr 9.983390555080193e-06\n",
      "epoch-232, loss 0.192\n",
      "------------------------------------\n",
      "iter-2000, loss 0.284\n",
      "lr 9.983390555080193e-06\n",
      "epoch-233, loss 1.385\n",
      "------------------------------------\n",
      "Epoch 771838: reducing learning rate of group 0 to 8.9851e-06.\n",
      "iter-2000, loss 0.234\n",
      "lr 8.985051499572174e-06\n",
      "epoch-234, loss 0.211\n",
      "------------------------------------\n",
      "iter-2000, loss 0.135\n",
      "lr 8.985051499572174e-06\n",
      "epoch-235, loss 0.022\n",
      "------------------------------------\n",
      "iter-2000, loss 0.457\n",
      "lr 8.985051499572174e-06\n",
      "epoch-236, loss 0.34\n",
      "------------------------------------\n",
      "iter-2000, loss 0.36\n",
      "Epoch 783839: reducing learning rate of group 0 to 8.0865e-06.\n",
      "lr 8.086546349614957e-06\n",
      "epoch-237, loss 0.242\n",
      "------------------------------------\n",
      "iter-2000, loss 0.135\n",
      "lr 8.086546349614957e-06\n",
      "epoch-238, loss 0.257\n",
      "------------------------------------\n",
      "iter-2000, loss 0.753\n",
      "lr 8.086546349614957e-06\n",
      "epoch-239, loss 0.538\n",
      "------------------------------------\n",
      "iter-2000, loss 0.38\n",
      "Accuracy (top 1 guesses) - train =  79.321 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   15221    45    97    18    12     5     0     2     2     1     1     0   \n",
      "1_P     327  5583    87    71    24     2    22     9    16     5     3    10   \n",
      "2_P     948   173  3785   100    28    18    23     6     9    10    13     7   \n",
      "3_P    1034   144   113  3538     3     2    23     5    29     3    14     4   \n",
      "4_P    1306    72    43     9  2902     4     6    11     8     7     1     0   \n",
      "5_P     920    15    22     3     2  2468     0    12     8     4     0     1   \n",
      "6_P     436   130    99   121    22     1  2274     0    32     1     2     1   \n",
      "7_P     926    25    15     9    13    27     0  1862     2     5    14     9   \n",
      "8_P     800   149    37    78    22    19    15     8  1665     4     2     4   \n",
      "9_P     213    53    75     8    14    25     4    11     1  1428    17     2   \n",
      "10_P    253    35    34   100     7     7     4    24     0     5  1397     4   \n",
      "11_P    155    81   173    31     4     5     6     9     5     2     2   931   \n",
      "12_P    265   112    56    11    32     3    19     0     2     5     0     0   \n",
      "13_P    174   275    47    44    45     3    34    10    54    11     3     8   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      0     0  \n",
      "1_P      8    17  \n",
      "2_P     11     0  \n",
      "3_P      1     0  \n",
      "4_P      4     3  \n",
      "5_P      0     0  \n",
      "6_P      5     3  \n",
      "7_P      0     0  \n",
      "8_P      4     5  \n",
      "9_P     13     4  \n",
      "10_P     0     0  \n",
      "11_P     1     1  \n",
      "12_P   859     4  \n",
      "13_P    10   682  \n",
      "Accuracy (top 1 guesses) - test =  49.952 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   5373    38   60  137  128   78   52  148   31    9    29    10    25   \n",
      "1_P    155  1935   82   73   53   30   51   18   29   26    22    27    43   \n",
      "2_P    365   105  880  174   49   37  138   18   32   91    36   109    22   \n",
      "3_P    675    88  132  713   47   35   83   60   43   26    81    30    26   \n",
      "4_P    716    50   74   64  717   22   79   77   23   32    19    19    20   \n",
      "5_P    552    56   28   47   27  535   44   26  171   29    17     3    18   \n",
      "6_P    323    92  218  142   97   42  327   27   53   31    29    43    33   \n",
      "7_P    604    34   25   53   78   26   25  365   28   16    33     9     8   \n",
      "8_P    359    97   43   64   38  201   69   18  243   18    13     8    15   \n",
      "9_P    145    91  140   66   45   25   27   21   29  300    24    24    27   \n",
      "10_P   165    39   64  128   33   11   36   30   11   25   269    10     9   \n",
      "11_P    91   105  162   54   31   11   31    9   19   18    17   102     8   \n",
      "12_P   163   108   49   35   13   16   31   12   17   41    12    11   137   \n",
      "13_P    75   157   54   46   42    6   36   17   17   25    12    15    16   \n",
      "\n",
      "      13_T  \n",
      "0_P      8  \n",
      "1_P     42  \n",
      "2_P     14  \n",
      "3_P      5  \n",
      "4_P     21  \n",
      "5_P      6  \n",
      "6_P     10  \n",
      "7_P     14  \n",
      "8_P     11  \n",
      "9_P     15  \n",
      "10_P     7  \n",
      "11_P     7  \n",
      "12_P    11  \n",
      "13_P   140  \n",
      "lr 8.086546349614957e-06\n",
      "epoch-240, loss 0.001\n",
      "------------------------------------\n",
      "Epoch 795840: reducing learning rate of group 0 to 7.2779e-06.\n",
      "iter-2000, loss 0.439\n",
      "lr 7.277891714653461e-06\n",
      "epoch-241, loss 0.242\n",
      "------------------------------------\n",
      "iter-2000, loss 0.451\n",
      "lr 7.277891714653461e-06\n",
      "epoch-242, loss 0.226\n",
      "------------------------------------\n",
      "iter-2000, loss 0.219\n",
      "lr 7.277891714653461e-06\n",
      "epoch-243, loss 0.01\n",
      "------------------------------------\n",
      "iter-2000, loss 0.428\n",
      "lr 7.277891714653461e-06\n",
      "epoch-244, loss 0.137\n",
      "------------------------------------\n",
      "Epoch 807841: reducing learning rate of group 0 to 6.5501e-06.\n",
      "iter-2000, loss 0.302\n",
      "lr 6.550102543188115e-06\n",
      "epoch-245, loss 0.044\n",
      "------------------------------------\n",
      "iter-2000, loss 0.57\n",
      "lr 6.550102543188115e-06\n",
      "epoch-246, loss 0.463\n",
      "------------------------------------\n",
      "iter-2000, loss 0.407\n",
      "lr 6.550102543188115e-06\n",
      "epoch-247, loss 0.149\n",
      "------------------------------------\n",
      "iter-2000, loss 0.134\n",
      "Epoch 819842: reducing learning rate of group 0 to 5.8951e-06.\n",
      "lr 5.895092288869304e-06\n",
      "epoch-248, loss 1.493\n",
      "------------------------------------\n",
      "iter-2000, loss 0.79\n",
      "lr 5.895092288869304e-06\n",
      "epoch-249, loss 0.145\n",
      "------------------------------------\n",
      "iter-2000, loss 0.168\n",
      "Accuracy (top 1 guesses) - train =  79.497 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   15269    46    90    13    12     8     0     4     3     1     0     1   \n",
      "1_P     348  5586    95    76    26     4    12     4    24     3     2    10   \n",
      "2_P     953   173  3813    94    27    21    16     8     8     9     9     4   \n",
      "3_P    1037   148   111  3549     5     1    17     1    27     1    16     3   \n",
      "4_P    1337    69    32     3  2901     3     7    11     6     6     2     1   \n",
      "5_P     878    14    12     0     4  2457     0    11     3     1     1     1   \n",
      "6_P     467   124    92   123    24     1  2279     1    35     1     1     0   \n",
      "7_P     880    15    14    14    11    29     0  1850     1     4    13    11   \n",
      "8_P     778   140    41    78    21    18    23     7  1674     5     4     3   \n",
      "9_P     195    45    78    11    15    28     6    18     1  1433    15     3   \n",
      "10_P    238    45    43    97     4     6     6    35     0     5  1401     1   \n",
      "11_P    148    82   168    24     4     8     5    10     2     3     0   934   \n",
      "12_P    287   126    42     5    26     1    10     0     1     8     0     0   \n",
      "13_P    163   279    52    54    50     4    49     9    48    11     5     9   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      1     0  \n",
      "1_P      8    21  \n",
      "2_P      5     1  \n",
      "3_P      0     2  \n",
      "4_P      2     2  \n",
      "5_P      0     0  \n",
      "6_P      3     5  \n",
      "7_P      0     0  \n",
      "8_P      2     3  \n",
      "9_P     15     3  \n",
      "10_P     1     0  \n",
      "11_P     1     1  \n",
      "12_P   868     1  \n",
      "13_P    10   680  \n",
      "Accuracy (top 1 guesses) - test =  50.056 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   5431    27   62  150  123   77   60  140   29   11    30     9    20   \n",
      "1_P    151  1934   79   68   55   31   51   16   32   26    21    33    34   \n",
      "2_P    356   111  893  168   55   36  145   18   29   90    43   108    21   \n",
      "3_P    657    80  157  700   45   34   98   68   47   28    78    25    25   \n",
      "4_P    734    54   82   58  728   21   71   77   23   37    27    15    18   \n",
      "5_P    494    54   21   43   31  523   45   26  163   24    14     3    12   \n",
      "6_P    342   101  207  146   93   41  314   24   59   39    34    43    33   \n",
      "7_P    584    32   23   59   70   24   25  364   28   14    31    13    14   \n",
      "8_P    383    87   40   74   44  209   62   20  243   15    14    10    14   \n",
      "9_P    144    71  130   66   40   24   24   21   24  295    21    27    38   \n",
      "10_P   150    48   56  129   28   15   31   31   11   23   261     7    10   \n",
      "11_P    88   111  155   53   31    8   37   10   13   20    19    99    10   \n",
      "12_P   157   111   41   33   20   17   29   13   23   44    11     8   142   \n",
      "13_P    90   174   65   49   35   15   37   18   22   21     9    20    16   \n",
      "\n",
      "      13_T  \n",
      "0_P      4  \n",
      "1_P     37  \n",
      "2_P     16  \n",
      "3_P      7  \n",
      "4_P     26  \n",
      "5_P      5  \n",
      "6_P     14  \n",
      "7_P     14  \n",
      "8_P     12  \n",
      "9_P     10  \n",
      "10_P     7  \n",
      "11_P     8  \n",
      "12_P    17  \n",
      "13_P   134  \n",
      "lr 5.895092288869304e-06\n",
      "epoch-250, loss 0.486\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter-2000, loss 0.314\n",
      "lr 5.895092288869304e-06\n",
      "epoch-251, loss 0.339\n",
      "------------------------------------\n",
      "Epoch 831843: reducing learning rate of group 0 to 5.3056e-06.\n",
      "iter-2000, loss 1.304\n",
      "lr 5.305583059982374e-06\n",
      "epoch-252, loss 3.543\n",
      "------------------------------------\n",
      "iter-2000, loss 0.384\n",
      "lr 5.305583059982374e-06\n",
      "epoch-253, loss 0.245\n",
      "------------------------------------\n",
      "iter-2000, loss 0.476\n",
      "lr 5.305583059982374e-06\n",
      "epoch-254, loss 0.719\n",
      "------------------------------------\n",
      "iter-2000, loss 0.201\n",
      "lr 5.305583059982374e-06\n",
      "epoch-255, loss 2.357\n",
      "------------------------------------\n",
      "Epoch 843844: reducing learning rate of group 0 to 4.7750e-06.\n",
      "iter-2000, loss 0.473\n",
      "lr 4.775024753984137e-06\n",
      "epoch-256, loss 0.105\n",
      "------------------------------------\n",
      "iter-2000, loss 0.193\n",
      "lr 4.775024753984137e-06\n",
      "epoch-257, loss 1.043\n",
      "------------------------------------\n",
      "iter-2000, loss 0.112\n",
      "lr 4.775024753984137e-06\n",
      "epoch-258, loss 0.012\n",
      "------------------------------------\n",
      "iter-2000, loss 0.121\n",
      "Epoch 855845: reducing learning rate of group 0 to 4.2975e-06.\n",
      "lr 4.297522278585723e-06\n",
      "epoch-259, loss 0.24\n",
      "------------------------------------\n",
      "iter-2000, loss 0.117\n",
      "Accuracy (top 1 guesses) - train =  79.515 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   15265    38    94     8    10     5     0     2     3     1     0     0   \n",
      "1_P     338  5527    93    83    18     7    28    10    16     6     2     9   \n",
      "2_P     963   165  3824   107    22    17    26     6     7     5    11    11   \n",
      "3_P    1043   156    93  3595     3     3    27     2    29     2    11     6   \n",
      "4_P    1327    69    39     6  2914     4     8     5     4     4     0     0   \n",
      "5_P     881    15    24     1     3  2453     0    10    13     2     1     3   \n",
      "6_P     459   143    90   103    16     0  2259     0    26     1     2     0   \n",
      "7_P     918    25    22     9    12    31     1  1855     5     7    10     6   \n",
      "8_P     764   144    50    59    14    24    14     5  1678     4     5     5   \n",
      "9_P     207    45    86     8    12    27     5    17     0  1432     9     3   \n",
      "10_P    227    35    29    85     4    10     5    31     1     6  1409     2   \n",
      "11_P    158   109   149    24     4     3     5    14     4     2     4   927   \n",
      "12_P    264   125    41     5    37     3    15     0     4     7     0     0   \n",
      "13_P    164   296    49    48    61     2    37    12    43    12     5     9   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      0     0  \n",
      "1_P      5    15  \n",
      "2_P      8     3  \n",
      "3_P      0     1  \n",
      "4_P      3     4  \n",
      "5_P      1     0  \n",
      "6_P      2     2  \n",
      "7_P      0     0  \n",
      "8_P      0     2  \n",
      "9_P      4     1  \n",
      "10_P     1     2  \n",
      "11_P     2     0  \n",
      "12_P   881     4  \n",
      "13_P     9   685  \n",
      "Accuracy (top 1 guesses) - test =  50.371 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   5449    34   61  151  124   69   63  157   35    9    29    11    16   \n",
      "1_P    144  1952   87   63   59   31   44   23   27   28    16    30    36   \n",
      "2_P    353   104  886  175   50   35  121   21   31   81    44   106    25   \n",
      "3_P    694    89  140  729   43   36   87   58   45   27    83    28    31   \n",
      "4_P    703    49   82   64  719   21   83   76   21   29    15    19    20   \n",
      "5_P    499    48   28   50   33  537   42   26  177   23    20     6    12   \n",
      "6_P    326    92  196  139   93   46  331   26   62   44    33    37    33   \n",
      "7_P    593    32   22   59   74   22   23  361   21   21    25     9    15   \n",
      "8_P    371    97   39   58   38  203   70   19  231   12    13     8    11   \n",
      "9_P    145    90  133   64   43   22   25   20   31  298    20    25    33   \n",
      "10_P   154    47   72  115   32   15   42   26   14   22   269    16    12   \n",
      "11_P    92   115  169   47   33   11   35    8   18   20    19    94     5   \n",
      "12_P   159    89   41   31   17   15   27    7   15   50    16    12   142   \n",
      "13_P    79   157   55   51   40   12   36   18   18   23    11    19    16   \n",
      "\n",
      "      13_T  \n",
      "0_P      3  \n",
      "1_P     40  \n",
      "2_P     16  \n",
      "3_P      4  \n",
      "4_P     26  \n",
      "5_P      6  \n",
      "6_P     12  \n",
      "7_P     11  \n",
      "8_P      9  \n",
      "9_P     14  \n",
      "10_P     7  \n",
      "11_P    14  \n",
      "12_P    10  \n",
      "13_P   139  \n",
      "lr 4.297522278585723e-06\n",
      "epoch-260, loss 0.006\n",
      "------------------------------------\n",
      "iter-2000, loss 0.283\n",
      "lr 4.297522278585723e-06\n",
      "epoch-261, loss 0.191\n",
      "------------------------------------\n",
      "iter-2000, loss 0.209\n",
      "lr 4.297522278585723e-06\n",
      "epoch-262, loss 0.004\n",
      "------------------------------------\n",
      "Epoch 867846: reducing learning rate of group 0 to 3.8678e-06.\n",
      "iter-2000, loss 0.257\n",
      "lr 3.867770050727151e-06\n",
      "epoch-263, loss 0.058\n",
      "------------------------------------\n",
      "iter-2000, loss 0.21\n",
      "lr 3.867770050727151e-06\n",
      "epoch-264, loss 0.188\n",
      "------------------------------------\n",
      "iter-2000, loss 0.234\n",
      "lr 3.867770050727151e-06\n",
      "epoch-265, loss 0.082\n",
      "------------------------------------\n",
      "iter-2000, loss 0.311\n",
      "Epoch 879847: reducing learning rate of group 0 to 3.4810e-06.\n",
      "lr 3.4809930456544357e-06\n",
      "epoch-266, loss 0.014\n",
      "------------------------------------\n",
      "iter-2000, loss 0.733\n",
      "lr 3.4809930456544357e-06\n",
      "epoch-267, loss 3.107\n",
      "------------------------------------\n",
      "iter-2000, loss 0.415\n",
      "lr 3.4809930456544357e-06\n",
      "epoch-268, loss 1.472\n",
      "------------------------------------\n",
      "iter-2000, loss 0.581\n",
      "lr 3.4809930456544357e-06\n",
      "epoch-269, loss 0.177\n",
      "------------------------------------\n",
      "Epoch 891848: reducing learning rate of group 0 to 3.1329e-06.\n",
      "iter-2000, loss 0.445\n",
      "Accuracy (top 1 guesses) - train =  79.581 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   15330    56   100    15     9     6     0     3     2     1     0     1   \n",
      "1_P     324  5574    90    74    23     8    16     6    15     3     3     9   \n",
      "2_P     994   183  3778   102    20    22    16     4     4     8     9     7   \n",
      "3_P    1048   147   108  3566     1     2    17     2    24     1    10     4   \n",
      "4_P    1284    77    35     7  2909     2     9     8     7     3     1     1   \n",
      "5_P     842    13    18     1     4  2452     0    17     9     3     0     0   \n",
      "6_P     465   118    96   119    25     0  2278     0    36     1     0     0   \n",
      "7_P     893    18    16    15    13    32     0  1843     2     6    14     6   \n",
      "8_P     786   137    36    73    13    21    18     6  1677     3     4     2   \n",
      "9_P     216    40    82    12    10    28     5    19     1  1435    11     1   \n",
      "10_P    219    40    49    75     5    10     5    33     1     5  1411     5   \n",
      "11_P    165    89   176    18     2     3     5    17     4     5     2   935   \n",
      "12_P    262   113    55     4    38     0    21     0     1     7     0     0   \n",
      "13_P    150   287    44    60    58     3    40    11    50    10     4    10   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      1     0  \n",
      "1_P      5    17  \n",
      "2_P      5     2  \n",
      "3_P      0     4  \n",
      "4_P      3     3  \n",
      "5_P      1     0  \n",
      "6_P      4     3  \n",
      "7_P      0     1  \n",
      "8_P      3     2  \n",
      "9_P     12     1  \n",
      "10_P     0     0  \n",
      "11_P     1     1  \n",
      "12_P   871     3  \n",
      "13_P    10   682  \n",
      "Accuracy (top 1 guesses) - test =  50.139 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   5402    28   54  134  125   76   58  148   31   15    30    10    26   \n",
      "1_P    169  1935   69   69   57   29   40   22   29   23    26    29    38   \n",
      "2_P    378   109  910  176   51   27  138   29   33   87    42   104    32   \n",
      "3_P    656    97  146  716   44   30   92   49   40   28    89    30    29   \n",
      "4_P    708    50   68   66  723   25   78   69   21   33    16    21    18   \n",
      "5_P    507    57   29   47   38  530   40   27  176   21    21     6    13   \n",
      "6_P    350    90  215  140   83   49  325   24   51   39    32    41    27   \n",
      "7_P    598    32   29   57   60   23   20  369   29   18    30    12     9   \n",
      "8_P    367    91   39   58   31  203   71   17  245   13    16    12    16   \n",
      "9_P    152    79  128   61   48   31   26   21   20  293    20    27    38   \n",
      "10_P   155    53   62  129   32   17   29   31   15   25   259     8     9   \n",
      "11_P    85   113  159   54   41    7   41    8   16   20    15    93     4   \n",
      "12_P   152    94   48   34   18   15   36   10   18   51    12    12   137   \n",
      "13_P    82   167   55   55   47   13   35   22   22   21     5    15    11   \n",
      "\n",
      "      13_T  \n",
      "0_P      9  \n",
      "1_P     35  \n",
      "2_P     14  \n",
      "3_P      6  \n",
      "4_P     20  \n",
      "5_P      3  \n",
      "6_P      9  \n",
      "7_P     11  \n",
      "8_P     15  \n",
      "9_P     19  \n",
      "10_P     4  \n",
      "11_P    12  \n",
      "12_P    10  \n",
      "13_P   144  \n",
      "lr 3.1328937410889924e-06\n",
      "epoch-270, loss 0.094\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter-2000, loss 0.631\n",
      "lr 3.1328937410889924e-06\n",
      "epoch-271, loss 0.624\n",
      "------------------------------------\n",
      "iter-2000, loss 0.413\n",
      "lr 3.1328937410889924e-06\n",
      "epoch-272, loss 3.074\n",
      "------------------------------------\n",
      "iter-2000, loss 2.566\n",
      "lr 3.1328937410889924e-06\n",
      "epoch-273, loss 0.219\n",
      "------------------------------------\n",
      "Epoch 903849: reducing learning rate of group 0 to 2.8196e-06.\n",
      "iter-2000, loss 0.182\n",
      "lr 2.8196043669800934e-06\n",
      "epoch-274, loss 0.203\n",
      "------------------------------------\n",
      "iter-2000, loss 0.667\n",
      "lr 2.8196043669800934e-06\n",
      "epoch-275, loss 0.295\n",
      "------------------------------------\n",
      "iter-2000, loss 0.39\n",
      "lr 2.8196043669800934e-06\n",
      "epoch-276, loss 0.049\n",
      "------------------------------------\n",
      "iter-2000, loss 0.26\n",
      "Epoch 915850: reducing learning rate of group 0 to 2.5376e-06.\n",
      "lr 2.537643930282084e-06\n",
      "epoch-277, loss 0.161\n",
      "------------------------------------\n",
      "iter-2000, loss 0.372\n",
      "lr 2.537643930282084e-06\n",
      "epoch-278, loss 0.112\n",
      "------------------------------------\n",
      "iter-2000, loss 0.575\n",
      "lr 2.537643930282084e-06\n",
      "epoch-279, loss 0.339\n",
      "------------------------------------\n",
      "iter-2000, loss 0.2\n",
      "Accuracy (top 1 guesses) - train =  79.725 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   15358    34   120    11     8     4     0     2     5     2     1     2   \n",
      "1_P     333  5585    98    75    23     4    22     4    26     8     4    11   \n",
      "2_P     968   165  3777    90    29    18    19     4     4     4    11     6   \n",
      "3_P    1017   145   121  3580     1     1    24     0    26     1    11     5   \n",
      "4_P    1320    74    48     7  2913     4     6     9     5     3     0     0   \n",
      "5_P     879    17    18     4     1  2475     0    10    12     4     2     0   \n",
      "6_P     453   131    80   107    24     0  2277     2    31     1     1     0   \n",
      "7_P     871    16    12    16    17    24     1  1863     2     8    14     7   \n",
      "8_P     768   142    33    71    13    13    15     6  1669     5     3     3   \n",
      "9_P     215    41    80     8    14    27     4    12     2  1434    12     0   \n",
      "10_P    233    35    25    89     5     6     2    34     1     5  1405     3   \n",
      "11_P    128    86   179    25     4     7     5     9     6     5     2   932   \n",
      "12_P    280   121    46     9    33     3    16     0     2     5     1     0   \n",
      "13_P    155   300    46    49    45     3    39    14    42     6     2    12   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      1     0  \n",
      "1_P      4    21  \n",
      "2_P      6     0  \n",
      "3_P      0     0  \n",
      "4_P      5     3  \n",
      "5_P      0     0  \n",
      "6_P      1     5  \n",
      "7_P      0     0  \n",
      "8_P      0     4  \n",
      "9_P     12     2  \n",
      "10_P     0     1  \n",
      "11_P     1     3  \n",
      "12_P   877     3  \n",
      "13_P     9   677  \n",
      "Accuracy (top 1 guesses) - test =  50.359 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   5442    33   50  141  118   79   65  149   25   10    28    13    22   \n",
      "1_P    139  1945   83   76   49   31   43   20   38   27    22    27    37   \n",
      "2_P    368   114  876  177   59   26  126   21   33   82    44   102    24   \n",
      "3_P    661    93  149  709   36   29  101   57   45   29    83    31    32   \n",
      "4_P    684    55   74   65  736   24   71   74   30   35    22    19    17   \n",
      "5_P    518    52   34   50   24  543   40   24  174   21    17     6    15   \n",
      "6_P    331    81  220  138   95   47  332   23   54   40    32    39    30   \n",
      "7_P    597    29   30   54   75   26   16  361   23   21    25    11     7   \n",
      "8_P    345    92   38   60   41  194   70   20  235   10    19     9    14   \n",
      "9_P    154    84  131   68   45   22   24   26   23  303    20    26    35   \n",
      "10_P   161    40   65  125   38   20   35   29   11   16   269     8     9   \n",
      "11_P    98   120  160   47   37    9   36   11   17   19    15   101     7   \n",
      "12_P   166   105   44   34   15   12   35   11   20   54     7    13   139   \n",
      "13_P    97   152   57   52   30   13   35   20   18   20    10    15    19   \n",
      "\n",
      "      13_T  \n",
      "0_P      7  \n",
      "1_P     33  \n",
      "2_P     12  \n",
      "3_P      9  \n",
      "4_P     23  \n",
      "5_P      5  \n",
      "6_P     16  \n",
      "7_P     10  \n",
      "8_P      8  \n",
      "9_P     18  \n",
      "10_P     9  \n",
      "11_P    10  \n",
      "12_P     8  \n",
      "13_P   143  \n",
      "lr 2.537643930282084e-06\n",
      "epoch-280, loss 0.003\n",
      "------------------------------------\n",
      "Epoch 927851: reducing learning rate of group 0 to 2.2839e-06.\n",
      "iter-2000, loss 0.41\n",
      "lr 2.2838795372538757e-06\n",
      "epoch-281, loss 0.281\n",
      "------------------------------------\n",
      "iter-2000, loss 0.227\n",
      "lr 2.2838795372538757e-06\n",
      "epoch-282, loss 0.144\n",
      "------------------------------------\n",
      "iter-2000, loss 0.201\n",
      "lr 2.2838795372538757e-06\n",
      "epoch-283, loss 0.086\n",
      "------------------------------------\n",
      "iter-2000, loss 0.622\n",
      "lr 2.2838795372538757e-06\n",
      "epoch-284, loss 0.006\n",
      "------------------------------------\n",
      "Epoch 939852: reducing learning rate of group 0 to 2.0555e-06.\n",
      "iter-2000, loss 0.729\n",
      "lr 2.055491583528488e-06\n",
      "epoch-285, loss 0.56\n",
      "------------------------------------\n",
      "iter-2000, loss 0.307\n",
      "lr 2.055491583528488e-06\n",
      "epoch-286, loss 0.009\n",
      "------------------------------------\n",
      "iter-2000, loss 0.192\n",
      "lr 2.055491583528488e-06\n",
      "epoch-287, loss 0.341\n",
      "------------------------------------\n",
      "iter-2000, loss 0.276\n",
      "Epoch 951853: reducing learning rate of group 0 to 1.8499e-06.\n",
      "lr 1.8499424251756394e-06\n",
      "epoch-288, loss 0.304\n",
      "------------------------------------\n",
      "iter-2000, loss 0.266\n",
      "lr 1.8499424251756394e-06\n",
      "epoch-289, loss 0.005\n",
      "------------------------------------\n",
      "iter-2000, loss 0.164\n",
      "Accuracy (top 1 guesses) - train =  79.719 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   15324    50    90    12    13     8     0     3     1     2     0     0   \n",
      "1_P     347  5581   112    64    27     4    12     4    16     4     2    10   \n",
      "2_P     971   175  3810    90    23    20    20     4    10    12    15     8   \n",
      "3_P    1015   130   106  3589     3     2    27     1    21     1     5     3   \n",
      "4_P    1278    54    44     4  2901     6     6     4     5     2     0     0   \n",
      "5_P     916    19    23     2     5  2453     0    13    10     4     4     0   \n",
      "6_P     460   116    93   108    21     0  2289     0    32     0     0     1   \n",
      "7_P     861    25    14     9     9    38     0  1870     3     9    16     6   \n",
      "8_P     796   149    30    94    14    13    11     4  1686     4     3     3   \n",
      "9_P     208    55    88    14    16    28     5    11     2  1429     7     1   \n",
      "10_P    230    41    38    79     5    10     3    25     3     6  1405     3   \n",
      "11_P    159    95   148    22     4     3     3    15     3     2     5   938   \n",
      "12_P    259   128    40     7    36     1    14     1     4     7     2     0   \n",
      "13_P    154   274    47    47    53     3    40    14    37     9     5     8   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      0     0  \n",
      "1_P     10    17  \n",
      "2_P      3     0  \n",
      "3_P      0     1  \n",
      "4_P      4     5  \n",
      "5_P      0     0  \n",
      "6_P      6     3  \n",
      "7_P      1     0  \n",
      "8_P      2     5  \n",
      "9_P     18     4  \n",
      "10_P     1     1  \n",
      "11_P     1     0  \n",
      "12_P   864     3  \n",
      "13_P     6   680  \n",
      "Accuracy (top 1 guesses) - test =  50.376 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   5416    31   55  135  129   73   61  147   34    9    27    11    16   \n",
      "1_P    143  1931   76   75   51   32   51   23   25   25    24    32    33   \n",
      "2_P    371   123  887  178   51   42  139   21   28   83    39    96    30   \n",
      "3_P    658    84  143  731   41   33   90   56   44   30    81    30    29   \n",
      "4_P    731    53   76   61  732   21   75   70   20   35    22    22    15   \n",
      "5_P    518    64   31   39   33  536   34   24  177   26    23     3    14   \n",
      "6_P    338    92  222  133   94   42  332   26   52   35    31    43    27   \n",
      "7_P    591    33   34   52   69   23   26  372   26   11    31     6    12   \n",
      "8_P    372    85   40   60   38  195   64   21  243   19    15    12    17   \n",
      "9_P    139    83  121   69   49   29   30   26   26  302    16    28    30   \n",
      "10_P   145    45   63  123   30   14   35   31   14   25   269    12    10   \n",
      "11_P    86   117  155   53   33    6   34    5   17   22    18    98     6   \n",
      "12_P   164    92   49   31   19   19   27   10   16   43     8     9   147   \n",
      "13_P    89   162   59   56   29   10   31   14   24   22     9    18    21   \n",
      "\n",
      "      13_T  \n",
      "0_P      5  \n",
      "1_P     35  \n",
      "2_P     10  \n",
      "3_P      7  \n",
      "4_P     25  \n",
      "5_P      8  \n",
      "6_P     19  \n",
      "7_P     11  \n",
      "8_P     10  \n",
      "9_P     12  \n",
      "10_P     7  \n",
      "11_P    11  \n",
      "12_P     9  \n",
      "13_P   142  \n",
      "lr 1.8499424251756394e-06\n",
      "epoch-290, loss 0.241\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter-2000, loss 0.332\n",
      "lr 1.8499424251756394e-06\n",
      "epoch-291, loss 0.011\n",
      "------------------------------------\n",
      "Epoch 963854: reducing learning rate of group 0 to 1.6649e-06.\n",
      "iter-2000, loss 0.125\n",
      "lr 1.6649481826580756e-06\n",
      "epoch-292, loss 0.088\n",
      "------------------------------------\n",
      "iter-2000, loss 0.778\n",
      "lr 1.6649481826580756e-06\n",
      "epoch-293, loss 0.543\n",
      "------------------------------------\n",
      "iter-2000, loss 0.564\n",
      "lr 1.6649481826580756e-06\n",
      "epoch-294, loss 0.228\n",
      "------------------------------------\n",
      "iter-2000, loss 0.151\n",
      "Epoch 975855: reducing learning rate of group 0 to 1.4985e-06.\n",
      "lr 1.4984533643922681e-06\n",
      "epoch-295, loss 0.393\n",
      "------------------------------------\n",
      "iter-2000, loss 0.744\n",
      "lr 1.4984533643922681e-06\n",
      "epoch-296, loss 0.014\n",
      "------------------------------------\n",
      "iter-2000, loss 0.222\n",
      "lr 1.4984533643922681e-06\n",
      "epoch-297, loss 0.259\n",
      "------------------------------------\n",
      "iter-2000, loss 0.094\n",
      "lr 1.4984533643922681e-06\n",
      "epoch-298, loss 1.153\n",
      "------------------------------------\n",
      "iter-2000, loss 0.254\n",
      "Epoch 987856: reducing learning rate of group 0 to 1.3486e-06.\n",
      "lr 1.3486080279530413e-06\n",
      "epoch-299, loss 0.012\n",
      "------------------------------------\n",
      "iter-2000, loss 0.409\n",
      "Accuracy (top 1 guesses) - train =  79.897 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   15491    42    98    10    13     8     0     0     5     1     0     1   \n",
      "1_P     338  5571    94    64    31     6    20     8    22     3     1     8   \n",
      "2_P     931   180  3813    94    19    21    21     4     9     9    14    10   \n",
      "3_P     990   152   110  3561     2     1    29     2    29     1    14     5   \n",
      "4_P    1204    75    37     9  2903     5     8    10    11     6     2     0   \n",
      "5_P     881    12    19     2     2  2450     0    13    10     3     1     1   \n",
      "6_P     466   104   103   128    23     0  2280     0    28     1     0     0   \n",
      "7_P     883    20    15     7    10    32     0  1859     2     5     7     4   \n",
      "8_P     796   155    31    86    16    20    15     4  1668     6     4     3   \n",
      "9_P     195    50    74     9    13    28     6    16     4  1430    10     0   \n",
      "10_P    233    38    25    87     6     6     0    29     0     7  1407     5   \n",
      "11_P    144    95   159    27     3     4     5    11     2     3     4   931   \n",
      "12_P    259   118    58     7    34     5    11     0     0     6     0     0   \n",
      "13_P    167   280    47    50    55     3    35    13    43    10     5    13   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      1     0  \n",
      "1_P      7    22  \n",
      "2_P      8     1  \n",
      "3_P      0     0  \n",
      "4_P      1     0  \n",
      "5_P      1     0  \n",
      "6_P      3     1  \n",
      "7_P      0     0  \n",
      "8_P      0     1  \n",
      "9_P     10     4  \n",
      "10_P     1     2  \n",
      "11_P     2     2  \n",
      "12_P   873     4  \n",
      "13_P     9   682  \n",
      "Accuracy (top 1 guesses) - test =  50.571 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   5496    35   57  152  125   71   52  146   35   11    26     7    24   \n",
      "1_P    148  1937   87   78   60   31   41   20   35   33    24    25    37   \n",
      "2_P    368   119  880  172   58   34  136   23   28   87    43   106    24   \n",
      "3_P    652    94  152  711   39   37   98   61   44   30    75    32    25   \n",
      "4_P    703    57   81   63  726   21   72   76   27   30    16    22    16   \n",
      "5_P    523    54   24   45   34  547   46   19  171   18    17     7    12   \n",
      "6_P    325    95  205  129   95   42  333   21   54   38    33    42    29   \n",
      "7_P    547    37   29   51   70   24   26  374   28   22    32     7    13   \n",
      "8_P    377    77   35   57   31  196   65   25  236   15    13     9    14   \n",
      "9_P    142    78  137   67   43   22   25   26   23  291    25    27    35   \n",
      "10_P   163    50   61  125   31   15   37   23   12   21   272    14    10   \n",
      "11_P    86   110  165   62   32   10   30   10   16   22    17    96     9   \n",
      "12_P   142    94   40   35   20   16   30    8   16   44     9     9   141   \n",
      "13_P    89   158   58   49   34    9   38   14   21   25    11    17    18   \n",
      "\n",
      "      13_T  \n",
      "0_P      7  \n",
      "1_P     37  \n",
      "2_P     12  \n",
      "3_P      8  \n",
      "4_P     24  \n",
      "5_P      6  \n",
      "6_P     11  \n",
      "7_P     12  \n",
      "8_P     10  \n",
      "9_P     13  \n",
      "10_P     3  \n",
      "11_P    12  \n",
      "12_P    11  \n",
      "13_P   145  \n",
      "lr 1.3486080279530413e-06\n",
      "epoch-300, loss 0.109\n",
      "------------------------------------\n",
      "iter-2000, loss 0.104\n",
      "lr 1.3486080279530413e-06\n",
      "epoch-301, loss 0.029\n",
      "------------------------------------\n",
      "iter-2000, loss 0.325\n",
      "lr 1.3486080279530413e-06\n",
      "epoch-302, loss 2.299\n",
      "------------------------------------\n",
      "Epoch 999857: reducing learning rate of group 0 to 1.2137e-06.\n",
      "iter-2000, loss 0.092\n",
      "lr 1.2137472251577372e-06\n",
      "epoch-303, loss 0.159\n",
      "------------------------------------\n",
      "iter-2000, loss 0.519\n",
      "lr 1.2137472251577372e-06\n",
      "epoch-304, loss 0.025\n",
      "------------------------------------\n",
      "iter-2000, loss 0.163\n",
      "lr 1.2137472251577372e-06\n",
      "epoch-305, loss 0.004\n",
      "------------------------------------\n",
      "iter-2000, loss 0.331\n",
      "Epoch 1011858: reducing learning rate of group 0 to 1.0924e-06.\n",
      "lr 1.0923725026419636e-06\n",
      "epoch-306, loss 0.025\n",
      "------------------------------------\n",
      "iter-2000, loss 0.376\n",
      "lr 1.0923725026419636e-06\n",
      "epoch-307, loss 0.354\n",
      "------------------------------------\n",
      "iter-2000, loss 0.549\n",
      "lr 1.0923725026419636e-06\n",
      "epoch-308, loss 0.042\n",
      "------------------------------------\n",
      "iter-2000, loss 0.4\n",
      "lr 1.0923725026419636e-06\n",
      "epoch-309, loss 0.586\n",
      "------------------------------------\n",
      "Epoch 1023859: reducing learning rate of group 0 to 9.8314e-07.\n",
      "iter-2000, loss 0.235\n",
      "Accuracy (top 1 guesses) - train =  79.83 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   15386    33   111    15     9     8     1     1     3     1     0     1   \n",
      "1_P     330  5577   101    62    20     6    12     5    27     8     6    12   \n",
      "2_P     946   176  3804    94    28    13    20     5     8     8     6     5   \n",
      "3_P    1004   156   112  3587     3     3    11     2    27     1    16     2   \n",
      "4_P    1280    59    34     4  2914     2     6     6     7     5     0     0   \n",
      "5_P     874     9    18     3     4  2464     0    13     7     1     4     0   \n",
      "6_P     442   134    92   108    20     0  2276     0    28     0     1     0   \n",
      "7_P     910    19    15     8    14    30     1  1873     2     8    11     7   \n",
      "8_P     806   143    35    90    13    17    21     6  1673     1     3     2   \n",
      "9_P     199    45    69    12    12    30     7    11     0  1429    13     1   \n",
      "10_P    228    39    31    78     5     9     3    22     1     6  1403     4   \n",
      "11_P    160    83   153    28     6     2     5    12     5     3     3   935   \n",
      "12_P    249   132    57     8    37     2    23     0     0     9     1     1   \n",
      "13_P    164   287    51    44    45     3    44    13    45    11     2    11   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      0     0  \n",
      "1_P      8    16  \n",
      "2_P      3     0  \n",
      "3_P      1     0  \n",
      "4_P      3     5  \n",
      "5_P      0     0  \n",
      "6_P      2     6  \n",
      "7_P      0     0  \n",
      "8_P      3     1  \n",
      "9_P      9     3  \n",
      "10_P     1     0  \n",
      "11_P     2     4  \n",
      "12_P   877     1  \n",
      "13_P     7   683  \n",
      "Accuracy (top 1 guesses) - test =  50.313 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   5397    29   60  142  127   80   65  159   38   11    34    17    21   \n",
      "1_P    137  1960   72   70   48   28   43   18   32   25    23    32    35   \n",
      "2_P    370   116  883  172   55   33  141   23   29   77    37   104    27   \n",
      "3_P    654    88  155  722   43   41   91   57   50   32    88    34    28   \n",
      "4_P    696    49   72   67  733   27   68   74   15   33    17    17    14   \n",
      "5_P    529    55   28   42   32  534   44   24  159   21    18     5    10   \n",
      "6_P    345    89  218  148   87   38  326   21   52   42    24    38    34   \n",
      "7_P    604    33   29   60   72   23   17  363   32   18    25     8    13   \n",
      "8_P    356    90   40   57   36  204   69   13  247   16    16    11    12   \n",
      "9_P    144    75  124   62   39   23   23   22   19  302    25    22    32   \n",
      "10_P   160    42   56  117   26   13   38   34   11   20   267    10    11   \n",
      "11_P   101   110  161   51   38    8   40    7   15   27    18    95     8   \n",
      "12_P   167   105   54   37   19   14   31   11   22   42     9    12   149   \n",
      "13_P   101   154   59   49   43    9   33   20   25   21    12    15    13   \n",
      "\n",
      "      13_T  \n",
      "0_P      5  \n",
      "1_P     36  \n",
      "2_P     11  \n",
      "3_P     11  \n",
      "4_P     23  \n",
      "5_P      4  \n",
      "6_P     10  \n",
      "7_P     13  \n",
      "8_P     12  \n",
      "9_P     15  \n",
      "10_P     5  \n",
      "11_P    12  \n",
      "12_P     9  \n",
      "13_P   145  \n",
      "lr 9.831352523777673e-07\n",
      "epoch-310, loss 0.161\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter-2000, loss 0.236\n",
      "lr 9.831352523777673e-07\n",
      "epoch-311, loss 0.6\n",
      "------------------------------------\n",
      "iter-2000, loss 0.482\n",
      "lr 9.831352523777673e-07\n",
      "epoch-312, loss 0.334\n",
      "------------------------------------\n",
      "iter-2000, loss 0.184\n",
      "lr 9.831352523777673e-07\n",
      "epoch-313, loss 1.231\n",
      "------------------------------------\n",
      "Epoch 1035860: reducing learning rate of group 0 to 8.8482e-07.\n",
      "iter-2000, loss 0.192\n",
      "lr 8.848217271399906e-07\n",
      "epoch-314, loss 0.022\n",
      "------------------------------------\n",
      "iter-2000, loss 0.772\n",
      "lr 8.848217271399906e-07\n",
      "epoch-315, loss 0.002\n",
      "------------------------------------\n",
      "iter-2000, loss 0.178\n",
      "lr 8.848217271399906e-07\n",
      "epoch-316, loss 0.008\n",
      "------------------------------------\n",
      "iter-2000, loss 0.347\n",
      "Epoch 1047861: reducing learning rate of group 0 to 7.9634e-07.\n",
      "lr 7.963395544259916e-07\n",
      "epoch-317, loss 0.693\n",
      "------------------------------------\n",
      "iter-2000, loss 0.345\n",
      "lr 7.963395544259916e-07\n",
      "epoch-318, loss 0.339\n",
      "------------------------------------\n",
      "iter-2000, loss 0.707\n",
      "lr 7.963395544259916e-07\n",
      "epoch-319, loss 0.047\n",
      "------------------------------------\n",
      "iter-2000, loss 0.369\n",
      "Accuracy (top 1 guesses) - train =  79.742 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   15334    45   112    14    15     3     0     1     3     0     1     0   \n",
      "1_P     344  5613    85    80    21     8    15     7    21     5     5    14   \n",
      "2_P     965   169  3815    94    25    18    18     4     7    12    11     8   \n",
      "3_P    1023   156    98  3570     3     1    22     1    32     1     9     2   \n",
      "4_P    1259    72    33     4  2907     3     6     7     5     3     0     0   \n",
      "5_P     874     7    14     3     1  2454     0    15     3     3     4     0   \n",
      "6_P     466   113    81   110    21     1  2282     0    28     2     2     1   \n",
      "7_P     905    20    13    17    14    32     2  1858     5     6    11     8   \n",
      "8_P     800   143    34    89    22    22    14     6  1678     3     6     1   \n",
      "9_P     211    58   101    11    11    34     5    23     4  1432    18     2   \n",
      "10_P    216    36    39    75     5     7     4    27     0     5  1396     3   \n",
      "11_P    149    84   171    21     4     0     5     7     5     2     2   933   \n",
      "12_P    281   112    43     4    32     2    15     1     1     7     1     0   \n",
      "13_P    151   264    44    49    49     4    42    12    41    10     3     9   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      0     0  \n",
      "1_P      7    16  \n",
      "2_P      9     0  \n",
      "3_P      0     1  \n",
      "4_P      4     2  \n",
      "5_P      0     0  \n",
      "6_P      1     4  \n",
      "7_P      0     1  \n",
      "8_P      1     4  \n",
      "9_P      7     1  \n",
      "10_P     1     1  \n",
      "11_P     1     1  \n",
      "12_P   874     2  \n",
      "13_P    11   686  \n",
      "Accuracy (top 1 guesses) - test =  50.396 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   5434    28   63  151  121   78   56  141   31   14    28     9    21   \n",
      "1_P    148  1952   75   68   52   33   46   18   37   25    19    26    37   \n",
      "2_P    380   118  874  164   53   31  136   19   36   85    43   103    28   \n",
      "3_P    666    92  157  725   41   35   84   55   44   28    83    38    29   \n",
      "4_P    694    48   79   65  733   22   73   73   23   32    25    23    17   \n",
      "5_P    515    57   33   43   29  532   48   24  164   27    17     5    11   \n",
      "6_P    337    94  226  139   84   47  338   18   55   34    31    43    24   \n",
      "7_P    602    29   23   52   80   25   20  377   25   10    30    11    13   \n",
      "8_P    359    83   29   65   42  200   65   23  236   13    12    12    18   \n",
      "9_P    136    76  127   59   39   21   23   24   26  313    18    22    35   \n",
      "10_P   162    39   62  116   30   15   31   38   16   24   263     9    11   \n",
      "11_P    77   118  158   64   36    8   47    6   12   23    23    86     6   \n",
      "12_P   158   107   49   45   23   16   24   10   20   32    14    12   140   \n",
      "13_P    93   154   56   40   35   12   38   20   21   27     7    21    17   \n",
      "\n",
      "      13_T  \n",
      "0_P      2  \n",
      "1_P     35  \n",
      "2_P     12  \n",
      "3_P      6  \n",
      "4_P     25  \n",
      "5_P      9  \n",
      "6_P     14  \n",
      "7_P     12  \n",
      "8_P     17  \n",
      "9_P     14  \n",
      "10_P     4  \n",
      "11_P     8  \n",
      "12_P    13  \n",
      "13_P   140  \n",
      "lr 7.963395544259916e-07\n",
      "epoch-320, loss 0.034\n",
      "------------------------------------\n",
      "Epoch 1059862: reducing learning rate of group 0 to 7.1671e-07.\n",
      "iter-2000, loss 0.359\n",
      "lr 7.167055989833925e-07\n",
      "epoch-321, loss 0.228\n",
      "------------------------------------\n",
      "iter-2000, loss 0.422\n",
      "lr 7.167055989833925e-07\n",
      "epoch-322, loss 0.054\n",
      "------------------------------------\n",
      "iter-2000, loss 0.116\n",
      "lr 7.167055989833925e-07\n",
      "epoch-323, loss 0.135\n",
      "------------------------------------\n",
      "iter-2000, loss 0.079\n",
      "lr 7.167055989833925e-07\n",
      "epoch-324, loss 0.029\n",
      "------------------------------------\n",
      "Epoch 1071863: reducing learning rate of group 0 to 6.4504e-07.\n",
      "iter-2000, loss 0.347\n",
      "lr 6.450350390850532e-07\n",
      "epoch-325, loss 0.046\n",
      "------------------------------------\n",
      "iter-2000, loss 0.215\n",
      "lr 6.450350390850532e-07\n",
      "epoch-326, loss 0.027\n",
      "------------------------------------\n",
      "iter-2000, loss 0.136\n",
      "lr 6.450350390850532e-07\n",
      "epoch-327, loss 0.635\n",
      "------------------------------------\n",
      "iter-2000, loss 0.285\n",
      "Epoch 1083864: reducing learning rate of group 0 to 5.8053e-07.\n",
      "lr 5.80531535176548e-07\n",
      "epoch-328, loss 0.169\n",
      "------------------------------------\n",
      "iter-2000, loss 0.347\n",
      "lr 5.80531535176548e-07\n",
      "epoch-329, loss 0.68\n",
      "------------------------------------\n",
      "iter-2000, loss 0.3\n",
      "Accuracy (top 1 guesses) - train =  79.842 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   15392    39    97    10     8     6     0     3     3     0     0     1   \n",
      "1_P     352  5585    88    70    27     4    15     8    19     2     3    13   \n",
      "2_P     934   177  3837    91    24    32    21     4     6     9    14     6   \n",
      "3_P     988   150   104  3580     0     2    16     3    25     0    12     3   \n",
      "4_P    1265    79    37     5  2906     5    10    11     8     3     0     1   \n",
      "5_P     813    13    22     0     1  2453     0    20     9     4     3     1   \n",
      "6_P     482   118    90   124    24     1  2282     0    34     0     1     0   \n",
      "7_P     887    23    15    11    11    25     1  1852     2     9    10     7   \n",
      "8_P     812   140    38    87    19    20    26     8  1672     4     7     3   \n",
      "9_P     207    42    54     7     9    30     7    20     2  1430    11     0   \n",
      "10_P    258    36    45    75     5     5     3    18     0     6  1404     2   \n",
      "11_P    158    85   166    25     4     1     3    12     4     3     1   935   \n",
      "12_P    277   112    44     5    46     3    15     0     4     7     1     0   \n",
      "13_P    153   293    46    51    46     2    31    10    45    14     2     9   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      1     0  \n",
      "1_P      8    20  \n",
      "2_P      3     2  \n",
      "3_P      0     1  \n",
      "4_P      3     5  \n",
      "5_P      0     0  \n",
      "6_P      1     2  \n",
      "7_P      0     0  \n",
      "8_P      1     1  \n",
      "9_P      9     2  \n",
      "10_P     0     2  \n",
      "11_P     0     0  \n",
      "12_P   876     0  \n",
      "13_P    14   684  \n",
      "Accuracy (top 1 guesses) - test =  50.471 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   5472    33   66  147  139   83   66  152   38    8    30     8    24   \n",
      "1_P    167  1937   87   67   54   33   51   19   38   27    23    26    35   \n",
      "2_P    372   109  874  177   43   36  132   20   28   88    39    96    26   \n",
      "3_P    655   100  166  729   36   25   89   58   40   30    73    38    28   \n",
      "4_P    695    52   79   68  726   21   71   80   20   32    23    20    18   \n",
      "5_P    497    55   34   48   28  537   53   26  175   33    22     3    13   \n",
      "6_P    347    89  206  122  100   44  340   24   52   37    28    36    31   \n",
      "7_P    594    23   24   62   66   27   16  368   26    9    24     8     9   \n",
      "8_P    370    97   36   60   38  200   61   15  232   15    18    10    14   \n",
      "9_P    130    70  121   64   44   20   20   24   24  292    14    36    33   \n",
      "10_P   140    43   64  114   31   17   33   32   14   28   273    13    11   \n",
      "11_P    96   118  155   50   35    9   39    6   19   24    23    95     5   \n",
      "12_P   147    96   46   38   18   14   30    7   20   47    14    13   144   \n",
      "13_P    79   173   53   50   40    9   28   15   20   17     9    18    16   \n",
      "\n",
      "      13_T  \n",
      "0_P      5  \n",
      "1_P     36  \n",
      "2_P     14  \n",
      "3_P      6  \n",
      "4_P     28  \n",
      "5_P      9  \n",
      "6_P     14  \n",
      "7_P     10  \n",
      "8_P      7  \n",
      "9_P     14  \n",
      "10_P     6  \n",
      "11_P     8  \n",
      "12_P    12  \n",
      "13_P   142  \n",
      "lr 5.80531535176548e-07\n",
      "epoch-330, loss 0.891\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter-2000, loss 0.703\n",
      "lr 5.80531535176548e-07\n",
      "epoch-331, loss 0.016\n",
      "------------------------------------\n",
      "Epoch 1095865: reducing learning rate of group 0 to 5.2248e-07.\n",
      "iter-2000, loss 0.377\n",
      "lr 5.224783816588932e-07\n",
      "epoch-332, loss 0.422\n",
      "------------------------------------\n",
      "iter-2000, loss 0.336\n",
      "lr 5.224783816588932e-07\n",
      "epoch-333, loss 0.444\n",
      "------------------------------------\n",
      "iter-2000, loss 0.132\n",
      "lr 5.224783816588932e-07\n",
      "epoch-334, loss 0.093\n",
      "------------------------------------\n",
      "iter-2000, loss 0.404\n",
      "Epoch 1107866: reducing learning rate of group 0 to 4.7023e-07.\n",
      "lr 4.702305434930039e-07\n",
      "epoch-335, loss 0.299\n",
      "------------------------------------\n",
      "iter-2000, loss 0.501\n",
      "lr 4.702305434930039e-07\n",
      "epoch-336, loss 0.259\n",
      "------------------------------------\n",
      "iter-2000, loss 0.519\n",
      "lr 4.702305434930039e-07\n",
      "epoch-337, loss 0.098\n",
      "------------------------------------\n",
      "iter-2000, loss 0.348\n",
      "lr 4.702305434930039e-07\n",
      "epoch-338, loss 0.1\n",
      "------------------------------------\n",
      "Epoch 1119867: reducing learning rate of group 0 to 4.2321e-07.\n",
      "iter-2000, loss 0.581\n",
      "lr 4.232074891437035e-07\n",
      "epoch-339, loss 1.115\n",
      "------------------------------------\n",
      "iter-2000, loss 0.246\n",
      "Accuracy (top 1 guesses) - train =  80.045 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   15454    46    99    16    13     6     0     2     4     0     1     0   \n",
      "1_P     319  5589    87    69    24     5    19     6    17     8     3    13   \n",
      "2_P     919   202  3850    72    30    19    22     1     8     4    11     6   \n",
      "3_P    1035   140   104  3606     2     0    11     3    27     0    12     2   \n",
      "4_P    1273    64    35     5  2899     5     5     8    10     2     0     0   \n",
      "5_P     854    11    21     2     1  2453     0    11     7     1     3     1   \n",
      "6_P     410   118    79   119    23     0  2288     1    33     1     1     0   \n",
      "7_P     867    18    12     9    14    30     1  1860     1    11    10     9   \n",
      "8_P     819   150    27    76    12    22    24     5  1667     4     4     1   \n",
      "9_P     190    58    69    10    14    27     6    19     3  1435     7     3   \n",
      "10_P    245    39    32    73     7     9     5    28     2     5  1410     2   \n",
      "11_P    162    75   167    27     3     4     4    17     4     2     1   936   \n",
      "12_P    272    99    50     5    35     6    11     0     4     7     1     0   \n",
      "13_P    159   283    51    52    53     3    34     8    46    11     5     8   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      2     0  \n",
      "1_P      6    16  \n",
      "2_P      9     1  \n",
      "3_P      0     0  \n",
      "4_P      3     2  \n",
      "5_P      0     0  \n",
      "6_P      3     5  \n",
      "7_P      0     0  \n",
      "8_P      2     3  \n",
      "9_P      6     4  \n",
      "10_P     0     0  \n",
      "11_P     2     2  \n",
      "12_P   873     4  \n",
      "13_P    10   682  \n",
      "Accuracy (top 1 guesses) - test =  50.413 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   5445    28   63  136  133   86   55  141   31    9    30    10    26   \n",
      "1_P    158  1943   79   60   55   29   41   25   36   26    17    30    37   \n",
      "2_P    368   103  885  160   56   29  141   17   32   85    43   104    32   \n",
      "3_P    673    87  158  734   45   26   91   60   45   26    78    37    29   \n",
      "4_P    727    59   75   69  718   21   84   73   23   34    19    20    15   \n",
      "5_P    523    60   25   44   29  536   41   28  165   18    18     3    10   \n",
      "6_P    344    86  209  127   91   43  332   23   59   45    30    39    27   \n",
      "7_P    552    32   30   48   71   24   22  372   24   15    33    11    12   \n",
      "8_P    349    91   39   66   35  196   66   21  237   13    17     8    15   \n",
      "9_P    136    92  133   72   40   27   23   26   23  299    16    25    31   \n",
      "10_P   155    49   58  131   26   18   32   29   14   21   272    11    10   \n",
      "11_P    95   118  164   54   36   13   31    8   16   28    17    97     8   \n",
      "12_P   146    97   41   40   20   15   32    9   17   49    14     7   138   \n",
      "13_P    90   150   52   55   43   12   38   14   24   19     9    18    17   \n",
      "\n",
      "      13_T  \n",
      "0_P      3  \n",
      "1_P     37  \n",
      "2_P     14  \n",
      "3_P      8  \n",
      "4_P     23  \n",
      "5_P      8  \n",
      "6_P     17  \n",
      "7_P     10  \n",
      "8_P     12  \n",
      "9_P     13  \n",
      "10_P    10  \n",
      "11_P     6  \n",
      "12_P    11  \n",
      "13_P   139  \n",
      "lr 4.232074891437035e-07\n",
      "epoch-340, loss 0.387\n",
      "------------------------------------\n",
      "iter-2000, loss 0.687\n",
      "lr 4.232074891437035e-07\n",
      "epoch-341, loss 0.013\n",
      "------------------------------------\n",
      "iter-2000, loss 0.287\n",
      "lr 4.232074891437035e-07\n",
      "epoch-342, loss 0.376\n",
      "------------------------------------\n",
      "Epoch 1131868: reducing learning rate of group 0 to 3.8089e-07.\n",
      "iter-2000, loss 0.459\n",
      "lr 3.8088674022933316e-07\n",
      "epoch-343, loss 0.108\n",
      "------------------------------------\n",
      "iter-2000, loss 0.289\n",
      "lr 3.8088674022933316e-07\n",
      "epoch-344, loss 0.534\n",
      "------------------------------------\n",
      "iter-2000, loss 0.287\n",
      "lr 3.8088674022933316e-07\n",
      "epoch-345, loss 0.401\n",
      "------------------------------------\n",
      "iter-2000, loss 0.348\n",
      "Epoch 1143869: reducing learning rate of group 0 to 3.4280e-07.\n",
      "lr 3.4279806620639985e-07\n",
      "epoch-346, loss 0.305\n",
      "------------------------------------\n",
      "iter-2000, loss 0.23\n",
      "lr 3.4279806620639985e-07\n",
      "epoch-347, loss 1.523\n",
      "------------------------------------\n",
      "iter-2000, loss 0.933\n",
      "lr 3.4279806620639985e-07\n",
      "epoch-348, loss 0.151\n",
      "------------------------------------\n",
      "iter-2000, loss 0.479\n",
      "lr 3.4279806620639985e-07\n",
      "epoch-349, loss 2.181\n",
      "------------------------------------\n",
      "Epoch 1155870: reducing learning rate of group 0 to 3.0852e-07.\n",
      "iter-2000, loss 0.103\n",
      "Accuracy (top 1 guesses) - train =  79.899 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   15440    50   100     7    12     4     0     2     4     3     0     0   \n",
      "1_P     319  5568    80    64    15     5    14     4    14     7     3    14   \n",
      "2_P     973   168  3827    85    27    24    16     3     8     5    13    11   \n",
      "3_P     985   162   119  3573     4     1    17     2    28     1     6     5   \n",
      "4_P    1266    85    36     8  2894     2     6     7     4     1     1     1   \n",
      "5_P     872     8    16     2     4  2463     0    11     8     1     0     2   \n",
      "6_P     456    98    90   114    28     0  2289     0    40     1     0     1   \n",
      "7_P     872    15    11    17     8    22     0  1857     3     9    13    10   \n",
      "8_P     800   156    35    87    23    19    16     9  1670     3     2     4   \n",
      "9_P     208    47    76     6    18    25     3    21     2  1439     5     0   \n",
      "10_P    227    33    55    95     6    12     4    32     4     4  1414     2   \n",
      "11_P    153    98   147    26     2     5     7     9     0     3     6   926   \n",
      "12_P    246   132    43     7    33     2    14     1     0     7     2     0   \n",
      "13_P    161   272    48    50    56     5    44    11    48     7     4     5   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      2     0  \n",
      "1_P      5    17  \n",
      "2_P      8     1  \n",
      "3_P      0     1  \n",
      "4_P      3     1  \n",
      "5_P      0     0  \n",
      "6_P      2     3  \n",
      "7_P      0     0  \n",
      "8_P      0     7  \n",
      "9_P     10     1  \n",
      "10_P     0     0  \n",
      "11_P     1     2  \n",
      "12_P   876     2  \n",
      "13_P     9   684  \n",
      "Accuracy (top 1 guesses) - test =  50.127 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   5405    34   48  134  127   81   50  146   32   11    29     9    23   \n",
      "1_P    162  1919   89   69   62   22   48   19   31   28    20    26    38   \n",
      "2_P    358   108  921  165   52   32  141   16   30   81    41   106    25   \n",
      "3_P    665    93  144  716   38   35   95   59   48   31    82    36    32   \n",
      "4_P    733    56   75   60  715   23   73   75   24   35    27    24    14   \n",
      "5_P    513    58   35   45   28  537   37   21  175   21    19     5    16   \n",
      "6_P    354    95  203  150  100   47  338   19   56   32    29    41    27   \n",
      "7_P    596    30   21   48   71   25   19  369   25   18    29     6    11   \n",
      "8_P    359    93   30   63   38  197   66   18  231   19    15     7    17   \n",
      "9_P    143    84  124   72   44   26   26   26   24  294    22    22    36   \n",
      "10_P   152    45   58  117   31   16   37   39   16   21   265    14    10   \n",
      "11_P    87   112  160   56   32    7   37    8   16   18    18    93     7   \n",
      "12_P   152   103   41   38   22   17   26   11   16   49     9    11   137   \n",
      "13_P    82   165   62   63   38   10   36   20   22   29     8    20    14   \n",
      "\n",
      "      13_T  \n",
      "0_P      2  \n",
      "1_P     37  \n",
      "2_P     15  \n",
      "3_P      6  \n",
      "4_P     30  \n",
      "5_P      7  \n",
      "6_P     15  \n",
      "7_P     11  \n",
      "8_P     10  \n",
      "9_P     14  \n",
      "10_P     7  \n",
      "11_P     6  \n",
      "12_P    13  \n",
      "13_P   138  \n",
      "lr 3.0851825958575986e-07\n",
      "epoch-350, loss 0.607\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter-2000, loss 0.157\n",
      "lr 3.0851825958575986e-07\n",
      "epoch-351, loss 0.803\n",
      "------------------------------------\n",
      "iter-2000, loss 0.232\n",
      "lr 3.0851825958575986e-07\n",
      "epoch-352, loss 2.271\n",
      "------------------------------------\n",
      "iter-2000, loss 0.746\n",
      "lr 3.0851825958575986e-07\n",
      "epoch-353, loss 4.375\n",
      "------------------------------------\n",
      "Epoch 1167871: reducing learning rate of group 0 to 2.7767e-07.\n",
      "iter-2000, loss 0.152\n",
      "lr 2.776664336271839e-07\n",
      "epoch-354, loss 0.399\n",
      "------------------------------------\n",
      "iter-2000, loss 0.331\n",
      "lr 2.776664336271839e-07\n",
      "epoch-355, loss 0.664\n",
      "------------------------------------\n",
      "iter-2000, loss 0.154\n",
      "lr 2.776664336271839e-07\n",
      "epoch-356, loss 1.823\n",
      "------------------------------------\n",
      "iter-2000, loss 0.374\n",
      "Epoch 1179872: reducing learning rate of group 0 to 2.4990e-07.\n",
      "lr 2.498997902644655e-07\n",
      "epoch-357, loss 0.477\n",
      "------------------------------------\n",
      "iter-2000, loss 0.328\n",
      "lr 2.498997902644655e-07\n",
      "epoch-358, loss 0.082\n",
      "------------------------------------\n",
      "iter-2000, loss 0.496\n",
      "lr 2.498997902644655e-07\n",
      "epoch-359, loss 0.338\n",
      "------------------------------------\n",
      "iter-2000, loss 0.17\n",
      "Accuracy (top 1 guesses) - train =  79.949 %\n",
      "\tConfusion Matrix train:\n",
      "         0_T   1_T   2_T   3_T   4_T   5_T   6_T   7_T   8_T   9_T  10_T  11_T  \\\n",
      "0_P   15459    44    99    10    12     6     1     0     1     2     0     0   \n",
      "1_P     325  5576    88    78    27     4    19     4    18     6     2     6   \n",
      "2_P     959   177  3823    81    33    20    26     5     6     8    10     7   \n",
      "3_P     966   145   107  3597     1     1    27     3    32     0     9     8   \n",
      "4_P    1232    68    38     6  2891     8     5     6     9     5     1     0   \n",
      "5_P     921    14    20     3     5  2450     0    13     7     5     1     0   \n",
      "6_P     463   117    98    98    29     0  2279     0    27     0     0     0   \n",
      "7_P     874    24    11     8    12    34     1  1866     3     4    18     7   \n",
      "8_P     746   145    35    85    19    19    16     4  1680     3     2     0   \n",
      "9_P     200    50    80     8    16    30     2    12     4  1431     7     1   \n",
      "10_P    230    38    35    91     5     9     2    29     3     5  1411     1   \n",
      "11_P    166    92   162    20     0     2     3    13     2     6     2   935   \n",
      "12_P    263   109    39     5    34     3    12     1     1     3     2     0   \n",
      "13_P    174   293    48    51    46     3    37    13    40    13     4    16   \n",
      "\n",
      "      12_T  13_T  \n",
      "0_P      1     0  \n",
      "1_P      7    23  \n",
      "2_P      9     1  \n",
      "3_P      1     1  \n",
      "4_P      2     4  \n",
      "5_P      0     0  \n",
      "6_P      2     0  \n",
      "7_P      0     0  \n",
      "8_P      3     4  \n",
      "9_P      9     3  \n",
      "10_P     0     0  \n",
      "11_P     0     0  \n",
      "12_P   870     3  \n",
      "13_P    12   680  \n",
      "Accuracy (top 1 guesses) - test =  50.446 %\n",
      "\tConfusion Matrix test:\n",
      "        0_T   1_T  2_T  3_T  4_T  5_T  6_T  7_T  8_T  9_T  10_T  11_T  12_T  \\\n",
      "0_P   5457    27   59  136  122   82   66  149   34   11    29     9    21   \n",
      "1_P    151  1939   82   86   54   34   39   18   32   19    21    27    45   \n",
      "2_P    369   113  891  156   50   32  137   21   29   80    39   104    26   \n",
      "3_P    653    91  146  707   46   30   85   57   42   31    87    32    26   \n",
      "4_P    704    57   70   63  742   18   74   69   19   32    28    21    17   \n",
      "5_P    486    55   28   51   30  534   47   22  166   26    19     1    11   \n",
      "6_P    337   103  208  139   89   44  329   21   54   42    34    45    34   \n",
      "7_P    603    33   30   65   69   31   18  373   28   18    26    16    10   \n",
      "8_P    373    91   36   57   38  195   66   25  250   16    15     8    14   \n",
      "9_P    133    90  130   66   42   28   31   23   24  290    17    21    33   \n",
      "10_P   159    43   58  126   31   14   33   31   16   26   266     9     9   \n",
      "11_P    93   109  176   57   36   10   43    7   15   27    17    94     5   \n",
      "12_P   151    91   38   31   14   14   25    8   15   45     8    13   141   \n",
      "13_P    92   153   59   56   35    9   36   22   22   24     7    20    15   \n",
      "\n",
      "      13_T  \n",
      "0_P      6  \n",
      "1_P     40  \n",
      "2_P     11  \n",
      "3_P      6  \n",
      "4_P     19  \n",
      "5_P      8  \n",
      "6_P     14  \n",
      "7_P     11  \n",
      "8_P     14  \n",
      "9_P     20  \n",
      "10_P     4  \n",
      "11_P     6  \n",
      "12_P    10  \n",
      "13_P   142  \n",
      "lr 2.498997902644655e-07\n",
      "epoch-360, loss 0.288\n",
      "------------------------------------\n",
      "Epoch 1191873: reducing learning rate of group 0 to 2.2491e-07.\n",
      "iter-2000, loss 0.393\n",
      "lr 2.2490981123801895e-07\n",
      "epoch-361, loss 0.009\n",
      "------------------------------------\n",
      "iter-2000, loss 0.625\n",
      "lr 2.2490981123801895e-07\n",
      "epoch-362, loss 0.346\n",
      "------------------------------------\n",
      "iter-2000, loss 0.1\n",
      "lr 2.2490981123801895e-07\n",
      "epoch-363, loss 0.519\n",
      "------------------------------------\n",
      "iter-2000, loss 0.617\n",
      "Epoch 1203874: reducing learning rate of group 0 to 2.0242e-07.\n",
      "lr 2.0241883011421707e-07\n",
      "epoch-364, loss 1.526\n",
      "------------------------------------\n",
      "iter-2000, loss 0.238\n",
      "lr 2.0241883011421707e-07\n",
      "epoch-365, loss 0.099\n",
      "------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-fee5e71d5b44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# train model using pytorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# model = torch_net(X_train, Y_train[:,0],X_test,Y_test,[100,50,50],epoch=1000)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-5710f31e6a6c>\u001b[0m in \u001b[0;36mtorch_net\u001b[1;34m(X_train, Y_train, X_test, Y_test, hidden_layers, device, epoch, batch_size)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mi_iter\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;31m# Forward pass: compute predicted y by passing x to the model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;31m#             print (\"x_batch.shape\", x_batch.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;31m#             print (\"y_batch.shape\", y_batch.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1351\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1352\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1353\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model using pytorch\n",
    "# model = torch_net(X_train, Y_train[:,0],X_test,Y_test,[100,50,50],epoch=1000)\n",
    "model = torch_net(X_train, Y_train[:,0],X_test,Y_test,[100,70,50],epoch=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
