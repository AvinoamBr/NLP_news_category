{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\אבינעם\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\אבינעם\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\אבינעם\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import nltk\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import torch.utils.data as torch_data\n",
    "import scipy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# from Utils.pytorch_utils import torch_net\n",
    "from Utils.pytorch_utils import sparse_to_matrix #, accuracy_test\n",
    "\n",
    "from Utils.NLP_utils import accuracy, find_senteces_with_lemma, get_wordnet_pos, load_and_lemmatize_data, load_processed_data\n",
    "\n",
    "# pickle file, data set as readable json file, since original data set is a 'pseudo json', written in text file.\n",
    "DATA_SET_FILE = r\"C:\\Users\\גורים\\PycharmProjects\\NLP_training\\datasets\\News_Category_Dataset_v2_mod.pkl\"\n",
    "PROCESSED_DATA_SET = r\"C:\\Users\\גורים\\PycharmProjects\\NLP_training\\datasets\\News_Category_Dataset_v2_mod_processed.pkl\"\n",
    "\n",
    "CrossEntropyLoss = \"CrossEntropyLoss\"\n",
    "MSELoss = \"MSELoss\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set loss type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_name = CrossEntropyLoss\n",
    "loss_name = MSELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_to_matrix(A):\n",
    "    if type(A) == scipy.sparse.csr.csr_matrix:\n",
    "        return np.array(A.todense())\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_disp(y_pred,y_true,label = False):\n",
    "    cm = confusion_matrix(y_pred,y_true)\n",
    "    if not label:\n",
    "        label_t,label_p = set(y_true) , set(y_pred)\n",
    "    else:\n",
    "        label_t,label_p = label\n",
    "    cm_pd = pd.DataFrame(cm,columns = [\"{}_P\".format(i)  for i in label_p],index = [\"{}_T\".format(i)  for i in label_t])\n",
    "    return cm_pd\n",
    "\n",
    "def accuracy_test_dummies(model, x, y, data_set_name = 'test',print_sample = False):\n",
    "    predicted = torch.argmax(model(torch.tensor(x, dtype=torch.float)), dim=-1).numpy()\n",
    "    truth = np.argmax(y, axis=-1)\n",
    "    # print(np.array((predicted, truth)))\n",
    "    print (f\"Accuracy {data_set_name} = \",\n",
    "           round( np.array(predicted == truth).mean()* 100, 3 ),\n",
    "           \"%\")\n",
    "    if print_sample:\n",
    "        ps = print_sample\n",
    "        sample = pd.DataFrame((predicted[:ps],truth[:ps]),index=['predicted','truth'])\n",
    "        print (sample)\n",
    "        print (pd.value_counts(predicted))\n",
    "        print (\"\\tConfusion Matrix:\\n\",confusion_matrix_disp (predicted,truth))\n",
    "        \n",
    "def accuracy_test_classes(*args, **kwargs):\n",
    "    ## TODO support accuracy test for \n",
    "    return None       \n",
    "\n",
    "if loss_name == MSELoss:\n",
    "    accuracy_test = accuracy_test_dummies\n",
    "elif loss_name == CrossEntropyLoss:\n",
    "    accuracy_test = accuracy_test_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "\n",
    "# dataset, headlines, headlines_orig = load_and_lemmatize_data(DATA_SET_FILE)\n",
    "dataset, headlines, headlines_orig = load_processed_data(PROCESSED_DATA_SET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reduce dataset to n categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = dataset['category']\n",
    "pd.value_counts(categories)\n",
    "\n",
    "# filter data for two categories, to make problem easier\n",
    "filter_index =  (categories == 'RELIGION')  | (categories == 'SCIENCE')  | (categories == 'TASTE')  | (categories == 'PARENTING')\n",
    "dataset   = dataset[filter_index]\n",
    "headlines = np.array(headlines)[filter_index]\n",
    "headlines_orig = np.array(headlines_orig)[filter_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = dataset['category']\n",
    "Y  = np.array(pd.get_dummies(categories))\n",
    "\n",
    "def categories_to_index(categories):\n",
    "    d = {}\n",
    "    for i, cat in enumerate(set(categories)):\n",
    "        d[cat] = i\n",
    "        \n",
    "    r = np.array(range(len(categories)))\n",
    "\n",
    "    for cat,i in d.items():\n",
    "        # print (cat,i)\n",
    "        r[categories == cat ] = i\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loss_name == CrossEntropyLoss:  \n",
    "    Y = categories_to_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data and lables to train/test\n",
    "\n",
    "headlines_train, headlines_test,\\\n",
    "headlines_train_orig, headlines_test_orig,\\\n",
    "Y_train, Y_test,\\\n",
    "cat_train, cat_test\\\n",
    "    = sklearn.model_selection.train_test_split(\n",
    "    headlines,headlines_orig, Y, categories, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features (Bag Of Words) using Vectorizer\n",
    "\n",
    "max_features=1000\n",
    "\n",
    "vectorizer = CountVectorizer\n",
    "# vectorizer = TfidfVectorizer\n",
    "matrix = vectorizer(max_features=max_features, ngram_range=(1, 2), max_df=0.1 ,min_df = 5)\n",
    "matrix.fit(headlines_train)\n",
    "X_train = matrix.transform(headlines_train)# .todense()\n",
    "X_test = matrix.transform(headlines_test)# .todense()\n",
    "\n",
    "# --- convert to data frame for display and debug ---\n",
    "# tokens = matrix.get_feature_names()\n",
    "# X_train= pd.DataFrame(X_train,columns=tokens)\n",
    "# X_test= pd.DataFrame(X_test,columns=tokens)\n",
    "\n",
    "assert X_train.shape[1]==max_features, X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated torch nn\n"
     ]
    }
   ],
   "source": [
    "def torch_net(X_in, Y_in, X_test, Y_test,\n",
    "              hidden_layers=[10], device=torch.device('cpu'), epoch=30, batch_size=17):\n",
    "    \n",
    "    def set_learning_rate(optimizer,lr):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "            \n",
    "    def print_learning_rate(optimizer):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print('lr', param_group['lr'])\n",
    "    \n",
    "    # hiden_layers = [size1,size2...]\n",
    "\n",
    "    dtype = torch.float\n",
    "    # device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "    # N is batch size; D_in is input dimension;\n",
    "    # H is hidden dimension; D_out is output dimension.\n",
    "    N, D_in = X_in.shape\n",
    "    D_out = Y_in.shape[-1]\n",
    "\n",
    "    # Create random input and output data\n",
    "\n",
    "    [X_in, Y_in, X_test, Y_test] = \\\n",
    "        [sparse_to_matrix(A) for A in[X_in, Y_in, X_test, Y_test]]\n",
    "\n",
    "    X = torch.tensor(X_in, device=device, dtype=dtype)\n",
    "    Y = torch.tensor(Y_in, device=device, dtype=dtype)\n",
    "\n",
    "    #create neural network net with multiple hidden layers with H dimetions:\n",
    "    dims = [D_in, *hidden_layers, D_out]\n",
    "    layers = []\n",
    "    for dim_ind in range(len(dims)-2):\n",
    "        layers.append(torch.nn.Linear(dims[dim_ind], dims[dim_ind+1]))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "    layers.append(torch.nn.Dropout(0.5))\n",
    "    layers.append(torch.nn.Linear(dims[-2], D_out))   \n",
    "    \n",
    "    model = torch.nn.Sequential(*layers)\n",
    "    if loss_name == CrossEntropyLoss:\n",
    "        loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')     \n",
    "    elif loss_name == MSELoss:\n",
    "        loss_fn = torch.nn.MSELoss(reduction='mean') \n",
    "\n",
    "    # Use the optim package to define an Optimizer that will update the weights of\n",
    "    # the model for us. Here we will use Adam; the optim package contains many other\n",
    "    # optimization algoriths. The first argument to the Adam constructor tells the\n",
    "    # optimizer which Tensors it should update.\n",
    "    learning_rate = 0.05\n",
    "    weight_decay = 0.00001\n",
    "    lr_decay = 0.9\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    dataloader = torch_data.DataLoader(\n",
    "        torch_data.TensorDataset(X, Y), batch_size=batch_size,\n",
    "        shuffle=True, num_workers=4)\n",
    "    print (\"Start training:\")\n",
    "    print (\"loss name is: \",loss_name, \" Using loss function: \", loss_fn)\n",
    "    accuracy_test(model, X_test, Y_test, data_set_name='test',print_sample = 16)\n",
    "    accuracy_test(model, X_in, Y_in, data_set_name='train',print_sample = 16)\n",
    "    \n",
    "    epoch_lr = learning_rate\n",
    "\n",
    "    for e in range(epoch):\n",
    "        for t,(x_batch, y_batch) in enumerate(dataloader):\n",
    "            # Forward pass: compute predicted y by passing x to the model.\n",
    "            y_pred = model(x_batch)\n",
    "#             print (\"x_batch.shape\", x_batch.shape)\n",
    "#             print (\"y_batch.shape\", y_batch.shape)\n",
    "#             print (\"y_pred.shape\", y_pred.shape)\n",
    "#             print (\"y_batch[0,0]\", y_batch[0,0])\n",
    "#             print (\"y_pred[0,0]\", y_pred[0,0])\n",
    "#             y_pred_soft = torch.nn.functional.softmax(y_pred, dim = -1)\n",
    "            # Compute and print loss.\n",
    "#             batch_class_weights = torch.ones((y_batch.dim()))\n",
    "#             loss = loss_fn(y_pred_soft, y_batch, weight = batch_class_weights)\n",
    "#             loss = loss_fn(y_pred_soft, y_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            if not ( (t +1) % 2000 ) :\n",
    "                print(f\"iter-{t+1}, loss {round(loss.item(),3)}\")\n",
    "\n",
    "            # Before the backward pass, use the optimizer object to zero all of the\n",
    "            # gradients for the variables it will update (which are the learnable\n",
    "            # weights of the model). This is because by default, gradients are\n",
    "            # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "            # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backward pass: compute gradient of the loss with respect to model\n",
    "            # parameters\n",
    "\n",
    "            #  $$$ this command destroy exit() command $$$\n",
    "            loss.backward()\n",
    "\n",
    "            # Calling the step function on an Optimizer makes an update to its\n",
    "            # parameters\n",
    "            optimizer.step()\n",
    "        accuracy_test(model, X_test, Y_test, data_set_name= 'test', print_sample=15)\n",
    "        accuracy_test(model, X_in, Y_in, data_set_name= 'train', print_sample = 15)\n",
    "        \n",
    "        epoch_lr = epoch_lr * lr_decay\n",
    "        print_learning_rate(optimizer)\n",
    "        print(f\"epoch-{e+1}, loss {round(loss.item(),3)}\")\n",
    "        print(\"------------------------------------\")\n",
    "        set_learning_rate(optimizer,epoch_lr)\n",
    "        \n",
    "    print (\"DONE, returning model\")\n",
    "    return model\n",
    "\n",
    "print (\"updated torch nn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training:\n",
      "loss name is:  MSELoss  Using loss function:  MSELoss()\n",
      "Accuracy test =  20.524 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15\n",
      "predicted   1   3   3   2   1   1   1   0   2   1   3   1   2   1   1   0\n",
      "truth       3   0   3   2   2   2   0   0   0   0   0   0   2   1   1   1\n",
      "1    1872\n",
      "3    1526\n",
      "0     664\n",
      "2     591\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T   385  101   86   92\n",
      "1_T  1001  298  289  284\n",
      "2_T   334   88   84   85\n",
      "3_T   872  275  191  188\n",
      "Accuracy train =  20.444 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15\n",
      "predicted   2   3   1   1   1   3   3   2   3   3   3   1   0   0   0   3\n",
      "truth       0   0   0   1   0   2   1   3   0   3   0   1   2   1   3   0\n",
      "1    4446\n",
      "3    3355\n",
      "0    1604\n",
      "2    1449\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T   951  215  207  231\n",
      "1_T  2337  735  704  670\n",
      "2_T   852  196  194  207\n",
      "3_T  1945  648  423  339\n",
      "Accuracy test =  46.228 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   3   2   3   0   3   0   0   0   0   1   2   1   0\n",
      "truth       3   0   3   2   2   2   0   0   0   0   0   0   2   1   1\n",
      "0    2299\n",
      "3     924\n",
      "1     773\n",
      "2     657\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  1493  335  239  232\n",
      "1_T   390  200   94   89\n",
      "2_T   279   84  212   82\n",
      "3_T   430  143  105  246\n",
      "Accuracy train =  47.024 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   1   0   0   1   0   0   1   0   3   0   0   2   3   0\n",
      "truth       0   0   0   1   0   2   1   3   0   3   0   1   2   1   3\n",
      "0    5430\n",
      "3    2156\n",
      "1    1750\n",
      "2    1518\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  3553  775  578  524\n",
      "1_T   833  513  238  166\n",
      "2_T   628  219  476  195\n",
      "3_T  1071  287  236  562\n",
      "lr 0.05\n",
      "epoch-1, loss 0.843\n",
      "------------------------------------\n",
      "Accuracy test =  50.484 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   3   0   0   0   0   2   2   0   1   3   0   0   0   0   0\n",
      "truth       3   0   3   2   2   2   0   0   0   0   0   0   2   1   1\n",
      "0    2640\n",
      "3     812\n",
      "1     707\n",
      "2     494\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  1739  335  284  282\n",
      "1_T   279  265   95   68\n",
      "2_T   189   67  142   96\n",
      "3_T   385   95  129  203\n",
      "Accuracy train =  52.036 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   0   0   0   3   1   0   0   3   0   0   0   3   3\n",
      "truth       0   0   0   1   0   2   1   3   0   3   0   1   2   1   3\n",
      "0    6225\n",
      "3    1858\n",
      "1    1558\n",
      "2    1213\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  4159  805  637  624\n",
      "1_T   589  602  240  127\n",
      "2_T   489  169  373  182\n",
      "3_T   848  218  278  514\n",
      "lr 0.045000000000000005\n",
      "epoch-2, loss 0.408\n",
      "------------------------------------\n",
      "Accuracy test =  47.174 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   3   3   2   0   0   2   2   0   0   2   0   3   1   0\n",
      "truth       3   0   3   2   2   2   0   0   0   0   0   0   2   1   1\n",
      "0    2115\n",
      "1     890\n",
      "2     864\n",
      "3     784\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  1444  283  190  198\n",
      "1_T   363  274  129  124\n",
      "2_T   416  116  241   91\n",
      "3_T   369   89   90  236\n",
      "Accuracy train =  47.945 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   3   0   1   1   0   3   1   0   0   1   0   0   0   2   0\n",
      "truth       0   0   0   1   0   2   1   3   0   3   0   1   2   1   3\n",
      "0    4788\n",
      "1    2113\n",
      "2    2109\n",
      "3    1844\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  3309  619  457  403\n",
      "1_T   879  739  256  239\n",
      "2_T  1025  247  594  243\n",
      "3_T   872  189  221  562\n",
      "lr 0.04050000000000001\n",
      "epoch-3, loss 0.222\n",
      "------------------------------------\n",
      "Accuracy test =  54.889 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   0   0   0   1   0   0   3   0   0   3   3   1   0\n",
      "truth       3   0   3   2   2   2   0   0   0   0   0   0   2   1   1\n",
      "0    2857\n",
      "3     643\n",
      "2     643\n",
      "1     510\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  1868  389  303  297\n",
      "1_T   193  215   63   39\n",
      "2_T   275   84  221   63\n",
      "3_T   256   74   63  250\n",
      "Accuracy train =  55.095 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   1   0   2   0   3   1   0   2   0   0   0   0   0   3\n",
      "truth       0   0   0   1   0   2   1   3   0   3   0   1   2   1   3\n",
      "0    6466\n",
      "2    1571\n",
      "3    1565\n",
      "1    1252\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  4308  882  645  631\n",
      "1_T   475  536  138  103\n",
      "2_T   644  200  575  152\n",
      "3_T   658  176  170  561\n",
      "lr 0.03645000000000001\n",
      "epoch-4, loss 0.439\n",
      "------------------------------------\n",
      "Accuracy test =  52.633 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   3   0   2   2   3   3   1   0   0   2   0   0   3   0   0\n",
      "truth       3   0   3   2   2   2   0   0   0   0   0   0   2   1   1\n",
      "0    2649\n",
      "3     807\n",
      "2     617\n",
      "1     580\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  1741  371  278  259\n",
      "1_T   248  226   63   43\n",
      "2_T   252   82  209   74\n",
      "3_T   351   83  100  273\n",
      "Accuracy train =  53.464 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   1   0   0   2   1   2   0   1   0   0   0   3   3\n",
      "truth       0   0   0   1   0   2   1   3   0   3   0   1   2   1   3\n",
      "0    6030\n",
      "3    1815\n",
      "2    1596\n",
      "1    1413\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  4022  835  616  557\n",
      "1_T   555  596  157  105\n",
      "2_T   689  171  568  168\n",
      "3_T   819  192  187  617\n",
      "lr 0.03280500000000001\n",
      "epoch-5, loss 0.225\n",
      "------------------------------------\n",
      "Accuracy test =  56.695 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   3   0   3   3   3   0   0   0   0   0   0   0   1   1   0\n",
      "truth       3   0   3   2   2   2   0   0   0   0   0   0   2   1   1\n",
      "0    2739\n",
      "3     710\n",
      "1     668\n",
      "2     536\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  1850  338  292  259\n",
      "1_T   241  294   81   52\n",
      "2_T   207   57  214   58\n",
      "3_T   294   73   63  280\n",
      "Accuracy train =  57.555 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   0   0   3   0   1   0   0   0   0   0   2   0   3\n",
      "truth       0   0   0   1   0   2   1   3   0   3   0   1   2   1   3\n",
      "0    6489\n",
      "3    1600\n",
      "1    1454\n",
      "2    1311\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  4431  799  677  582\n",
      "1_T   537  646  141  130\n",
      "2_T   468  170  554  119\n",
      "3_T   649  179  156  616\n",
      "lr 0.02952450000000001\n",
      "epoch-6, loss 0.218\n",
      "------------------------------------\n",
      "Accuracy test =  59.123 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   3   2   0   0   3   0   3   1   0   3   2   0   0\n",
      "truth       3   0   3   2   2   2   0   0   0   0   0   0   2   1   1\n",
      "0    3015\n",
      "3     640\n",
      "2     511\n",
      "1     487\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  2039  392  278  306\n",
      "1_T   143  233   67   44\n",
      "2_T   166   59  233   53\n",
      "3_T   244   78   72  246\n",
      "Accuracy train =  59.278 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   0   2   0   0   1   0   0   0   2   0   0   0   3\n",
      "truth       0   0   0   1   0   2   1   3   0   3   0   1   2   1   3\n",
      "0    6900\n",
      "3    1429\n",
      "2    1266\n",
      "1    1259\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  4712  826  698  664\n",
      "1_T   379  640  134  106\n",
      "2_T   406  189  538  133\n",
      "3_T   588  139  158  544\n",
      "lr 0.02657205000000001\n",
      "epoch-7, loss 0.203\n",
      "------------------------------------\n",
      "Accuracy test =  57.167 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   0   2   3   3   0   0   2   0   0   0   2   0   2\n",
      "truth       3   0   3   2   2   2   0   0   0   0   0   0   2   1   1\n",
      "0    2658\n",
      "1     717\n",
      "3     643\n",
      "2     635\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  1850  302  247  259\n",
      "1_T   263  313   80   61\n",
      "2_T   224   69  255   87\n",
      "3_T   255   78   68  242\n",
      "Accuracy train =  58.485 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   0   3   0   0   1   3   0   0   0   0   0   1   0\n",
      "truth       0   0   0   1   0   2   1   3   0   3   0   1   2   1   3\n",
      "0    6173\n",
      "1    1790\n",
      "2    1492\n",
      "3    1399\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  4335  693  579  566\n",
      "1_T   636  812  199  143\n",
      "2_T   545  144  633  170\n",
      "3_T   569  145  117  568\n",
      "lr 0.02391484500000001\n",
      "epoch-8, loss 0.171\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test =  61.724 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   3   0   0   0   0   0   0   0   0   0   2   0   0\n",
      "truth       3   0   3   2   2   2   0   0   0   0   0   0   2   1   1\n",
      "0    3167\n",
      "1     563\n",
      "3     485\n",
      "2     438\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  2143  380  350  294\n",
      "1_T   172  278   56   57\n",
      "2_T   135   68  194   41\n",
      "3_T   142   36   50  257\n",
      "Accuracy train =  62.659 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   0   0   0   2   1   3   0   0   0   0   0   0   0\n",
      "truth       0   0   0   1   0   2   1   3   0   3   0   1   2   1   3\n",
      "0    7328\n",
      "1    1296\n",
      "3    1154\n",
      "2    1076\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  5051  855  814  608\n",
      "1_T   350  692  119  135\n",
      "2_T   344  140  473  119\n",
      "3_T   340  107  122  585\n",
      "lr 0.021523360500000012\n",
      "epoch-9, loss 0.278\n",
      "------------------------------------\n",
      "Accuracy test =  60.628 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   0   2   0   1   0   0   3   0   0   0   1   0   0\n",
      "truth       3   0   3   2   2   2   0   0   0   0   0   0   2   1   1\n",
      "0    3023\n",
      "2     582\n",
      "3     568\n",
      "1     480\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  2080  368  292  283\n",
      "1_T   121  254   44   61\n",
      "2_T   194   74  248   66\n",
      "3_T   197   66   66  239\n",
      "Accuracy train =  61.83 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   0   0   0   1   1   0   0   0   0   0   3   3   3\n",
      "truth       0   0   0   1   0   2   1   3   0   3   0   1   2   1   3\n",
      "0    6996\n",
      "3    1431\n",
      "2    1317\n",
      "1    1110\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  4884  823  713  576\n",
      "1_T   289  629   87  105\n",
      "2_T   442  179  564  132\n",
      "3_T   470  163  164  634\n",
      "lr 0.01937102445000001\n",
      "epoch-10, loss 0.212\n",
      "------------------------------------\n",
      "Accuracy test =  62.863 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   3   0   1   2   0   0   2   0   0   0   0   1   2   0   0\n",
      "truth       3   0   3   2   2   2   0   0   0   0   0   0   2   1   1\n",
      "0    3001\n",
      "1     639\n",
      "2     514\n",
      "3     499\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  2090  383  283  245\n",
      "1_T   204  298   68   69\n",
      "2_T   155   43  259   57\n",
      "3_T   143   38   40  278\n",
      "Accuracy train =  63.682 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   0   0   0   2   1   0   1   0   0   0   0   0   0\n",
      "truth       0   0   0   1   0   2   1   3   0   3   0   1   2   1   3\n",
      "0    7040\n",
      "1    1433\n",
      "2    1217\n",
      "3    1164\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  4942  792  692  614\n",
      "1_T   441  753  132  107\n",
      "2_T   361  135  606  115\n",
      "3_T   341  114   98  611\n",
      "lr 0.01743392200500001\n",
      "epoch-11, loss 0.188\n",
      "------------------------------------\n",
      "Accuracy test =  62.261 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0\n",
      "truth       3   0   3   2   2   2   0   0   0   0   0   0   2   1   1\n",
      "0    2918\n",
      "3     617\n",
      "1     575\n",
      "2     543\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  2038  344  289  247\n",
      "1_T   157  313   70   35\n",
      "2_T   181   49  246   67\n",
      "3_T   216   56   45  300\n",
      "Accuracy train =  62.954 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   0   0   0   0   1   3   1   2   0   0   0   0   2\n",
      "truth       0   0   0   1   0   2   1   3   0   3   0   1   2   1   3\n",
      "0    6821\n",
      "3    1514\n",
      "1    1286\n",
      "2    1233\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  4811  776  656  578\n",
      "1_T   338  737  130   81\n",
      "2_T   422  128  590   93\n",
      "3_T   514  153  152  695\n",
      "lr 0.015690529804500006\n",
      "epoch-12, loss 0.162\n",
      "------------------------------------\n",
      "Accuracy test =  63.894 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   3   0   0   0   0   0   0   0   0   0   0   3   0   1\n",
      "truth       3   0   3   2   2   2   0   0   0   0   0   0   2   1   1\n",
      "0    3214\n",
      "1     539\n",
      "3     454\n",
      "2     446\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  2201  391  318  304\n",
      "1_T   123  294   57   65\n",
      "2_T   135   45  232   34\n",
      "3_T   133   32   43  246\n",
      "Accuracy train =  65.248 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   0   0   0   0   1   3   0   0   0   0   0   0   0\n",
      "truth       0   0   0   1   0   2   1   3   0   3   0   1   2   1   3\n",
      "0    7290\n",
      "1    1378\n",
      "3    1107\n",
      "2    1079\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  5104  853  704  629\n",
      "1_T   341  767  151  119\n",
      "2_T   280  107  602   90\n",
      "3_T   360   67   71  609\n",
      "lr 0.014121476824050006\n",
      "epoch-13, loss 0.198\n",
      "------------------------------------\n",
      "Accuracy test =  65.119 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   3   0   0   0   0   0   0   0   0   0   0   2   1   0\n",
      "truth       3   0   3   2   2   2   0   0   0   0   0   0   2   1   1\n",
      "0    3143\n",
      "2     540\n",
      "1     535\n",
      "3     435\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  2190  367  297  289\n",
      "1_T   124  314   55   42\n",
      "2_T   157   51  270   62\n",
      "3_T   121   30   28  256\n",
      "Accuracy train =  67.404 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   0   0   0   2   1   3   0   0   0   0   1   1   0\n",
      "truth       0   0   0   1   0   2   1   3   0   3   0   1   2   1   3\n",
      "0    7304\n",
      "1    1291\n",
      "2    1207\n",
      "3    1052\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  5213  790  702  599\n",
      "1_T   277  820  118   76\n",
      "2_T   316  122  640  129\n",
      "3_T   279   62   68  643\n",
      "lr 0.012709329141645007\n",
      "epoch-14, loss 0.095\n",
      "------------------------------------\n",
      "Accuracy test =  66.581 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   2   3   2   0   3   0   0   0   3   0   0   2   1   1\n",
      "truth       3   0   3   2   2   2   0   0   0   0   0   0   2   1   1\n",
      "0    3168\n",
      "1     528\n",
      "3     481\n",
      "2     476\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  2215  366  302  285\n",
      "1_T   122  326   42   38\n",
      "2_T   133   38  268   37\n",
      "3_T   122   32   38  289\n",
      "Accuracy train =  67.422 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   0   0   0   2   1   1   0   2   0   0   0   1   0\n",
      "truth       0   0   0   1   0   2   1   3   0   3   0   1   2   1   3\n",
      "0    7274\n",
      "1    1290\n",
      "3    1148\n",
      "2    1142\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  5174  809  698  593\n",
      "1_T   305  820   78   87\n",
      "2_T   292   95  656   99\n",
      "3_T   314   70   96  668\n",
      "lr 0.011438396227480507\n",
      "epoch-15, loss 0.145\n",
      "------------------------------------\n",
      "Accuracy test =  66.538 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   3   3   2   0   1   0   0   0   3   0   0   0   0   0\n",
      "truth       3   0   3   2   2   2   0   0   0   0   0   0   2   1   1\n",
      "0    3349\n",
      "1     472\n",
      "3     450\n",
      "2     382\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  2284  404  348  313\n",
      "1_T    98  307   28   39\n",
      "2_T    90   34  233   25\n",
      "3_T   120   17   41  272\n",
      "Accuracy train =  67.957 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   0   0   0   0   1   3   0   0   0   0   0   0   0\n",
      "truth       0   0   0   1   0   2   1   3   0   3   0   1   2   1   3\n",
      "0    7814\n",
      "1    1155\n",
      "3    1001\n",
      "2     884\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  5417  895  783  719\n",
      "1_T   220  782   87   66\n",
      "2_T   186   65  574   59\n",
      "3_T   262   52   84  603\n",
      "lr 0.010294556604732457\n",
      "epoch-16, loss 0.167\n",
      "------------------------------------\n",
      "Accuracy test =  66.645 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   3   0   3   0   0   0   0   0   0   0   0   0   2   0   0\n",
      "truth       3   0   3   2   2   2   0   0   0   0   0   0   2   1   1\n",
      "0    3383\n",
      "2     436\n",
      "3     420\n",
      "1     414\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  2313  413  324  333\n",
      "1_T    77  279   31   27\n",
      "2_T   110   42  252   32\n",
      "3_T    92   28   43  257\n",
      "Accuracy train =  69.21 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   0   0   0   2   0   0   0   0   0   0   0   3   3\n",
      "truth       0   0   0   1   0   2   1   3   0   3   0   1   2   1   3\n",
      "0    7764\n",
      "1    1112\n",
      "3    1016\n",
      "2     962\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  5449  853  762  700\n",
      "1_T   198  795   75   44\n",
      "2_T   221   78  614   49\n",
      "3_T   217   68   77  654\n",
      "lr 0.00926510094425921\n",
      "epoch-17, loss 0.181\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test =  68.279 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   0   2   0   0   0   0   0   0   0   0   0   0   1\n",
      "truth       3   0   3   2   2   2   0   0   0   0   0   0   2   1   1\n",
      "0    3309\n",
      "3     506\n",
      "2     426\n",
      "1     412\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  2313  381  323  292\n",
      "1_T    61  298   30   23\n",
      "2_T    98   48  256   24\n",
      "3_T   120   35   41  310\n",
      "Accuracy train =  69.864 %\n",
      "           0   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "predicted   0   0   0   2   0   2   1   3   0   0   0   0   0   1   3\n",
      "truth       0   0   0   1   0   2   1   3   0   3   0   1   2   1   3\n",
      "0    7657\n",
      "1    1090\n",
      "3    1077\n",
      "2    1030\n",
      "dtype: int64\n",
      "\tConfusion Matrix:\n",
      "       0_P  1_P  2_P  3_P\n",
      "0_T  5450  854  718  635\n",
      "1_T   175  778   85   52\n",
      "2_T   228   95  651   56\n",
      "3_T   232   67   74  704\n",
      "lr 0.00833859084983329\n",
      "epoch-18, loss 0.133\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# train model using pytorch\n",
    "model = torch_net(X_train, Y_train,X_test,Y_test,[],epoch=1000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
